{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Final Project - EE 379k - sp18 - \n",
    "\n",
    "# Shahshank Kambhampati - skk834, Shrikara Murthy - svm456, Pranav Harathi - , Neil Charles - \n",
    "\n",
    "# Job Satisfaction Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "### All hail lord and savior XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomTreesEmbedding, AdaBoostClassifier, AdaBoostRegressor, RandomForestRegressor, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectKBest,  chi2\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from __future__ import print_function\n",
    "%config inlinebackend.figure_format = 'retina' \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Observations about the Data and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = re.compile('[\\d,]+')\n",
    "def get_first_number(val):\n",
    "    matched = number.match(str(val))\n",
    "    if matched:\n",
    "        return int(matched.group())\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "satisfaction_strs = {\n",
    "    'I love my job': 10,\n",
    "    'I\\'m somewhat satisfied with my job': 7.5,\n",
    "    'I\\'m neither satisfied nor dissatisfied with my job': 5,\n",
    "    'I\\'m somewhat dissatisfied with my job': 2.5,\n",
    "    'I hate my job': 0,\n",
    "}\n",
    "\n",
    "binary_labels = [\n",
    "    'Lang & Tech',\n",
    "    'Training & Education',\n",
    "    'How can companies improve interview process',\n",
    "    'Why try Stack Overflow Careers',\n",
    "    'Most important aspect of new job opportunity',\n",
    "    'Most annoying about job search',\n",
    "    'Appealing message traits',\n",
    "    'Most urgent info about job opportunity',\n",
    "    'Who do you want to communicate with about a new job opportunity',\n",
    "    'Why use Stack Overflow',\n",
    "    'Why answer',\n",
    "    'Source control used',\n",
    "]\n",
    "\n",
    "numeric_labels = [\n",
    "    'Age',\n",
    "    'Years IT / Programming Experience',\n",
    "    'Compensation: midpoint'\n",
    "]\n",
    "\n",
    "yes_no_labels = [\n",
    "    'Changed Jobs in last 12 Months'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,108,121,196,197,198) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs:\n",
      "Age\n",
      "Years IT / Programming Experience\n",
      "Compensation: midpoint\n",
      "Filling with mean of column\n"
     ]
    }
   ],
   "source": [
    "# 2015 preproc\n",
    "data = pd.read_csv('data/2015.csv')\n",
    "to_drop = [label for label in data if 'write-in' in label.lower()]\n",
    "\n",
    "data['Job Satisfaction'] = data['Job Satisfaction']\\\n",
    "                                    .map(satisfaction_strs).astype('float')\n",
    "data = data[data['Job Satisfaction'].notnull()]\n",
    "to_drop.append('Country')\n",
    "to_drop.append('Compensation')\n",
    "\n",
    "data['Age'] = data['Age'].map(get_first_number).astype('float')\n",
    "data['gender_M'] = (data['Gender'] == 'Male').astype('int8')\n",
    "data['gender_F'] = (data['Gender'] == 'Female').astype('int8')\n",
    "to_drop.append('Gender')\n",
    "to_drop.append('Prefered Source Control')\n",
    "\n",
    "bin_labels = [key for key in data if any(label in key for label in binary_labels)]\n",
    "data[bin_labels] = data[bin_labels].apply(lambda col: col.notnull().astype('int8'))\n",
    "\n",
    "data[numeric_labels] = data[numeric_labels].applymap(get_first_number)\n",
    "data[yes_no_labels] = data[yes_no_labels]\\\n",
    "                                .apply(lambda col: col.map({'Yes': 1, 'No': 0}))\\\n",
    "                                .fillna(0)\n",
    "\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "print(\"Columns with NaNs:\")\n",
    "\n",
    "for key in data:\n",
    "    if data[key].isnull().any():\n",
    "        print (key)\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "print ('Filling with mean of column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data contains a DataFrame with no NaNs, all numbers.\n",
    "# We're trying to predict the \"Job Satisfaction\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = data[['Compensation: midpoint','Purchasing Power_I have no say in purchasing what I need or want at work','Remote Status_Never','Changed Jobs in last 12 Months']]\n",
    "X = data.drop('Job Satisfaction',axis=1)\n",
    "y = data['Job Satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)#stratify=y\n",
    "scoring = {'mean': make_scorer(mean_squared_error)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Years IT / Programming Experience  Current Lang & Tech: Android  \\\n",
      "0  25.0                                2.0                             0   \n",
      "1  20.0                                1.0                             0   \n",
      "2  20.0                                1.0                             0   \n",
      "3  25.0                                6.0                             0   \n",
      "4  30.0                                2.0                             0   \n",
      "\n",
      "   Current Lang & Tech: Arduino  Current Lang & Tech: AngularJS  \\\n",
      "0                             0                               0   \n",
      "1                             0                               0   \n",
      "2                             0                               0   \n",
      "3                             0                               0   \n",
      "4                             0                               0   \n",
      "\n",
      "   Current Lang & Tech: C  Current Lang & Tech: C++  \\\n",
      "0                       0                         0   \n",
      "1                       0                         0   \n",
      "2                       0                         0   \n",
      "3                       0                         0   \n",
      "4                       0                         0   \n",
      "\n",
      "   Current Lang & Tech: C++11  Current Lang & Tech: C#  \\\n",
      "0                           0                        0   \n",
      "1                           0                        1   \n",
      "2                           0                        1   \n",
      "3                           0                        0   \n",
      "4                           0                        1   \n",
      "\n",
      "   Current Lang & Tech: Cassandra  \\\n",
      "0                               0   \n",
      "1                               0   \n",
      "2                               0   \n",
      "3                               0   \n",
      "4                               0   \n",
      "\n",
      "                            ...                            \\\n",
      "0                           ...                             \n",
      "1                           ...                             \n",
      "2                           ...                             \n",
      "3                           ...                             \n",
      "4                           ...                             \n",
      "\n",
      "   Preferred text editor_XEmacs  Preferred text editor_atom.io  \\\n",
      "0                           0.0                            0.0   \n",
      "1                           0.0                            0.0   \n",
      "2                           1.0                            0.0   \n",
      "3                           0.0                            0.0   \n",
      "4                           0.0                            0.0   \n",
      "\n",
      "   Prefered IDE theme_Dark  Prefered IDE theme_I don't use an IDE  \\\n",
      "0                      1.0                                    0.0   \n",
      "1                      0.0                                    0.0   \n",
      "2                      1.0                                    0.0   \n",
      "3                      1.0                                    0.0   \n",
      "4                      1.0                                    0.0   \n",
      "\n",
      "   Prefered IDE theme_Light  \\\n",
      "0                       0.0   \n",
      "1                       1.0   \n",
      "2                       0.0   \n",
      "3                       0.0   \n",
      "4                       0.0   \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Always  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                0.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Never  \\\n",
      "0                                                0.0      \n",
      "1                                                0.0      \n",
      "2                                                0.0      \n",
      "3                                                0.0      \n",
      "4                                                0.0      \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "0                                                0.0       \n",
      "1                                                0.0       \n",
      "2                                                1.0       \n",
      "3                                                0.0       \n",
      "4                                                0.0       \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "0                                                0.0          \n",
      "1                                                0.0          \n",
      "2                                                0.0          \n",
      "3                                                0.0          \n",
      "4                                                0.0          \n",
      "\n",
      "   How often are Stack Overflow's answers helpful_Usually  \n",
      "0                                                1.0       \n",
      "1                                                1.0       \n",
      "2                                                0.0       \n",
      "3                                                1.0       \n",
      "4                                                1.0       \n",
      "\n",
      "[5 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age  Years IT / Programming Experience  \\\n",
      "count  16004.000000                       16004.000000   \n",
      "mean      28.478348                           5.839325   \n",
      "std        6.955481                           3.850501   \n",
      "min       20.000000                           1.000000   \n",
      "25%       25.000000                           2.000000   \n",
      "50%       25.000000                           6.000000   \n",
      "75%       30.000000                          11.000000   \n",
      "max       51.000000                          11.000000   \n",
      "\n",
      "       Current Lang & Tech: Android  Current Lang & Tech: Arduino  \\\n",
      "count                  16004.000000                  16004.000000   \n",
      "mean                       0.173269                      0.061110   \n",
      "std                        0.378492                      0.239539   \n",
      "min                        0.000000                      0.000000   \n",
      "25%                        0.000000                      0.000000   \n",
      "50%                        0.000000                      0.000000   \n",
      "75%                        0.000000                      0.000000   \n",
      "max                        1.000000                      1.000000   \n",
      "\n",
      "       Current Lang & Tech: AngularJS  Current Lang & Tech: C  \\\n",
      "count                    16004.000000            16004.000000   \n",
      "mean                         0.147713                0.131280   \n",
      "std                          0.354826                0.337717   \n",
      "min                          0.000000                0.000000   \n",
      "25%                          0.000000                0.000000   \n",
      "50%                          0.000000                0.000000   \n",
      "75%                          0.000000                0.000000   \n",
      "max                          1.000000                1.000000   \n",
      "\n",
      "       Current Lang & Tech: C++  Current Lang & Tech: C++11  \\\n",
      "count              16004.000000                16004.000000   \n",
      "mean                   0.171270                    0.069733   \n",
      "std                    0.376756                    0.254704   \n",
      "min                    0.000000                    0.000000   \n",
      "25%                    0.000000                    0.000000   \n",
      "50%                    0.000000                    0.000000   \n",
      "75%                    0.000000                    0.000000   \n",
      "max                    1.000000                    1.000000   \n",
      "\n",
      "       Current Lang & Tech: C#  Current Lang & Tech: Cassandra  \\\n",
      "count             16004.000000                    16004.000000   \n",
      "mean                  0.334416                        0.010122   \n",
      "std                   0.471801                        0.100103   \n",
      "min                   0.000000                        0.000000   \n",
      "25%                   0.000000                        0.000000   \n",
      "50%                   0.000000                        0.000000   \n",
      "75%                   1.000000                        0.000000   \n",
      "max                   1.000000                        1.000000   \n",
      "\n",
      "                                ...                            \\\n",
      "count                           ...                             \n",
      "mean                            ...                             \n",
      "std                             ...                             \n",
      "min                             ...                             \n",
      "25%                             ...                             \n",
      "50%                             ...                             \n",
      "75%                             ...                             \n",
      "max                             ...                             \n",
      "\n",
      "       Preferred text editor_XEmacs  Preferred text editor_atom.io  \\\n",
      "count                  16004.000000                   16004.000000   \n",
      "mean                       0.002374                       0.021995   \n",
      "std                        0.048672                       0.146670   \n",
      "min                        0.000000                       0.000000   \n",
      "25%                        0.000000                       0.000000   \n",
      "50%                        0.000000                       0.000000   \n",
      "75%                        0.000000                       0.000000   \n",
      "max                        1.000000                       1.000000   \n",
      "\n",
      "       Prefered IDE theme_Dark  Prefered IDE theme_I don't use an IDE  \\\n",
      "count             16004.000000                           16004.000000   \n",
      "mean                  0.428268                               0.059548   \n",
      "std                   0.494843                               0.236654   \n",
      "min                   0.000000                               0.000000   \n",
      "25%                   0.000000                               0.000000   \n",
      "50%                   0.000000                               0.000000   \n",
      "75%                   1.000000                               0.000000   \n",
      "max                   1.000000                               1.000000   \n",
      "\n",
      "       Prefered IDE theme_Light  \\\n",
      "count              16004.000000   \n",
      "mean                   0.343227   \n",
      "std                    0.474801   \n",
      "min                    0.000000   \n",
      "25%                    0.000000   \n",
      "50%                    0.000000   \n",
      "75%                    1.000000   \n",
      "max                    1.000000   \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Always  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.079668       \n",
      "std                                             0.270786       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Never  \\\n",
      "count                                       16004.000000      \n",
      "mean                                            0.000812      \n",
      "std                                             0.028490      \n",
      "min                                             0.000000      \n",
      "25%                                             0.000000      \n",
      "50%                                             0.000000      \n",
      "75%                                             0.000000      \n",
      "max                                             1.000000      \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Rarely  \\\n",
      "count                                       16004.000000       \n",
      "mean                                            0.003687       \n",
      "std                                             0.060607       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             0.000000       \n",
      "75%                                             0.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Sometimes  \\\n",
      "count                                       16004.000000          \n",
      "mean                                            0.108660          \n",
      "std                                             0.311222          \n",
      "min                                             0.000000          \n",
      "25%                                             0.000000          \n",
      "50%                                             0.000000          \n",
      "75%                                             0.000000          \n",
      "max                                             1.000000          \n",
      "\n",
      "       How often are Stack Overflow's answers helpful_Usually  \n",
      "count                                       16004.000000       \n",
      "mean                                            0.634404       \n",
      "std                                             0.481612       \n",
      "min                                             0.000000       \n",
      "25%                                             0.000000       \n",
      "50%                                             1.000000       \n",
      "75%                                             1.000000       \n",
      "max                                             1.000000       \n",
      "\n",
      "[8 rows x 347 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-17a6f4e5f63b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, method, min_periods)\u001b[0m\n\u001b[1;32m   4554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pearson'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4556\u001b[0;31m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_algos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_float64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4557\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'spearman'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4558\u001b[0m             correl = _algos.nancorr_spearman(com._ensure_float64(mat),\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in data.corr():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "rfe = RFE(model, 50,2)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "X_train = rfe.transform(X_train)\n",
    "X_test = rfe.transform(X_test)\n",
    "#rfe_preds = rfe.predict(X_test)\n",
    "#print mean_squared_error(y_test,rfe_preds)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[160]\n",
    "}\n",
    "modelETC = ExtraTreesRegressor()\n",
    "gridETC = GridSearchCV(modelETC, param_grid=parameters,scoring = scoring, cv=5, refit = 'mean',verbose=1)\n",
    "gridETC.fit(X_train,y_train)\n",
    "print(gridETC.best_params_)\n",
    "#print(modelETC.feature_importances_)\n",
    "etc_preds = gridETC.predict(X_test)\n",
    "print (mean_squared_error(y_test,etc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print mean_squared_error(y_test,etc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.471834236419676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7feeac38f990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAEZCAYAAADbteACAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPN9TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee75f0b990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "#gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "#gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "#xgb_preds = gridXGB.predict(X_test)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_model._Booster.save_model('output2015.model')\n",
    "xgb.plot_importance(xgb_model,max_num_features = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.33352], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model._Booster.predict(xgb.DMatrix([0.0,0.0,0.0,0.0], feature_names=[u'Compensation: midpoint', u'Purchasing Power_I have no say in purchasing what I need or want at work', u'Remote Status_Never', u'Changed Jobs in last 12 Months']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'booster':['gbtree'],# dart is nice but far too slow\n",
    "              'learning_rate': [.01], #\n",
    "              'max_depth': [7],#1,3,5,6,7,8,10\n",
    "              'min_child_weight': [8],#1,3,5,7,8,9,10\n",
    "              'reg_alpha':[.01],#.0001,.001,.01,.1,1,10\n",
    "              'silent': [0],\n",
    "              'subsample': [.6],#.6,.7,.8,.9\n",
    "              'gamma':[.001],#.1,.01,.001.,.005,0\n",
    "              'colsample_bytree': [.8],#.6,.7,.8,.9\n",
    "              'n_estimators': [10000], \n",
    "              'seed': [1337]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n",
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=21.1min\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 21.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=25.0min\n",
      "[CV] reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree \n",
      "[CV]  reg_alpha=0.01, colsample_bytree=0.8, silent=0, learning_rate=0.01, min_child_weight=8, n_estimators=10000, subsample=0.6, seed=1337, max_depth=7, gamma=0.001, booster=gbtree, total=21.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 68.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2666836788652214\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "gridXGB = GridSearchCV(xgb_model, param_grid=parameters,scoring = scoring, cv=3, verbose=2, refit = 'mean')\n",
    "gridXGB.fit(X_train, y_train,eval_metric='rmse')\n",
    "#print(gridXGB.best_params_)\n",
    "xgb_preds = gridXGB.predict(X_test)\n",
    "#xgb_model.fit(X_train, y_train)\n",
    "#xgb_preds = xgb_model.predict(X_test)\n",
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n",
    "#xgb_copy = list(xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gridXGB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fed3b56b9277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridXGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gridXGB' is not defined"
     ]
    }
   ],
   "source": [
    "print(gridXGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.322300794571225\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,xgb_preds)**.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.492633136249195\n"
     ]
    }
   ],
   "source": [
    "print (sum(y_test)/len(y_test))\n",
    "print (sum(xgb_preds)/len(xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2432018773173352\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[1],\n",
    "    'learning_rate':[.1]\n",
    "   # 'base_estimator':[ExtraTreesClassifier(160,class_weight='balanced')]\n",
    "   # 'base_estimator':[grid]\n",
    "}\n",
    "modelABC = AdaBoostRegressor(base_estimator=xgb.XGBRegressor(reg_alpha=.01, colsample_bytree=.8, \n",
    "                                silent=0, learning_rate=.01, min_child_weight=8, n_estimators=10000, \n",
    "                                            subsample=.6, max_depth=7,gamma=.001,booster='gbtree'),n_estimators = 20)\n",
    "#gridABC = GridSearchCV(modelABC, param_grid=parameters,scoring = scoring, cv=2, refit = 'mean',verbose=2)\n",
    "modelABC.fit(X_train,y_train)\n",
    "abc_preds = modelABC.predict(X_test)\n",
    "print (mean_squared_error(y_test,abc_preds)**.5)\n",
    "#print(gridABC.best_params_)\n",
    "#print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clipS(preds):\n",
    "    for pred, element in enumerate(preds):\n",
    "        if preds[pred] < 1.25:\n",
    "            preds[pred] = 0\n",
    "        elif preds[pred] < 3.75:\n",
    "            preds[pred] = 2.5\n",
    "        elif  preds[pred] < 6.25:\n",
    "            preds[pred] = 5\n",
    "        elif  preds[pred] < 8.75:\n",
    "            preds[pred] = 7.5\n",
    "        else: \n",
    "            preds[pred] = 10\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.286079 7.5 10.0\n",
      "7.927208 7.5 7.5\n",
      "6.8665676 7.5 7.5\n",
      "7.365894 7.5 7.5\n",
      "8.49939 7.5 5.0\n",
      "7.1254463 7.5 5.0\n",
      "6.702565 7.5 7.5\n",
      "5.842753 5 7.5\n",
      "8.738859 7.5 10.0\n",
      "7.841649 7.5 10.0\n",
      "6.74351 7.5 7.5\n",
      "7.807215 7.5 7.5\n",
      "9.261417 10 7.5\n",
      "7.109841 7.5 5.0\n",
      "6.8010564 7.5 7.5\n",
      "7.597346 7.5 10.0\n",
      "6.9410725 7.5 2.5\n",
      "6.5449824 7.5 0.0\n",
      "7.402582 7.5 5.0\n",
      "6.431654 7.5 0.0\n",
      "7.1956844 7.5 7.5\n",
      "7.6999984 7.5 10.0\n",
      "6.1977854 5 2.5\n",
      "7.982983 7.5 10.0\n",
      "7.190724 7.5 7.5\n",
      "6.7932687 7.5 10.0\n",
      "8.369915 7.5 7.5\n",
      "8.421787 7.5 7.5\n",
      "7.026611 7.5 7.5\n",
      "6.857605 7.5 7.5\n",
      "8.973689 10 10.0\n",
      "6.7475266 7.5 2.5\n",
      "8.897934 10 7.5\n",
      "7.8295035 7.5 10.0\n",
      "9.146121 10 10.0\n",
      "8.495934 7.5 7.5\n",
      "6.728901 7.5 7.5\n",
      "7.36117 7.5 10.0\n",
      "8.701159 7.5 10.0\n",
      "7.6483 7.5 10.0\n",
      "7.262645 7.5 7.5\n",
      "7.3512554 7.5 7.5\n",
      "7.0285273 7.5 10.0\n",
      "8.729461 7.5 7.5\n",
      "7.8325706 7.5 7.5\n",
      "8.742565 7.5 10.0\n",
      "6.331672 7.5 0.0\n",
      "8.884819 10 7.5\n",
      "7.004472 7.5 7.5\n",
      "7.0543513 7.5 5.0\n",
      "7.403653 7.5 10.0\n",
      "7.0553303 7.5 7.5\n",
      "7.1007104 7.5 7.5\n",
      "4.405138 5 5.0\n",
      "6.3311124 7.5 5.0\n",
      "7.363051 7.5 5.0\n",
      "6.0551515 5 2.5\n",
      "9.117585 10 10.0\n",
      "9.358985 10 10.0\n",
      "5.541956 5 2.5\n",
      "8.615711 7.5 10.0\n",
      "9.012321 10 7.5\n",
      "6.0414762 5 7.5\n",
      "8.579151 7.5 10.0\n",
      "8.030192 7.5 7.5\n",
      "8.855805 10 10.0\n",
      "8.832175 10 7.5\n",
      "7.6058855 7.5 5.0\n",
      "7.199923 7.5 7.5\n",
      "8.900732 10 10.0\n",
      "8.324468 7.5 10.0\n",
      "8.5223 7.5 7.5\n",
      "9.109856 10 10.0\n",
      "6.486567 7.5 2.5\n",
      "8.735019 7.5 10.0\n",
      "7.5179343 7.5 5.0\n",
      "3.6571748 2.5 2.5\n",
      "6.286259 7.5 7.5\n",
      "6.783825 7.5 2.5\n",
      "6.983751 7.5 7.5\n",
      "8.085805 7.5 2.5\n",
      "6.5495825 7.5 10.0\n",
      "7.5467052 7.5 5.0\n",
      "9.301053 10 10.0\n",
      "6.9998946 7.5 7.5\n",
      "6.4746428 7.5 7.5\n",
      "8.327482 7.5 7.5\n",
      "7.71578 7.5 7.5\n",
      "8.524395 7.5 7.5\n",
      "6.8809905 7.5 7.5\n",
      "7.17428 7.5 7.5\n",
      "6.652444 7.5 7.5\n",
      "9.1943655 10 10.0\n",
      "7.41816 7.5 2.5\n",
      "8.574999 7.5 10.0\n",
      "9.110284 10 10.0\n",
      "7.2170534 7.5 5.0\n",
      "6.7920656 7.5 7.5\n",
      "7.6146593 7.5 2.5\n",
      "7.6355267 7.5 10.0\n",
      "7.725098 7.5 7.5\n",
      "9.835834 10 10.0\n",
      "8.92887 10 7.5\n",
      "7.7761097 7.5 5.0\n",
      "7.411673 7.5 10.0\n",
      "6.9068995 7.5 10.0\n",
      "4.706843 5 5.0\n",
      "6.7363033 7.5 10.0\n",
      "7.4693766 7.5 10.0\n",
      "6.62778 7.5 10.0\n",
      "8.363657 7.5 5.0\n",
      "7.438783 7.5 7.5\n",
      "8.178367 7.5 10.0\n",
      "6.381085 7.5 2.5\n",
      "8.266884 7.5 10.0\n",
      "8.277149 7.5 7.5\n",
      "7.65782 7.5 10.0\n",
      "8.929945 10 10.0\n",
      "9.464274 10 10.0\n",
      "7.760153 7.5 7.5\n",
      "7.0397315 7.5 7.5\n",
      "7.167578 7.5 7.5\n",
      "6.8036776 7.5 5.0\n",
      "7.7189155 7.5 7.5\n",
      "7.5646496 7.5 2.5\n",
      "8.044349 7.5 5.0\n",
      "7.171184 7.5 7.5\n",
      "8.161463 7.5 7.5\n",
      "7.9289637 7.5 10.0\n",
      "7.277117 7.5 10.0\n",
      "6.609256 7.5 2.5\n",
      "5.275037 5 5.0\n",
      "7.0832453 7.5 10.0\n",
      "9.117787 10 7.5\n",
      "7.603249 7.5 7.5\n",
      "6.663688 7.5 7.5\n",
      "4.723162 5 2.5\n",
      "7.6154575 7.5 10.0\n",
      "8.043401 7.5 10.0\n",
      "8.383421 7.5 7.5\n",
      "6.9304047 7.5 5.0\n",
      "8.473858 7.5 10.0\n",
      "7.591846 7.5 7.5\n",
      "7.1693206 7.5 0.0\n",
      "7.0171704 7.5 2.5\n",
      "8.716563 7.5 10.0\n",
      "6.279488 7.5 7.5\n",
      "7.7324343 7.5 7.5\n",
      "7.218708 7.5 5.0\n",
      "7.526625 7.5 7.5\n",
      "5.372349 5 5.0\n",
      "8.66315 7.5 10.0\n",
      "7.438694 7.5 7.5\n",
      "7.6925898 7.5 10.0\n",
      "7.1397734 7.5 7.5\n",
      "7.101089 7.5 7.5\n",
      "8.670513 7.5 10.0\n",
      "7.135246 7.5 10.0\n",
      "7.6819215 7.5 2.5\n",
      "8.511471 7.5 5.0\n",
      "6.893649 7.5 7.5\n",
      "7.893755 7.5 10.0\n",
      "8.673151 7.5 7.5\n",
      "7.3726406 7.5 7.5\n",
      "5.202962 5 0.0\n",
      "7.3817315 7.5 7.5\n",
      "7.201135 7.5 10.0\n",
      "7.397476 7.5 7.5\n",
      "4.704034 5 5.0\n",
      "6.9775224 7.5 7.5\n",
      "8.79597 10 10.0\n",
      "7.282974 7.5 10.0\n",
      "8.459864 7.5 10.0\n",
      "7.0988016 7.5 7.5\n",
      "5.45099 5 7.5\n",
      "6.903828 7.5 2.5\n",
      "7.262401 7.5 7.5\n",
      "5.0595374 5 2.5\n",
      "7.8998914 7.5 7.5\n",
      "8.004835 7.5 7.5\n",
      "5.8966293 5 5.0\n",
      "4.485405 5 2.5\n",
      "5.643121 5 2.5\n",
      "8.961643 10 10.0\n",
      "7.5989194 7.5 10.0\n",
      "6.7831264 7.5 5.0\n",
      "8.754775 10 10.0\n",
      "8.347086 7.5 7.5\n",
      "6.6628594 7.5 2.5\n",
      "7.0336676 7.5 7.5\n",
      "7.366872 7.5 7.5\n",
      "6.7191534 7.5 7.5\n",
      "7.8934665 7.5 10.0\n",
      "9.191255 10 10.0\n",
      "7.557719 7.5 7.5\n",
      "6.9939127 7.5 7.5\n",
      "6.472245 7.5 5.0\n",
      "7.3428783 7.5 2.5\n",
      "6.4768124 7.5 2.5\n",
      "5.3114104 5 7.5\n",
      "7.6250925 7.5 7.5\n",
      "7.5127063 7.5 10.0\n",
      "7.503521 7.5 7.5\n",
      "8.132802 7.5 7.5\n",
      "7.9164486 7.5 7.5\n",
      "7.0198107 7.5 7.5\n",
      "7.0506005 7.5 2.5\n",
      "8.404212 7.5 7.5\n",
      "7.6292434 7.5 7.5\n",
      "6.6520014 7.5 10.0\n",
      "8.912238 10 10.0\n",
      "8.9411745 10 10.0\n",
      "7.1848226 7.5 5.0\n",
      "5.805557 5 5.0\n",
      "7.137453 7.5 7.5\n",
      "7.3466763 7.5 7.5\n",
      "7.4282475 7.5 10.0\n",
      "5.8565474 5 10.0\n",
      "6.839623 7.5 7.5\n",
      "7.060577 7.5 7.5\n",
      "9.138858 10 10.0\n",
      "6.35038 7.5 5.0\n",
      "7.7695136 7.5 10.0\n",
      "6.0542393 5 7.5\n",
      "7.2977853 7.5 10.0\n",
      "6.835838 7.5 5.0\n",
      "7.5787945 7.5 7.5\n",
      "8.911916 10 5.0\n",
      "7.544947 7.5 5.0\n",
      "8.094479 7.5 10.0\n",
      "8.853425 10 10.0\n",
      "8.564133 7.5 7.5\n",
      "7.4951167 7.5 2.5\n",
      "7.7497053 7.5 7.5\n",
      "6.557948 7.5 7.5\n",
      "7.6053023 7.5 10.0\n",
      "8.348433 7.5 7.5\n",
      "6.014029 5 5.0\n",
      "7.017941 7.5 7.5\n",
      "5.64851 5 10.0\n",
      "6.886149 7.5 5.0\n",
      "6.4640403 7.5 7.5\n",
      "5.3906755 5 10.0\n",
      "7.2654233 7.5 10.0\n",
      "9.335668 10 10.0\n",
      "6.481755 7.5 2.5\n",
      "6.017241 5 7.5\n",
      "8.043382 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "6.560203 7.5 7.5\n",
      "8.62571 7.5 5.0\n",
      "8.877778 10 10.0\n",
      "7.7104654 7.5 7.5\n",
      "7.369749 7.5 7.5\n",
      "8.967628 10 10.0\n",
      "5.2159295 5 2.5\n",
      "8.635881 7.5 7.5\n",
      "7.1446714 7.5 2.5\n",
      "7.4312387 7.5 2.5\n",
      "6.711874 7.5 10.0\n",
      "8.671534 7.5 7.5\n",
      "7.5660887 7.5 2.5\n",
      "5.8431525 5 5.0\n",
      "6.714745 7.5 7.5\n",
      "7.6558537 7.5 10.0\n",
      "7.377463 7.5 7.5\n",
      "4.7338557 5 5.0\n",
      "9.316233 10 7.5\n",
      "7.186562 7.5 7.5\n",
      "8.721661 7.5 10.0\n",
      "6.9716315 7.5 10.0\n",
      "7.6170654 7.5 10.0\n",
      "4.8393083 5 7.5\n",
      "7.38621 7.5 10.0\n",
      "7.297359 7.5 7.5\n",
      "6.9779367 7.5 7.5\n",
      "8.299047 7.5 7.5\n",
      "8.64231 7.5 10.0\n",
      "9.119448 10 7.5\n",
      "4.38325 5 2.5\n",
      "9.018082 10 10.0\n",
      "7.2247763 7.5 10.0\n",
      "6.4251723 7.5 7.5\n",
      "7.1317353 7.5 10.0\n",
      "8.600432 7.5 10.0\n",
      "7.3213086 7.5 10.0\n",
      "7.583395 7.5 5.0\n",
      "8.4304905 7.5 10.0\n",
      "7.1937423 7.5 10.0\n",
      "7.2638855 7.5 7.5\n",
      "4.718356 5 2.5\n",
      "8.542231 7.5 7.5\n",
      "8.715064 7.5 10.0\n",
      "7.007884 7.5 7.5\n",
      "7.155012 7.5 10.0\n",
      "6.0820823 5 2.5\n",
      "8.476149 7.5 10.0\n",
      "6.3996363 7.5 2.5\n",
      "6.704749 7.5 5.0\n",
      "7.937782 7.5 7.5\n",
      "6.222191 5 0.0\n",
      "6.969253 7.5 7.5\n",
      "8.322651 7.5 5.0\n",
      "6.794183 7.5 7.5\n",
      "8.821465 10 10.0\n",
      "8.9155245 10 10.0\n",
      "9.655393 10 10.0\n",
      "7.691099 7.5 7.5\n",
      "8.331469 7.5 2.5\n",
      "9.57851 10 10.0\n",
      "7.8688903 7.5 10.0\n",
      "7.268002 7.5 5.0\n",
      "4.363471 5 7.5\n",
      "7.0442104 7.5 7.5\n",
      "7.034379 7.5 7.5\n",
      "8.409029 7.5 5.0\n",
      "7.3680425 7.5 10.0\n",
      "4.837284 5 2.5\n",
      "8.177069 7.5 10.0\n",
      "7.5692315 7.5 10.0\n",
      "6.857407 7.5 5.0\n",
      "8.328121 7.5 7.5\n",
      "7.276381 7.5 5.0\n",
      "7.601217 7.5 10.0\n",
      "7.3337727 7.5 7.5\n",
      "6.951588 7.5 7.5\n",
      "8.452675 7.5 5.0\n",
      "7.929223 7.5 5.0\n",
      "7.182568 7.5 7.5\n",
      "6.8402877 7.5 10.0\n",
      "6.775493 7.5 5.0\n",
      "6.1471343 5 10.0\n",
      "7.3068666 7.5 7.5\n",
      "6.7196417 7.5 7.5\n",
      "8.756385 10 5.0\n",
      "7.2793436 7.5 10.0\n",
      "5.000211 5 10.0\n",
      "6.7214365 7.5 10.0\n",
      "7.6406875 7.5 10.0\n",
      "7.3126354 7.5 7.5\n",
      "9.401726 10 10.0\n",
      "9.104323 10 10.0\n",
      "8.366888 7.5 7.5\n",
      "4.901815 5 5.0\n",
      "8.21958 7.5 10.0\n",
      "7.9752884 7.5 2.5\n",
      "7.4142094 7.5 7.5\n",
      "7.7659926 7.5 10.0\n",
      "8.70406 7.5 10.0\n",
      "7.4904323 7.5 7.5\n",
      "6.7746053 7.5 7.5\n",
      "6.530846 7.5 7.5\n",
      "8.04063 7.5 5.0\n",
      "8.221747 7.5 7.5\n",
      "7.400912 7.5 10.0\n",
      "7.7718835 7.5 7.5\n",
      "7.148913 7.5 2.5\n",
      "8.17844 7.5 10.0\n",
      "9.469219 10 10.0\n",
      "7.73892 7.5 10.0\n",
      "7.133104 7.5 7.5\n",
      "6.705155 7.5 5.0\n",
      "6.997345 7.5 7.5\n",
      "8.586482 7.5 10.0\n",
      "8.821429 10 7.5\n",
      "7.6046114 7.5 5.0\n",
      "7.3128233 7.5 10.0\n",
      "8.714591 7.5 7.5\n",
      "7.660843 7.5 7.5\n",
      "8.609051 7.5 7.5\n",
      "6.9730186 7.5 5.0\n",
      "8.670081 7.5 10.0\n",
      "8.079895 7.5 10.0\n",
      "7.9215693 7.5 7.5\n",
      "5.7190385 5 7.5\n",
      "9.331474 10 10.0\n",
      "6.8284993 7.5 7.5\n",
      "8.0086975 7.5 10.0\n",
      "7.02293 7.5 10.0\n",
      "7.0213385 7.5 7.5\n",
      "6.6029406 7.5 10.0\n",
      "7.4014792 7.5 10.0\n",
      "7.298542 7.5 0.0\n",
      "7.619708 7.5 5.0\n",
      "7.1979895 7.5 10.0\n",
      "7.448646 7.5 7.5\n",
      "8.440142 7.5 7.5\n",
      "6.9769835 7.5 7.5\n",
      "6.138256 5 7.5\n",
      "7.2245126 7.5 5.0\n",
      "6.527871 7.5 7.5\n",
      "6.8050394 7.5 7.5\n",
      "6.3317323 7.5 2.5\n",
      "6.772269 7.5 7.5\n",
      "8.76172 10 7.5\n",
      "7.0657053 7.5 7.5\n",
      "5.377063 5 10.0\n",
      "8.594167 7.5 5.0\n",
      "7.422571 7.5 10.0\n",
      "6.9281945 7.5 7.5\n",
      "5.144563 5 5.0\n",
      "7.5175185 7.5 5.0\n",
      "6.9254336 7.5 10.0\n",
      "7.3157744 7.5 7.5\n",
      "7.2429156 7.5 7.5\n",
      "4.8302307 5 2.5\n",
      "5.554353 5 2.5\n",
      "7.481337 7.5 10.0\n",
      "7.421533 7.5 7.5\n",
      "8.007649 7.5 10.0\n",
      "7.350526 7.5 2.5\n",
      "9.06644 10 10.0\n",
      "7.250871 7.5 10.0\n",
      "7.9431186 7.5 10.0\n",
      "6.920812 7.5 10.0\n",
      "6.753942 7.5 10.0\n",
      "8.611946 7.5 7.5\n",
      "7.4769297 7.5 5.0\n",
      "7.192379 7.5 10.0\n",
      "5.9402156 5 2.5\n",
      "8.96776 10 10.0\n",
      "6.6662545 7.5 2.5\n",
      "7.4262714 7.5 2.5\n",
      "8.85153 10 7.5\n",
      "8.936792 10 7.5\n",
      "7.3628335 7.5 7.5\n",
      "5.7974925 5 7.5\n",
      "7.203161 7.5 0.0\n",
      "6.0014415 5 7.5\n",
      "7.666558 7.5 7.5\n",
      "7.287009 7.5 7.5\n",
      "7.173406 7.5 5.0\n",
      "7.7139025 7.5 10.0\n",
      "6.0934787 5 7.5\n",
      "7.2690234 7.5 5.0\n",
      "8.296945 7.5 10.0\n",
      "7.9280605 7.5 7.5\n",
      "7.032693 7.5 2.5\n",
      "8.463832 7.5 10.0\n",
      "7.1000605 7.5 7.5\n",
      "8.899751 10 10.0\n",
      "7.7113748 7.5 7.5\n",
      "8.2399845 7.5 10.0\n",
      "8.778484 10 10.0\n",
      "7.807631 7.5 10.0\n",
      "7.206174 7.5 2.5\n",
      "8.808467 10 7.5\n",
      "4.1308002 5 2.5\n",
      "7.0482454 7.5 7.5\n",
      "8.931331 10 0.0\n",
      "7.2467513 7.5 7.5\n",
      "7.292097 7.5 7.5\n",
      "6.701726 7.5 7.5\n",
      "9.159873 10 7.5\n",
      "8.311512 7.5 10.0\n",
      "7.8484197 7.5 10.0\n",
      "7.418136 7.5 7.5\n",
      "6.9726777 7.5 10.0\n",
      "7.6918173 7.5 10.0\n",
      "6.9782104 7.5 7.5\n",
      "7.405746 7.5 7.5\n",
      "6.3513823 7.5 7.5\n",
      "7.091888 7.5 7.5\n",
      "9.166574 10 10.0\n",
      "7.951657 7.5 10.0\n",
      "6.0477605 5 2.5\n",
      "9.185785 10 10.0\n",
      "5.3644524 5 7.5\n",
      "7.0279727 7.5 7.5\n",
      "8.721304 7.5 10.0\n",
      "5.368986 5 0.0\n",
      "7.10423 7.5 7.5\n",
      "7.692889 7.5 10.0\n",
      "7.1589327 7.5 2.5\n",
      "9.070053 10 10.0\n",
      "6.972535 7.5 7.5\n",
      "5.3782387 5 5.0\n",
      "7.221765 7.5 7.5\n",
      "7.29352 7.5 7.5\n",
      "7.9121714 7.5 10.0\n",
      "6.5349183 7.5 5.0\n",
      "8.577447 7.5 10.0\n",
      "9.000124 10 10.0\n",
      "9.061013 10 10.0\n",
      "6.8140445 7.5 5.0\n",
      "8.715182 7.5 7.5\n",
      "7.6654744 7.5 7.5\n",
      "9.053612 10 10.0\n",
      "6.8768363 7.5 7.5\n",
      "7.7563195 7.5 7.5\n",
      "5.586463 5 5.0\n",
      "7.1503057 7.5 7.5\n",
      "7.8367867 7.5 7.5\n",
      "8.792763 10 10.0\n",
      "7.0504675 7.5 7.5\n",
      "7.165014 7.5 7.5\n",
      "7.01019 7.5 2.5\n",
      "6.183681 5 7.5\n",
      "7.369988 7.5 10.0\n",
      "8.126756 7.5 7.5\n",
      "6.9977584 7.5 2.5\n",
      "8.87244 10 10.0\n",
      "6.3783193 7.5 7.5\n",
      "8.659013 7.5 10.0\n",
      "6.876874 7.5 5.0\n",
      "9.120095 10 10.0\n",
      "7.640631 7.5 7.5\n",
      "7.764863 7.5 5.0\n",
      "7.984157 7.5 5.0\n",
      "6.3734446 7.5 10.0\n",
      "9.266925 10 10.0\n",
      "7.1606984 7.5 7.5\n",
      "7.230636 7.5 7.5\n",
      "7.7491655 7.5 7.5\n",
      "8.973715 10 7.5\n",
      "6.57913 7.5 7.5\n",
      "6.8133802 7.5 7.5\n",
      "7.585878 7.5 5.0\n",
      "6.0682187 5 2.5\n",
      "7.4714656 7.5 10.0\n",
      "8.99028 10 10.0\n",
      "6.096297 5 7.5\n",
      "7.929471 7.5 10.0\n",
      "6.6532526 7.5 7.5\n",
      "7.255486 7.5 7.5\n",
      "7.121804 7.5 7.5\n",
      "8.741817 7.5 10.0\n",
      "6.4791694 7.5 10.0\n",
      "7.16204 7.5 10.0\n",
      "7.40656 7.5 10.0\n",
      "8.835292 10 10.0\n",
      "6.354284 7.5 2.5\n",
      "7.7022524 7.5 10.0\n",
      "7.180073 7.5 7.5\n",
      "7.618295 7.5 5.0\n",
      "9.011094 10 10.0\n",
      "6.4088025 7.5 7.5\n",
      "6.851756 7.5 10.0\n",
      "6.524576 7.5 5.0\n",
      "6.737183 7.5 10.0\n",
      "7.736432 7.5 10.0\n",
      "8.675886 7.5 10.0\n",
      "7.5902305 7.5 7.5\n",
      "6.956921 7.5 7.5\n",
      "7.0642276 7.5 10.0\n",
      "7.7774615 7.5 10.0\n",
      "8.840522 10 10.0\n",
      "9.018677 10 10.0\n",
      "7.1048713 7.5 10.0\n",
      "7.5425825 7.5 10.0\n",
      "5.916163 5 10.0\n",
      "6.2203655 5 7.5\n",
      "9.624352 10 10.0\n",
      "5.7014008 5 7.5\n",
      "6.383533 7.5 5.0\n",
      "6.731 7.5 2.5\n",
      "8.903315 10 10.0\n",
      "7.2506924 7.5 10.0\n",
      "7.6655774 7.5 7.5\n",
      "7.8781333 7.5 7.5\n",
      "7.3385854 7.5 10.0\n",
      "7.295913 7.5 10.0\n",
      "7.059357 7.5 5.0\n",
      "8.175743 7.5 7.5\n",
      "7.035736 7.5 7.5\n",
      "9.075741 10 10.0\n",
      "8.659208 7.5 7.5\n",
      "7.261086 7.5 5.0\n",
      "9.128366 10 10.0\n",
      "9.201667 10 10.0\n",
      "6.909012 7.5 7.5\n",
      "8.563478 7.5 10.0\n",
      "7.7417493 7.5 7.5\n",
      "6.598126 7.5 10.0\n",
      "6.838928 7.5 7.5\n",
      "4.8229856 5 5.0\n",
      "6.9030147 7.5 7.5\n",
      "4.448558 5 7.5\n",
      "7.3287625 7.5 7.5\n",
      "8.58215 7.5 7.5\n",
      "6.9423847 7.5 7.5\n",
      "7.1722794 7.5 5.0\n",
      "7.8454676 7.5 7.5\n",
      "8.680428 7.5 7.5\n",
      "8.819686 10 7.5\n",
      "7.5887103 7.5 10.0\n",
      "9.291523 10 7.5\n",
      "8.94677 10 10.0\n",
      "7.8365974 7.5 10.0\n",
      "7.1992483 7.5 10.0\n",
      "7.6480193 7.5 10.0\n",
      "6.431595 7.5 7.5\n",
      "6.666589 7.5 2.5\n",
      "7.5594454 7.5 7.5\n",
      "7.0675583 7.5 7.5\n",
      "8.671326 7.5 10.0\n",
      "8.293993 7.5 7.5\n",
      "6.065326 5 10.0\n",
      "8.743233 7.5 10.0\n",
      "8.602865 7.5 10.0\n",
      "7.545047 7.5 5.0\n",
      "6.366297 7.5 2.5\n",
      "6.999705 7.5 7.5\n",
      "7.727626 7.5 7.5\n",
      "7.2649617 7.5 5.0\n",
      "6.262243 7.5 2.5\n",
      "6.624135 7.5 5.0\n",
      "8.509215 7.5 7.5\n",
      "7.9518967 7.5 10.0\n",
      "9.159919 10 10.0\n",
      "6.3651114 7.5 2.5\n",
      "7.2806845 7.5 10.0\n",
      "7.0947695 7.5 5.0\n",
      "4.6172037 5 0.0\n",
      "9.0803995 10 10.0\n",
      "6.4334626 7.5 5.0\n",
      "7.1046987 7.5 10.0\n",
      "8.443733 7.5 10.0\n",
      "8.841903 10 10.0\n",
      "8.612307 7.5 7.5\n",
      "8.098684 7.5 10.0\n",
      "6.9010196 7.5 2.5\n",
      "6.1703377 5 5.0\n",
      "7.5871663 7.5 7.5\n",
      "7.388483 7.5 7.5\n",
      "9.196045 10 10.0\n",
      "7.2582064 7.5 7.5\n",
      "7.027735 7.5 7.5\n",
      "7.087882 7.5 10.0\n",
      "8.592028 7.5 10.0\n",
      "7.827072 7.5 10.0\n",
      "7.3170323 7.5 7.5\n",
      "7.033129 7.5 7.5\n",
      "6.7714667 7.5 7.5\n",
      "6.588135 7.5 2.5\n",
      "6.9748836 7.5 2.5\n",
      "8.837019 10 7.5\n",
      "7.3911443 7.5 7.5\n",
      "7.607795 7.5 10.0\n",
      "9.386492 10 10.0\n",
      "7.8328876 7.5 7.5\n",
      "7.1335373 7.5 7.5\n",
      "6.209868 5 7.5\n",
      "7.228551 7.5 7.5\n",
      "7.3156276 7.5 7.5\n",
      "7.9866543 7.5 10.0\n",
      "7.741124 7.5 7.5\n",
      "7.191593 7.5 7.5\n",
      "9.061615 10 10.0\n",
      "4.8184996 5 2.5\n",
      "7.2674165 7.5 2.5\n",
      "6.645566 7.5 10.0\n",
      "7.947404 7.5 7.5\n",
      "8.051508 7.5 10.0\n",
      "5.444333 5 2.5\n",
      "7.182348 7.5 7.5\n",
      "7.5451245 7.5 7.5\n",
      "8.9796 10 7.5\n",
      "7.307333 7.5 10.0\n",
      "8.824837 10 7.5\n",
      "8.7856865 10 7.5\n",
      "4.7115307 5 7.5\n",
      "7.3474936 7.5 0.0\n",
      "9.230823 10 10.0\n",
      "7.1721816 7.5 0.0\n",
      "9.018509 10 10.0\n",
      "6.925648 7.5 7.5\n",
      "7.803427 7.5 10.0\n",
      "9.032519 10 7.5\n",
      "6.853879 7.5 7.5\n",
      "7.3689675 7.5 10.0\n",
      "6.5305805 7.5 10.0\n",
      "7.9466605 7.5 7.5\n",
      "4.0821304 5 10.0\n",
      "5.524874 5 7.5\n",
      "6.761877 7.5 7.5\n",
      "7.3257155 7.5 10.0\n",
      "7.274838 7.5 7.5\n",
      "9.0077305 10 10.0\n",
      "5.556011 5 2.5\n",
      "7.233306 7.5 7.5\n",
      "7.492793 7.5 7.5\n",
      "9.328015 10 10.0\n",
      "5.844181 5 2.5\n",
      "7.709036 7.5 10.0\n",
      "4.6909084 5 2.5\n",
      "8.109215 7.5 7.5\n",
      "8.120611 7.5 7.5\n",
      "6.494277 7.5 10.0\n",
      "8.475326 7.5 10.0\n",
      "8.678416 7.5 10.0\n",
      "7.4901304 7.5 2.5\n",
      "7.6018887 7.5 7.5\n",
      "7.0528555 7.5 7.5\n",
      "7.511163 7.5 10.0\n",
      "6.9843717 7.5 10.0\n",
      "7.0571322 7.5 10.0\n",
      "7.2764153 7.5 5.0\n",
      "8.238143 7.5 5.0\n",
      "6.9302516 7.5 5.0\n",
      "7.0490346 7.5 10.0\n",
      "7.5759425 7.5 10.0\n",
      "7.4752707 7.5 7.5\n",
      "9.279785 10 7.5\n",
      "7.3576407 7.5 10.0\n",
      "9.222765 10 7.5\n",
      "3.7707024 5 2.5\n",
      "6.655712 7.5 2.5\n",
      "5.809638 5 10.0\n",
      "8.82486 10 7.5\n",
      "5.3256445 5 7.5\n",
      "7.6264615 7.5 10.0\n",
      "7.997728 7.5 10.0\n",
      "6.646442 7.5 7.5\n",
      "7.897709 7.5 10.0\n",
      "7.041987 7.5 7.5\n",
      "7.296846 7.5 10.0\n",
      "6.7226424 7.5 7.5\n",
      "9.206126 10 10.0\n",
      "8.828104 10 10.0\n",
      "6.2329283 5 7.5\n",
      "8.983676 10 10.0\n",
      "5.994786 5 7.5\n",
      "6.218967 5 5.0\n",
      "5.8920155 5 5.0\n",
      "6.0475736 5 10.0\n",
      "7.211736 7.5 5.0\n",
      "8.815203 10 7.5\n",
      "7.504905 7.5 7.5\n",
      "8.741962 7.5 10.0\n",
      "8.915806 10 10.0\n",
      "7.541846 7.5 7.5\n",
      "3.4106596 2.5 5.0\n",
      "8.79356 10 10.0\n",
      "8.566177 7.5 7.5\n",
      "8.124886 7.5 2.5\n",
      "6.979462 7.5 7.5\n",
      "8.853748 10 10.0\n",
      "8.997233 10 7.5\n",
      "7.0251513 7.5 7.5\n",
      "7.8392673 7.5 10.0\n",
      "7.8085976 7.5 7.5\n",
      "8.683331 7.5 10.0\n",
      "8.896036 10 7.5\n",
      "8.994874 10 10.0\n",
      "7.89607 7.5 10.0\n",
      "8.616039 7.5 10.0\n",
      "8.097696 7.5 7.5\n",
      "9.043376 10 7.5\n",
      "6.682789 7.5 5.0\n",
      "8.723237 7.5 10.0\n",
      "6.4684787 7.5 7.5\n",
      "8.265588 7.5 10.0\n",
      "6.0097704 5 2.5\n",
      "9.308809 10 10.0\n",
      "6.5025406 7.5 10.0\n",
      "6.8406534 7.5 10.0\n",
      "6.926695 7.5 7.5\n",
      "7.3717694 7.5 10.0\n",
      "6.738855 7.5 7.5\n",
      "5.3507657 5 7.5\n",
      "7.85317 7.5 7.5\n",
      "7.6980686 7.5 7.5\n",
      "6.312067 7.5 7.5\n",
      "7.1721983 7.5 10.0\n",
      "6.913116 7.5 7.5\n",
      "7.600892 7.5 10.0\n",
      "5.9748197 5 10.0\n",
      "6.718238 7.5 7.5\n",
      "9.62091 10 10.0\n",
      "7.014466 7.5 7.5\n",
      "6.4093614 7.5 5.0\n",
      "8.128167 7.5 10.0\n",
      "5.95065 5 5.0\n",
      "8.686604 7.5 7.5\n",
      "7.8931046 7.5 7.5\n",
      "7.4930286 7.5 10.0\n",
      "6.5529804 7.5 0.0\n",
      "7.9078407 7.5 5.0\n",
      "8.575612 7.5 7.5\n",
      "9.971751 10 7.5\n",
      "6.828097 7.5 10.0\n",
      "6.32053 7.5 2.5\n",
      "6.0071945 5 5.0\n",
      "9.117696 10 7.5\n",
      "6.7290273 7.5 7.5\n",
      "7.487945 7.5 10.0\n",
      "7.153184 7.5 2.5\n",
      "7.1766214 7.5 7.5\n",
      "8.006289 7.5 10.0\n",
      "8.8548975 10 10.0\n",
      "5.1826515 5 10.0\n",
      "5.557401 5 2.5\n",
      "7.505442 7.5 7.5\n",
      "8.943387 10 7.5\n",
      "7.8343396 7.5 10.0\n",
      "7.5074115 7.5 7.5\n",
      "9.099901 10 7.5\n",
      "5.911309 5 10.0\n",
      "7.029959 7.5 5.0\n",
      "9.008444 10 7.5\n",
      "7.210225 7.5 10.0\n",
      "6.657603 7.5 7.5\n",
      "8.045045 7.5 7.5\n",
      "5.7507095 5 2.5\n",
      "5.902056 5 2.5\n",
      "8.480425 7.5 7.5\n",
      "4.6460853 5 7.5\n",
      "6.4929423 7.5 7.5\n",
      "7.3816013 7.5 7.5\n",
      "8.495994 7.5 10.0\n",
      "8.137367 7.5 2.5\n",
      "7.6977563 7.5 7.5\n",
      "8.839391 10 7.5\n",
      "8.6795225 7.5 10.0\n",
      "8.643074 7.5 10.0\n",
      "7.879315 7.5 7.5\n",
      "7.0873356 7.5 5.0\n",
      "9.043024 10 10.0\n",
      "7.307547 7.5 10.0\n",
      "8.444422 7.5 7.5\n",
      "7.4380927 7.5 10.0\n",
      "8.870378 10 10.0\n",
      "5.7060328 5 2.5\n",
      "6.9695334 7.5 5.0\n",
      "8.153898 7.5 10.0\n",
      "8.310602 7.5 10.0\n",
      "8.003927 7.5 7.5\n",
      "8.020667 7.5 10.0\n",
      "8.752924 10 7.5\n",
      "7.638061 7.5 7.5\n",
      "9.11074 10 10.0\n",
      "7.2740993 7.5 5.0\n",
      "7.56591 7.5 5.0\n",
      "7.749696 7.5 10.0\n",
      "7.434558 7.5 7.5\n",
      "6.910165 7.5 7.5\n",
      "8.751173 10 7.5\n",
      "7.666991 7.5 10.0\n",
      "8.362771 7.5 7.5\n",
      "6.4933314 7.5 7.5\n",
      "8.187576 7.5 7.5\n",
      "8.396187 7.5 10.0\n",
      "6.6282578 7.5 7.5\n",
      "5.4653378 5 7.5\n",
      "6.1717305 5 7.5\n",
      "7.2601748 7.5 7.5\n",
      "8.385347 7.5 7.5\n",
      "8.917405 10 10.0\n",
      "8.489651 7.5 10.0\n",
      "8.503833 7.5 10.0\n",
      "7.7287445 7.5 7.5\n",
      "6.6385245 7.5 7.5\n",
      "6.423091 7.5 10.0\n",
      "7.3621283 7.5 7.5\n",
      "6.18691 5 7.5\n",
      "8.913301 10 10.0\n",
      "7.048974 7.5 7.5\n",
      "8.951509 10 10.0\n",
      "7.1843157 7.5 7.5\n",
      "7.048867 7.5 10.0\n",
      "8.535232 7.5 10.0\n",
      "7.9645624 7.5 7.5\n",
      "7.198618 7.5 7.5\n",
      "6.9649787 7.5 7.5\n",
      "8.590393 7.5 7.5\n",
      "8.645126 7.5 10.0\n",
      "7.3044996 7.5 7.5\n",
      "8.393788 7.5 10.0\n",
      "7.1001616 7.5 7.5\n",
      "7.4772654 7.5 10.0\n",
      "6.089533 5 2.5\n",
      "5.695056 5 0.0\n",
      "7.2276936 7.5 2.5\n",
      "7.6275587 7.5 2.5\n",
      "6.3332486 7.5 5.0\n",
      "7.011819 7.5 10.0\n",
      "6.514311 7.5 5.0\n",
      "6.4802876 7.5 5.0\n",
      "6.3746715 7.5 7.5\n",
      "6.4421344 7.5 7.5\n",
      "7.1798344 7.5 7.5\n",
      "6.9129825 7.5 7.5\n",
      "6.991682 7.5 10.0\n",
      "7.338098 7.5 5.0\n",
      "7.1576395 7.5 7.5\n",
      "8.81388 10 7.5\n",
      "8.478157 7.5 7.5\n",
      "4.0456686 5 7.5\n",
      "8.933377 10 10.0\n",
      "7.0464997 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2498374 7.5 10.0\n",
      "7.0629873 7.5 10.0\n",
      "6.8996253 7.5 7.5\n",
      "6.8121514 7.5 10.0\n",
      "7.2658896 7.5 2.5\n",
      "8.852533 10 10.0\n",
      "7.584811 7.5 5.0\n",
      "8.762749 10 10.0\n",
      "6.7032113 7.5 7.5\n",
      "7.040448 7.5 7.5\n",
      "8.731287 7.5 10.0\n",
      "8.339863 7.5 10.0\n",
      "9.299665 10 10.0\n",
      "7.84971 7.5 7.5\n",
      "5.7796865 5 7.5\n",
      "5.215879 5 2.5\n",
      "6.0454664 5 5.0\n",
      "7.069505 7.5 7.5\n",
      "7.026026 7.5 10.0\n",
      "8.7816305 10 7.5\n",
      "7.6395483 7.5 10.0\n",
      "8.811912 10 7.5\n",
      "7.073048 7.5 7.5\n",
      "6.7585797 7.5 7.5\n",
      "5.5238676 5 7.5\n",
      "7.074044 7.5 7.5\n",
      "8.605527 7.5 10.0\n",
      "4.81072 5 2.5\n",
      "6.474626 7.5 10.0\n",
      "7.489467 7.5 10.0\n",
      "6.297437 7.5 7.5\n",
      "9.015276 10 10.0\n",
      "7.1141887 7.5 2.5\n",
      "8.855669 10 7.5\n",
      "7.5748086 7.5 7.5\n",
      "7.4217353 7.5 10.0\n",
      "7.6471562 7.5 7.5\n",
      "6.816087 7.5 5.0\n",
      "8.472724 7.5 10.0\n",
      "6.552516 7.5 7.5\n",
      "7.1472735 7.5 2.5\n",
      "5.7331457 5 7.5\n",
      "6.8766747 7.5 2.5\n",
      "5.6829224 5 2.5\n",
      "9.096558 10 10.0\n",
      "7.444388 7.5 7.5\n",
      "8.846415 10 7.5\n",
      "7.449927 7.5 7.5\n",
      "7.189878 7.5 7.5\n",
      "6.0751224 5 10.0\n",
      "7.364566 7.5 10.0\n",
      "5.6063213 5 10.0\n",
      "7.286406 7.5 7.5\n",
      "7.6666327 7.5 7.5\n",
      "6.3354225 7.5 10.0\n",
      "5.25561 5 10.0\n",
      "9.825521 10 10.0\n",
      "6.786795 7.5 10.0\n",
      "7.211224 7.5 7.5\n",
      "5.1729994 5 0.0\n",
      "8.658024 7.5 7.5\n",
      "7.481276 7.5 7.5\n",
      "8.141222 7.5 10.0\n",
      "7.8352633 7.5 2.5\n",
      "7.047787 7.5 7.5\n",
      "6.354513 7.5 5.0\n",
      "7.257781 7.5 7.5\n",
      "7.370767 7.5 10.0\n",
      "9.072065 10 7.5\n",
      "9.001488 10 10.0\n",
      "7.203402 7.5 7.5\n",
      "7.442974 7.5 2.5\n",
      "7.4649825 7.5 7.5\n",
      "7.3099937 7.5 7.5\n",
      "6.758963 7.5 7.5\n",
      "7.267594 7.5 2.5\n",
      "6.822842 7.5 7.5\n",
      "7.388667 7.5 10.0\n",
      "6.7713485 7.5 7.5\n",
      "9.20234 10 7.5\n",
      "6.988487 7.5 7.5\n",
      "7.457518 7.5 7.5\n",
      "7.1103916 7.5 10.0\n",
      "9.00083 10 10.0\n",
      "6.9202895 7.5 7.5\n",
      "9.033867 10 10.0\n",
      "7.7080817 7.5 10.0\n",
      "7.770261 7.5 10.0\n",
      "6.412739 7.5 10.0\n",
      "5.156807 5 2.5\n",
      "7.8048015 7.5 7.5\n",
      "7.976662 7.5 10.0\n",
      "5.4503665 5 0.0\n",
      "7.6033726 7.5 10.0\n",
      "6.092348 5 7.5\n",
      "7.874834 7.5 2.5\n",
      "6.79322 7.5 5.0\n",
      "7.040174 7.5 7.5\n",
      "6.7235327 7.5 5.0\n",
      "5.583452 5 7.5\n",
      "7.2103567 7.5 10.0\n",
      "6.54365 7.5 7.5\n",
      "5.1156597 5 7.5\n",
      "8.544493 7.5 10.0\n",
      "5.7954426 5 7.5\n",
      "7.408787 7.5 7.5\n",
      "7.061892 7.5 5.0\n",
      "7.4255366 7.5 10.0\n",
      "7.224121 7.5 10.0\n",
      "7.383934 7.5 10.0\n",
      "7.893984 7.5 10.0\n",
      "8.617469 7.5 10.0\n",
      "7.1683226 7.5 7.5\n",
      "6.9922867 7.5 7.5\n",
      "8.941133 10 10.0\n",
      "8.846904 10 7.5\n",
      "8.689668 7.5 7.5\n",
      "9.024565 10 7.5\n",
      "7.057293 7.5 7.5\n",
      "6.706053 7.5 2.5\n",
      "7.8386283 7.5 7.5\n",
      "6.367111 7.5 7.5\n",
      "9.645114 10 10.0\n",
      "5.350004 5 7.5\n",
      "5.563779 5 7.5\n",
      "7.238351 7.5 7.5\n",
      "8.127445 7.5 7.5\n",
      "7.08908 7.5 10.0\n",
      "9.023237 10 10.0\n",
      "9.000626 10 7.5\n",
      "6.821427 7.5 7.5\n",
      "7.675 7.5 7.5\n",
      "7.2775536 7.5 10.0\n",
      "9.138244 10 10.0\n",
      "7.510306 7.5 10.0\n",
      "9.392152 10 10.0\n",
      "8.145443 7.5 10.0\n",
      "7.6661754 7.5 7.5\n",
      "8.918307 10 7.5\n",
      "6.54089 7.5 7.5\n",
      "6.3692465 7.5 10.0\n",
      "8.753905 10 10.0\n",
      "8.292461 7.5 10.0\n",
      "6.9488854 7.5 7.5\n",
      "4.5113273 5 5.0\n",
      "7.3257065 7.5 7.5\n",
      "8.623052 7.5 5.0\n",
      "3.4767556 2.5 2.5\n",
      "7.4732413 7.5 2.5\n",
      "7.4558063 7.5 7.5\n",
      "6.8179145 7.5 7.5\n",
      "8.182265 7.5 7.5\n",
      "6.3605795 7.5 7.5\n",
      "8.82775 10 2.5\n",
      "6.4925985 7.5 2.5\n",
      "9.774725 10 10.0\n",
      "9.050994 10 10.0\n",
      "7.5621967 7.5 7.5\n",
      "7.7375073 7.5 10.0\n",
      "9.538564 10 10.0\n",
      "6.7260523 7.5 7.5\n",
      "6.9928975 7.5 7.5\n",
      "4.2454185 5 2.5\n",
      "8.913458 10 10.0\n",
      "5.435524 5 2.5\n",
      "7.069144 7.5 2.5\n",
      "5.191503 5 0.0\n",
      "7.4445653 7.5 7.5\n",
      "9.248551 10 10.0\n",
      "7.5086207 7.5 7.5\n",
      "8.966882 10 10.0\n",
      "7.027886 7.5 7.5\n",
      "7.498787 7.5 7.5\n",
      "6.449946 7.5 10.0\n",
      "7.8176117 7.5 10.0\n",
      "6.509526 7.5 7.5\n",
      "6.122298 5 5.0\n",
      "7.063854 7.5 10.0\n",
      "8.963464 10 10.0\n",
      "8.021267 7.5 10.0\n",
      "7.0349474 7.5 10.0\n",
      "7.732552 7.5 10.0\n",
      "7.586988 7.5 5.0\n",
      "6.085227 5 10.0\n",
      "6.929994 7.5 7.5\n",
      "7.0557137 7.5 10.0\n",
      "8.813485 10 2.5\n",
      "7.7594194 7.5 10.0\n",
      "7.205122 7.5 10.0\n",
      "9.455564 10 10.0\n",
      "7.2847705 7.5 5.0\n",
      "6.8737597 7.5 5.0\n",
      "8.735121 7.5 10.0\n",
      "5.746553 5 2.5\n",
      "7.3846097 7.5 10.0\n",
      "5.4099116 5 7.5\n",
      "9.203973 10 10.0\n",
      "6.50757 7.5 2.5\n",
      "5.785525 5 2.5\n",
      "7.429924 7.5 5.0\n",
      "8.514276 7.5 10.0\n",
      "8.714898 7.5 10.0\n",
      "7.1421967 7.5 2.5\n",
      "8.464184 7.5 10.0\n",
      "7.187747 7.5 2.5\n",
      "8.536988 7.5 10.0\n",
      "7.54845 7.5 5.0\n",
      "8.697537 7.5 10.0\n",
      "8.607667 7.5 7.5\n",
      "7.186866 7.5 10.0\n",
      "6.663266 7.5 2.5\n",
      "6.4507785 7.5 7.5\n",
      "8.296478 7.5 7.5\n",
      "7.314121 7.5 7.5\n",
      "6.8918114 7.5 7.5\n",
      "7.044851 7.5 5.0\n",
      "7.7899666 7.5 10.0\n",
      "7.09461 7.5 7.5\n",
      "4.6186843 5 2.5\n",
      "6.355214 7.5 10.0\n",
      "9.169338 10 10.0\n",
      "8.2008 7.5 7.5\n",
      "8.376865 7.5 7.5\n",
      "6.5528026 7.5 7.5\n",
      "5.987219 5 7.5\n",
      "4.9347157 5 7.5\n",
      "7.146894 7.5 7.5\n",
      "6.811525 7.5 2.5\n",
      "7.5428085 7.5 5.0\n",
      "7.453137 7.5 7.5\n",
      "7.887602 7.5 5.0\n",
      "7.151456 7.5 7.5\n",
      "7.3123374 7.5 5.0\n",
      "8.540018 7.5 7.5\n",
      "7.2549872 7.5 7.5\n",
      "6.4958644 7.5 2.5\n",
      "6.7641068 7.5 7.5\n",
      "4.5989475 5 0.0\n",
      "7.576034 7.5 10.0\n",
      "7.593365 7.5 7.5\n",
      "8.065838 7.5 7.5\n",
      "7.4106355 7.5 10.0\n",
      "6.8438683 7.5 7.5\n",
      "7.225608 7.5 10.0\n",
      "7.512239 7.5 10.0\n",
      "7.0448594 7.5 7.5\n",
      "5.268523 5 7.5\n",
      "7.466051 7.5 7.5\n",
      "8.637916 7.5 10.0\n",
      "7.1564126 7.5 7.5\n",
      "8.812299 10 5.0\n",
      "8.743115 7.5 7.5\n",
      "9.019884 10 10.0\n",
      "7.5913563 7.5 5.0\n",
      "7.7267227 7.5 10.0\n",
      "6.4716396 7.5 7.5\n",
      "6.9944367 7.5 2.5\n",
      "7.1243243 7.5 7.5\n",
      "8.703987 7.5 7.5\n",
      "8.217157 7.5 7.5\n",
      "7.5046453 7.5 7.5\n",
      "8.315876 7.5 5.0\n",
      "5.6956534 5 10.0\n",
      "8.69694 7.5 10.0\n",
      "7.385411 7.5 10.0\n",
      "8.1806555 7.5 10.0\n",
      "8.9774475 10 10.0\n",
      "6.8783274 7.5 7.5\n",
      "9.785297 10 7.5\n",
      "6.1938806 5 7.5\n",
      "6.6089344 7.5 7.5\n",
      "8.643121 7.5 10.0\n",
      "8.680582 7.5 5.0\n",
      "8.755383 10 10.0\n",
      "6.9071403 7.5 7.5\n",
      "5.2429338 5 7.5\n",
      "8.281757 7.5 10.0\n",
      "7.5964136 7.5 2.5\n",
      "7.2373586 7.5 7.5\n",
      "6.486621 7.5 7.5\n",
      "6.771817 7.5 7.5\n",
      "8.620655 7.5 7.5\n",
      "9.175645 10 5.0\n",
      "7.187366 7.5 7.5\n",
      "7.4759254 7.5 7.5\n",
      "8.1177845 7.5 10.0\n",
      "8.611422 7.5 10.0\n",
      "8.822244 10 10.0\n",
      "7.4913416 7.5 5.0\n",
      "7.407981 7.5 7.5\n",
      "7.6483407 7.5 10.0\n",
      "7.541469 7.5 10.0\n",
      "7.109718 7.5 5.0\n",
      "7.486066 7.5 10.0\n",
      "7.994737 7.5 7.5\n",
      "7.68822 7.5 10.0\n",
      "5.6646867 5 7.5\n",
      "8.6029825 7.5 10.0\n",
      "9.483179 10 10.0\n",
      "7.295296 7.5 10.0\n",
      "9.029859 10 7.5\n",
      "5.8091884 5 0.0\n",
      "5.740032 5 7.5\n",
      "5.498538 5 5.0\n",
      "6.9687257 7.5 2.5\n",
      "9.286668 10 10.0\n",
      "7.478028 7.5 7.5\n",
      "7.220284 7.5 5.0\n",
      "6.716022 7.5 5.0\n",
      "6.6826515 7.5 5.0\n",
      "8.822994 10 10.0\n",
      "8.114517 7.5 10.0\n",
      "7.451096 7.5 10.0\n",
      "7.302082 7.5 5.0\n",
      "8.558032 7.5 7.5\n",
      "8.00451 7.5 7.5\n",
      "7.9069095 7.5 10.0\n",
      "8.974684 10 7.5\n",
      "7.373004 7.5 7.5\n",
      "7.1409616 7.5 10.0\n",
      "7.3959208 7.5 7.5\n",
      "5.6613936 5 7.5\n",
      "7.6332 7.5 7.5\n",
      "7.86587 7.5 2.5\n",
      "8.94788 10 10.0\n",
      "7.5456867 7.5 7.5\n",
      "7.745742 7.5 7.5\n",
      "8.815609 10 7.5\n",
      "7.620989 7.5 7.5\n",
      "9.196998 10 10.0\n",
      "7.2991962 7.5 5.0\n",
      "7.886896 7.5 7.5\n",
      "8.167473 7.5 2.5\n",
      "7.793927 7.5 7.5\n",
      "6.8595023 7.5 7.5\n",
      "7.9327607 7.5 5.0\n",
      "9.08575 10 10.0\n",
      "7.7906137 7.5 10.0\n",
      "8.805328 10 7.5\n",
      "7.477594 7.5 10.0\n",
      "7.3080354 7.5 10.0\n",
      "7.0417 7.5 10.0\n",
      "7.1795034 7.5 2.5\n",
      "8.952321 10 10.0\n",
      "6.2882357 7.5 7.5\n",
      "8.555668 7.5 5.0\n",
      "8.493538 7.5 7.5\n",
      "8.73978 7.5 10.0\n",
      "8.429314 7.5 10.0\n",
      "7.1374307 7.5 7.5\n",
      "8.879378 10 7.5\n",
      "7.659003 7.5 10.0\n",
      "6.3142133 7.5 2.5\n",
      "7.169751 7.5 10.0\n",
      "8.2054615 7.5 10.0\n",
      "6.8600082 7.5 10.0\n",
      "8.788044 10 10.0\n",
      "6.810656 7.5 5.0\n",
      "8.93925 10 7.5\n",
      "6.626221 7.5 7.5\n",
      "7.790435 7.5 10.0\n",
      "8.750533 10 10.0\n",
      "7.784374 7.5 10.0\n",
      "7.319374 7.5 5.0\n",
      "6.8688507 7.5 7.5\n",
      "9.553318 10 10.0\n",
      "7.1464562 7.5 7.5\n",
      "8.914801 10 10.0\n",
      "4.4226484 5 7.5\n",
      "8.526663 7.5 2.5\n",
      "9.217181 10 7.5\n",
      "8.803108 10 10.0\n",
      "7.061543 7.5 7.5\n",
      "8.6854105 7.5 10.0\n",
      "8.708967 7.5 7.5\n",
      "7.427226 7.5 10.0\n",
      "8.480953 7.5 7.5\n",
      "6.412194 7.5 7.5\n",
      "8.024704 7.5 10.0\n",
      "4.946924 5 2.5\n",
      "7.828813 7.5 10.0\n",
      "8.925004 10 10.0\n",
      "5.6424537 5 5.0\n",
      "7.219738 7.5 7.5\n",
      "7.7464285 7.5 7.5\n",
      "4.7814307 5 5.0\n",
      "6.554984 7.5 7.5\n",
      "8.494024 7.5 10.0\n",
      "6.5330257 7.5 2.5\n",
      "8.953579 10 7.5\n",
      "6.7262745 7.5 5.0\n",
      "5.8080707 5 5.0\n",
      "8.200482 7.5 10.0\n",
      "6.5908813 7.5 2.5\n",
      "7.3661475 7.5 7.5\n",
      "7.3360615 7.5 7.5\n",
      "9.13434 10 10.0\n",
      "6.7171574 7.5 7.5\n",
      "8.603332 7.5 7.5\n",
      "7.074343 7.5 5.0\n",
      "6.7384787 7.5 10.0\n",
      "5.199965 5 0.0\n",
      "9.223745 10 10.0\n",
      "7.737554 7.5 5.0\n",
      "5.234888 5 7.5\n",
      "6.2234335 5 7.5\n",
      "8.678134 7.5 7.5\n",
      "6.2208266 5 7.5\n",
      "6.7712274 7.5 10.0\n",
      "5.740088 5 2.5\n",
      "7.2667933 7.5 7.5\n",
      "7.6964865 7.5 5.0\n",
      "8.2085495 7.5 10.0\n",
      "6.1386037 5 2.5\n",
      "8.527719 7.5 10.0\n",
      "6.4446654 7.5 7.5\n",
      "7.1821866 7.5 7.5\n",
      "5.479504 5 2.5\n",
      "5.3922663 5 7.5\n",
      "8.669475 7.5 10.0\n",
      "9.067867 10 10.0\n",
      "7.5673323 7.5 2.5\n",
      "6.632557 7.5 10.0\n",
      "7.230455 7.5 5.0\n",
      "7.8837194 7.5 5.0\n",
      "8.845236 10 2.5\n",
      "6.2565565 7.5 5.0\n",
      "8.344422 7.5 7.5\n",
      "6.801099 7.5 5.0\n",
      "5.749136 5 2.5\n",
      "8.002837 7.5 10.0\n",
      "7.6359105 7.5 7.5\n",
      "6.5352516 7.5 10.0\n",
      "5.3504424 5 2.5\n",
      "7.0716796 7.5 7.5\n",
      "7.93775 7.5 10.0\n",
      "7.541265 7.5 7.5\n",
      "8.935629 10 7.5\n",
      "7.793917 7.5 10.0\n",
      "6.9183064 7.5 2.5\n",
      "7.366221 7.5 2.5\n",
      "6.8426757 7.5 7.5\n",
      "7.8274326 7.5 10.0\n",
      "5.049364 5 2.5\n",
      "7.0201197 7.5 10.0\n",
      "8.233742 7.5 7.5\n",
      "8.915218 10 10.0\n",
      "7.3247695 7.5 2.5\n",
      "9.456071 10 7.5\n",
      "6.8846717 7.5 7.5\n",
      "8.792272 10 10.0\n",
      "7.1873093 7.5 5.0\n",
      "7.7473865 7.5 7.5\n",
      "8.013124 7.5 10.0\n",
      "7.1964283 7.5 7.5\n",
      "9.183392 10 10.0\n",
      "8.739866 7.5 7.5\n",
      "7.2692833 7.5 7.5\n",
      "9.072422 10 10.0\n",
      "4.4244757 5 0.0\n",
      "7.137235 7.5 7.5\n",
      "7.0545163 7.5 7.5\n",
      "6.024472 5 5.0\n",
      "8.640497 7.5 7.5\n",
      "7.149264 7.5 10.0\n",
      "7.0813375 7.5 10.0\n",
      "7.5472527 7.5 10.0\n",
      "6.8816147 7.5 10.0\n",
      "7.1109734 7.5 7.5\n",
      "7.7418427 7.5 7.5\n",
      "7.4933615 7.5 7.5\n",
      "6.8401346 7.5 7.5\n",
      "8.641765 7.5 10.0\n",
      "8.495836 7.5 10.0\n",
      "6.913295 7.5 7.5\n",
      "9.247961 10 7.5\n",
      "7.3477445 7.5 7.5\n",
      "8.371833 7.5 7.5\n",
      "7.105676 7.5 10.0\n",
      "8.610822 7.5 7.5\n",
      "9.176532 10 10.0\n",
      "6.139636 5 7.5\n",
      "7.5413303 7.5 10.0\n",
      "8.279529 7.5 10.0\n",
      "8.737379 7.5 10.0\n",
      "7.029888 7.5 7.5\n",
      "9.3458395 10 7.5\n",
      "6.0182886 5 7.5\n",
      "6.634849 7.5 7.5\n",
      "8.545707 7.5 10.0\n",
      "7.5122757 7.5 7.5\n",
      "7.973449 7.5 0.0\n",
      "9.290523 10 7.5\n",
      "6.656411 7.5 7.5\n",
      "6.5741644 7.5 7.5\n",
      "7.302179 7.5 7.5\n",
      "6.8291636 7.5 7.5\n",
      "7.8633523 7.5 10.0\n",
      "6.7097077 7.5 5.0\n",
      "8.009538 7.5 5.0\n",
      "4.436139 5 7.5\n",
      "7.2893195 7.5 2.5\n",
      "7.7883353 7.5 7.5\n",
      "7.339655 7.5 10.0\n",
      "7.6217484 7.5 10.0\n",
      "7.738951 7.5 10.0\n",
      "6.5560365 7.5 10.0\n",
      "8.728482 7.5 7.5\n",
      "5.1010313 5 5.0\n",
      "4.3613224 5 0.0\n",
      "9.5216055 10 10.0\n",
      "9.29446 10 7.5\n",
      "8.210159 7.5 10.0\n",
      "8.984551 10 7.5\n",
      "6.139171 5 7.5\n",
      "8.1457615 7.5 7.5\n",
      "8.890227 10 10.0\n",
      "7.43087 7.5 7.5\n",
      "7.1270623 7.5 7.5\n",
      "6.802337 7.5 5.0\n",
      "7.8323064 7.5 7.5\n",
      "8.99246 10 10.0\n",
      "7.029524 7.5 7.5\n",
      "6.5357003 7.5 7.5\n",
      "7.1400647 7.5 7.5\n",
      "6.397643 7.5 7.5\n",
      "8.446936 7.5 7.5\n",
      "9.142687 10 7.5\n",
      "7.1688886 7.5 10.0\n",
      "6.255579 7.5 2.5\n",
      "6.0960407 5 10.0\n",
      "7.8559084 7.5 10.0\n",
      "5.342618 5 5.0\n",
      "8.438427 7.5 7.5\n",
      "7.3734694 7.5 10.0\n",
      "6.405296 7.5 7.5\n",
      "8.155603 7.5 10.0\n",
      "8.190871 7.5 7.5\n",
      "9.0663805 10 10.0\n",
      "7.9243712 7.5 10.0\n",
      "7.620014 7.5 7.5\n",
      "7.4874115 7.5 10.0\n",
      "8.342056 7.5 7.5\n",
      "8.776154 10 10.0\n",
      "7.26893 7.5 10.0\n",
      "9.145419 10 10.0\n",
      "8.861709 10 10.0\n",
      "7.105817 7.5 10.0\n",
      "8.636096 7.5 10.0\n",
      "6.829931 7.5 5.0\n",
      "7.282233 7.5 2.5\n",
      "8.826428 10 7.5\n",
      "8.053238 7.5 10.0\n",
      "8.7493515 7.5 10.0\n",
      "8.689772 7.5 7.5\n",
      "8.869054 10 10.0\n",
      "6.188213 5 7.5\n",
      "8.557263 7.5 10.0\n",
      "7.8925877 7.5 10.0\n",
      "8.160575 7.5 10.0\n",
      "7.78371 7.5 7.5\n",
      "7.9097896 7.5 7.5\n",
      "6.996173 7.5 7.5\n",
      "8.052032 7.5 10.0\n",
      "7.4665585 7.5 10.0\n",
      "7.224904 7.5 10.0\n",
      "6.9748864 7.5 5.0\n",
      "7.4137926 7.5 2.5\n",
      "7.2851715 7.5 7.5\n",
      "7.31 7.5 7.5\n",
      "8.6545515 7.5 10.0\n",
      "8.431164 7.5 7.5\n",
      "7.219908 7.5 10.0\n",
      "6.9951906 7.5 7.5\n",
      "9.066986 10 10.0\n",
      "7.1111197 7.5 7.5\n",
      "7.3360605 7.5 10.0\n",
      "7.63771 7.5 0.0\n",
      "7.012859 7.5 7.5\n",
      "8.961229 10 10.0\n",
      "7.000494 7.5 7.5\n",
      "6.6613817 7.5 2.5\n",
      "9.101882 10 7.5\n",
      "9.059652 10 10.0\n",
      "8.604819 7.5 10.0\n",
      "8.625079 7.5 10.0\n",
      "7.5306935 7.5 7.5\n",
      "7.304101 7.5 10.0\n",
      "6.1289907 5 7.5\n",
      "7.281407 7.5 7.5\n",
      "8.888058 10 10.0\n",
      "7.274769 7.5 7.5\n",
      "8.896404 10 10.0\n",
      "9.15768 10 10.0\n",
      "8.768877 10 10.0\n",
      "5.280571 5 2.5\n",
      "6.705205 7.5 5.0\n",
      "7.762806 7.5 10.0\n",
      "6.7312284 7.5 10.0\n",
      "7.591618 7.5 7.5\n",
      "6.308951 7.5 10.0\n",
      "7.094358 7.5 7.5\n",
      "7.978814 7.5 7.5\n",
      "6.5401406 7.5 5.0\n",
      "6.9508786 7.5 10.0\n",
      "8.48898 7.5 7.5\n",
      "8.505541 7.5 10.0\n",
      "6.6333866 7.5 2.5\n",
      "6.710438 7.5 10.0\n",
      "7.039234 7.5 7.5\n",
      "7.3088984 7.5 2.5\n",
      "7.594661 7.5 7.5\n",
      "7.799756 7.5 7.5\n",
      "7.924488 7.5 7.5\n",
      "8.130526 7.5 7.5\n",
      "7.4066944 7.5 7.5\n",
      "7.270441 7.5 2.5\n",
      "7.265235 7.5 7.5\n",
      "8.737057 7.5 10.0\n",
      "5.083915 5 7.5\n",
      "7.602276 7.5 5.0\n",
      "7.356227 7.5 10.0\n",
      "8.869089 10 7.5\n",
      "7.2095714 7.5 7.5\n",
      "8.55527 7.5 7.5\n",
      "7.8641415 7.5 10.0\n",
      "6.017965 5 2.5\n",
      "6.474202 7.5 7.5\n",
      "8.801375 10 7.5\n",
      "7.997595 7.5 10.0\n",
      "8.310228 7.5 7.5\n",
      "7.712623 7.5 10.0\n",
      "8.753038 10 10.0\n",
      "7.755875 7.5 7.5\n",
      "8.469633 7.5 10.0\n",
      "8.895757 10 7.5\n",
      "7.3946657 7.5 7.5\n",
      "6.4811864 7.5 7.5\n",
      "6.4527173 7.5 2.5\n",
      "6.9135666 7.5 7.5\n",
      "7.139869 7.5 2.5\n",
      "8.39085 7.5 7.5\n",
      "7.079531 7.5 7.5\n",
      "9.039807 10 10.0\n",
      "7.822174 7.5 7.5\n",
      "7.0947776 7.5 10.0\n",
      "8.168383 7.5 10.0\n",
      "7.177552 7.5 7.5\n",
      "5.489314 5 7.5\n",
      "4.826519 5 7.5\n",
      "6.8174458 7.5 10.0\n",
      "7.8012595 7.5 10.0\n",
      "6.06841 5 7.5\n",
      "8.877749 10 7.5\n",
      "7.951837 7.5 7.5\n",
      "5.344897 5 2.5\n",
      "8.195393 7.5 10.0\n",
      "8.40124 7.5 7.5\n",
      "7.6985817 7.5 7.5\n",
      "7.8474765 7.5 5.0\n",
      "7.2066436 7.5 7.5\n",
      "8.149211 7.5 7.5\n",
      "6.9455957 7.5 5.0\n",
      "6.3098154 7.5 2.5\n",
      "6.33211 7.5 5.0\n",
      "6.40574 7.5 7.5\n",
      "6.9030623 7.5 7.5\n",
      "3.206841 2.5 2.5\n",
      "7.447324 7.5 2.5\n",
      "7.562243 7.5 7.5\n",
      "6.3648105 7.5 10.0\n",
      "4.9486704 5 7.5\n",
      "7.817934 7.5 2.5\n",
      "8.402046 7.5 10.0\n",
      "7.7464633 7.5 2.5\n",
      "8.706513 7.5 10.0\n",
      "7.3992596 7.5 5.0\n",
      "6.945388 7.5 7.5\n",
      "8.492481 7.5 10.0\n",
      "8.299252 7.5 7.5\n",
      "7.583466 7.5 10.0\n",
      "7.2872763 7.5 7.5\n",
      "8.35582 7.5 7.5\n",
      "8.030301 7.5 7.5\n",
      "9.012908 10 10.0\n",
      "7.240848 7.5 10.0\n",
      "6.959243 7.5 5.0\n",
      "8.585435 7.5 7.5\n",
      "7.555036 7.5 7.5\n",
      "8.290573 7.5 10.0\n",
      "8.799361 10 7.5\n",
      "5.264028 5 7.5\n",
      "7.9414825 7.5 7.5\n",
      "7.856016 7.5 7.5\n",
      "9.483923 10 10.0\n",
      "6.076272 5 10.0\n",
      "7.0877542 7.5 10.0\n",
      "6.9425583 7.5 2.5\n",
      "7.468598 7.5 5.0\n",
      "7.3825173 7.5 5.0\n",
      "7.115344 7.5 7.5\n",
      "8.0335045 7.5 10.0\n",
      "8.730178 7.5 10.0\n",
      "8.419784 7.5 10.0\n",
      "7.798797 7.5 7.5\n",
      "7.6943526 7.5 7.5\n",
      "6.584841 7.5 5.0\n",
      "6.7851033 7.5 7.5\n",
      "7.1537595 7.5 10.0\n",
      "7.422084 7.5 7.5\n",
      "7.165734 7.5 7.5\n",
      "3.8009396 5 2.5\n",
      "6.9972525 7.5 10.0\n",
      "8.824984 10 10.0\n",
      "7.791033 7.5 7.5\n",
      "8.141205 7.5 10.0\n",
      "4.988617 5 2.5\n",
      "7.219178 7.5 7.5\n",
      "7.0459085 7.5 10.0\n",
      "7.070277 7.5 5.0\n",
      "8.11845 7.5 7.5\n",
      "8.998032 10 10.0\n",
      "6.8798656 7.5 7.5\n",
      "6.174459 5 5.0\n",
      "4.4020157 5 0.0\n",
      "8.0084915 7.5 10.0\n",
      "7.26875 7.5 7.5\n",
      "8.78282 10 7.5\n",
      "7.0594187 7.5 0.0\n",
      "8.089159 7.5 10.0\n",
      "7.018011 7.5 7.5\n",
      "5.6199512 5 7.5\n",
      "4.4933977 5 2.5\n",
      "7.1704116 7.5 7.5\n",
      "7.3016014 7.5 5.0\n",
      "5.169882 5 2.5\n",
      "8.3884 7.5 10.0\n",
      "4.523283 5 2.5\n",
      "7.107578 7.5 7.5\n",
      "7.3936977 7.5 7.5\n",
      "7.8517084 7.5 2.5\n",
      "7.00041 7.5 7.5\n",
      "6.455077 7.5 7.5\n",
      "7.4617457 7.5 10.0\n",
      "5.392189 5 7.5\n",
      "7.701345 7.5 7.5\n",
      "8.87136 10 7.5\n",
      "8.94487 10 7.5\n",
      "8.811584 10 10.0\n",
      "7.2529273 7.5 2.5\n",
      "5.091694 5 7.5\n",
      "9.023467 10 5.0\n",
      "8.589597 7.5 10.0\n",
      "7.219659 7.5 7.5\n",
      "8.477047 7.5 10.0\n",
      "7.1748805 7.5 2.5\n",
      "7.433496 7.5 7.5\n",
      "8.793344 10 10.0\n",
      "9.211994 10 10.0\n",
      "7.1827335 7.5 7.5\n",
      "7.5120325 7.5 7.5\n",
      "7.3371315 7.5 7.5\n",
      "6.986016 7.5 5.0\n",
      "7.859622 7.5 5.0\n",
      "6.8411217 7.5 2.5\n",
      "5.3299756 5 5.0\n",
      "5.7599874 5 2.5\n",
      "7.130823 7.5 2.5\n",
      "4.8966084 5 7.5\n",
      "7.036296 7.5 5.0\n",
      "8.859753 10 10.0\n",
      "8.998312 10 10.0\n",
      "6.9230065 7.5 2.5\n",
      "6.1667223 5 5.0\n",
      "7.46657 7.5 10.0\n",
      "7.1951647 7.5 10.0\n",
      "9.417651 10 10.0\n",
      "7.1169744 7.5 10.0\n",
      "8.759647 10 10.0\n",
      "8.686352 7.5 10.0\n",
      "7.8044577 7.5 7.5\n",
      "6.2809176 7.5 10.0\n",
      "6.733169 7.5 10.0\n",
      "6.9946346 7.5 5.0\n",
      "7.5724654 7.5 10.0\n",
      "5.876876 5 7.5\n",
      "7.2717805 7.5 7.5\n",
      "7.252929 7.5 10.0\n",
      "8.265154 7.5 7.5\n",
      "8.61026 7.5 10.0\n",
      "4.2675037 5 7.5\n",
      "8.10353 7.5 7.5\n",
      "8.166803 7.5 5.0\n",
      "8.212906 7.5 7.5\n",
      "7.3442926 7.5 7.5\n",
      "5.345816 5 2.5\n",
      "7.0297627 7.5 7.5\n",
      "8.757666 10 10.0\n",
      "6.4201317 7.5 7.5\n",
      "7.4657893 7.5 7.5\n",
      "7.800231 7.5 7.5\n",
      "8.073482 7.5 2.5\n",
      "6.745623 7.5 5.0\n",
      "5.237392 5 7.5\n",
      "7.5151434 7.5 7.5\n",
      "7.7858205 7.5 7.5\n",
      "7.201031 7.5 10.0\n",
      "7.1281676 7.5 5.0\n",
      "8.2869625 7.5 7.5\n",
      "6.612165 7.5 10.0\n",
      "7.377511 7.5 10.0\n",
      "7.099855 7.5 7.5\n",
      "7.523238 7.5 7.5\n",
      "6.3083353 7.5 7.5\n",
      "7.7223873 7.5 7.5\n",
      "7.8259206 7.5 10.0\n",
      "8.568031 7.5 10.0\n",
      "7.122948 7.5 10.0\n",
      "7.7605457 7.5 10.0\n",
      "7.4238973 7.5 7.5\n",
      "6.36018 7.5 7.5\n",
      "6.642846 7.5 7.5\n",
      "7.260721 7.5 5.0\n",
      "8.953952 10 10.0\n",
      "8.366808 7.5 7.5\n",
      "7.011583 7.5 10.0\n",
      "7.934847 7.5 10.0\n",
      "6.5885687 7.5 5.0\n",
      "6.4567766 7.5 7.5\n",
      "7.671178 7.5 5.0\n",
      "8.154356 7.5 7.5\n",
      "6.404556 7.5 2.5\n",
      "5.465638 5 2.5\n",
      "6.8559866 7.5 7.5\n",
      "6.5621066 7.5 7.5\n",
      "6.2901382 7.5 10.0\n",
      "6.9750776 7.5 10.0\n",
      "7.4078064 7.5 2.5\n",
      "8.242606 7.5 7.5\n",
      "7.745081 7.5 10.0\n",
      "7.051695 7.5 7.5\n",
      "8.875136 10 7.5\n",
      "6.3689322 7.5 2.5\n",
      "6.9917083 7.5 2.5\n",
      "8.377071 7.5 10.0\n",
      "6.3208 7.5 2.5\n",
      "6.4019732 7.5 7.5\n",
      "5.8370466 5 7.5\n",
      "6.9752703 7.5 7.5\n",
      "7.8977265 7.5 7.5\n",
      "8.067947 7.5 7.5\n",
      "9.118327 10 10.0\n",
      "7.101579 7.5 10.0\n",
      "6.7159967 7.5 2.5\n",
      "7.2055264 7.5 10.0\n",
      "7.661001 7.5 7.5\n",
      "7.2205963 7.5 5.0\n",
      "6.633061 7.5 2.5\n",
      "6.6140428 7.5 10.0\n",
      "8.52115 7.5 10.0\n",
      "7.3540564 7.5 10.0\n",
      "8.627132 7.5 10.0\n",
      "6.3774414 7.5 2.5\n",
      "8.874928 10 10.0\n",
      "6.4356565 7.5 2.5\n",
      "6.4370685 7.5 2.5\n",
      "7.2858677 7.5 7.5\n",
      "7.385181 7.5 7.5\n",
      "8.027273 7.5 10.0\n",
      "7.5243363 7.5 7.5\n",
      "6.336462 7.5 10.0\n",
      "8.3227825 7.5 10.0\n",
      "7.106969 7.5 7.5\n",
      "7.195165 7.5 7.5\n",
      "7.069553 7.5 7.5\n",
      "7.480245 7.5 2.5\n",
      "6.7298155 7.5 5.0\n",
      "5.521868 5 7.5\n",
      "6.6968417 7.5 7.5\n",
      "7.3511276 7.5 0.0\n",
      "9.303144 10 10.0\n",
      "7.4655623 7.5 7.5\n",
      "5.6219034 5 0.0\n",
      "7.111885 7.5 7.5\n",
      "7.6180983 7.5 2.5\n",
      "5.714168 5 2.5\n",
      "7.4361115 7.5 7.5\n",
      "8.853647 10 7.5\n",
      "9.173534 10 10.0\n",
      "8.322689 7.5 7.5\n",
      "7.1198945 7.5 7.5\n",
      "8.685178 7.5 10.0\n",
      "7.5461574 7.5 7.5\n",
      "7.625299 7.5 10.0\n",
      "7.795294 7.5 10.0\n",
      "8.32785 7.5 10.0\n",
      "5.0081077 5 2.5\n",
      "6.4386535 7.5 7.5\n",
      "7.0277205 7.5 7.5\n",
      "7.8231196 7.5 7.5\n",
      "7.39638 7.5 7.5\n",
      "8.520012 7.5 10.0\n",
      "8.0893 7.5 5.0\n",
      "7.013221 7.5 10.0\n",
      "5.8427258 5 2.5\n",
      "8.448505 7.5 7.5\n",
      "7.68631 7.5 10.0\n",
      "8.408602 7.5 7.5\n",
      "7.281528 7.5 10.0\n",
      "7.4973373 7.5 7.5\n",
      "9.097749 10 2.5\n",
      "8.948606 10 5.0\n",
      "6.835436 7.5 7.5\n",
      "7.6762257 7.5 10.0\n",
      "8.882473 10 10.0\n",
      "7.2579484 7.5 7.5\n",
      "7.913873 7.5 7.5\n",
      "8.181637 7.5 10.0\n",
      "7.5347548 7.5 5.0\n",
      "6.7162385 7.5 10.0\n",
      "6.5141006 7.5 10.0\n",
      "5.0072517 5 2.5\n",
      "7.319083 7.5 5.0\n",
      "7.726082 7.5 5.0\n",
      "9.070667 10 10.0\n",
      "6.9449677 7.5 7.5\n",
      "7.4241624 7.5 10.0\n",
      "8.935159 10 10.0\n",
      "9.121632 10 7.5\n",
      "9.037085 10 10.0\n",
      "9.079686 10 10.0\n",
      "5.319502 5 7.5\n",
      "7.750863 7.5 10.0\n",
      "8.297959 7.5 5.0\n",
      "7.107518 7.5 2.5\n",
      "9.366106 10 10.0\n",
      "7.842175 7.5 2.5\n",
      "7.3438187 7.5 7.5\n",
      "7.6902995 7.5 7.5\n",
      "4.9804335 5 2.5\n",
      "8.831953 10 10.0\n",
      "7.756983 7.5 2.5\n",
      "7.169433 7.5 7.5\n",
      "8.091944 7.5 10.0\n",
      "7.7673006 7.5 10.0\n",
      "8.80626 10 10.0\n",
      "8.424608 7.5 7.5\n",
      "7.9119263 7.5 7.5\n",
      "7.6256275 7.5 7.5\n",
      "8.038233 7.5 10.0\n",
      "7.2625117 7.5 5.0\n",
      "6.7822204 7.5 7.5\n",
      "7.144688 7.5 7.5\n",
      "8.487054 7.5 10.0\n",
      "8.587625 7.5 10.0\n",
      "7.0492554 7.5 7.5\n",
      "6.342285 7.5 5.0\n",
      "6.38799 7.5 10.0\n",
      "7.1295676 7.5 7.5\n",
      "7.4619455 7.5 5.0\n",
      "4.3434243 5 7.5\n",
      "9.680006 10 10.0\n",
      "6.9844713 7.5 7.5\n",
      "8.150993 7.5 2.5\n",
      "7.2638707 7.5 7.5\n",
      "7.212571 7.5 7.5\n",
      "8.798696 10 10.0\n",
      "7.992386 7.5 7.5\n",
      "8.897947 10 7.5\n",
      "6.931009 7.5 10.0\n",
      "5.980958 5 7.5\n",
      "7.5002656 7.5 7.5\n",
      "8.1958885 7.5 10.0\n",
      "8.373877 7.5 2.5\n",
      "6.0194907 5 5.0\n",
      "5.157937 5 2.5\n",
      "7.683049 7.5 7.5\n",
      "7.460378 7.5 7.5\n",
      "8.31866 7.5 10.0\n",
      "6.86084 7.5 2.5\n",
      "6.9291873 7.5 7.5\n",
      "7.3484073 7.5 7.5\n",
      "7.491715 7.5 7.5\n",
      "6.5854144 7.5 7.5\n",
      "8.226849 7.5 10.0\n",
      "7.6999984 7.5 10.0\n",
      "6.993706 7.5 7.5\n",
      "7.161355 7.5 7.5\n",
      "8.086059 7.5 7.5\n",
      "4.4511447 5 7.5\n",
      "7.724736 7.5 5.0\n",
      "6.8132577 7.5 7.5\n",
      "8.556672 7.5 7.5\n",
      "8.3048 7.5 10.0\n",
      "8.198301 7.5 10.0\n",
      "7.0581517 7.5 7.5\n",
      "8.775366 10 10.0\n",
      "9.535846 10 10.0\n",
      "6.279993 7.5 10.0\n",
      "8.58876 7.5 10.0\n",
      "8.370449 7.5 10.0\n",
      "5.8076835 5 0.0\n",
      "9.35909 10 10.0\n",
      "8.692758 7.5 10.0\n",
      "6.409334 7.5 7.5\n",
      "7.706914 7.5 7.5\n",
      "7.9264364 7.5 10.0\n",
      "8.374477 7.5 10.0\n",
      "5.5105133 5 2.5\n",
      "6.679524 7.5 7.5\n",
      "5.9542613 5 7.5\n",
      "6.602333 7.5 7.5\n",
      "5.38588 5 2.5\n",
      "7.379202 7.5 7.5\n",
      "8.2308655 7.5 10.0\n",
      "9.017106 10 10.0\n",
      "7.245659 7.5 7.5\n",
      "7.0276556 7.5 7.5\n",
      "7.7206063 7.5 10.0\n",
      "7.5445886 7.5 7.5\n",
      "8.026932 7.5 7.5\n",
      "7.314439 7.5 10.0\n",
      "8.70756 7.5 7.5\n",
      "7.4323936 7.5 7.5\n",
      "5.741646 5 7.5\n",
      "7.568746 7.5 5.0\n",
      "3.4795103 2.5 0.0\n",
      "9.297452 10 10.0\n",
      "6.5596867 7.5 7.5\n",
      "7.263273 7.5 10.0\n",
      "4.1708136 5 2.5\n",
      "8.284242 7.5 5.0\n",
      "7.6258106 7.5 2.5\n",
      "8.794491 10 10.0\n",
      "6.4097238 7.5 10.0\n",
      "6.2405357 5 7.5\n",
      "8.163931 7.5 10.0\n",
      "8.669819 7.5 7.5\n",
      "6.081125 5 2.5\n",
      "9.173985 10 10.0\n",
      "7.297164 7.5 10.0\n",
      "6.5417137 7.5 5.0\n",
      "8.056555 7.5 7.5\n",
      "8.813874 10 5.0\n",
      "7.6736975 7.5 10.0\n",
      "5.195836 5 2.5\n",
      "7.1033144 7.5 7.5\n",
      "8.408995 7.5 10.0\n",
      "7.2171135 7.5 7.5\n",
      "7.4275546 7.5 7.5\n",
      "9.351756 10 10.0\n",
      "7.830738 7.5 10.0\n",
      "6.8312693 7.5 10.0\n",
      "6.898449 7.5 2.5\n",
      "4.3234873 5 2.5\n",
      "9.103485 10 10.0\n",
      "7.1605515 7.5 5.0\n",
      "5.3991456 5 7.5\n",
      "6.0527334 5 10.0\n",
      "6.081086 5 10.0\n",
      "7.685126 7.5 2.5\n",
      "8.429449 7.5 10.0\n",
      "7.0713825 7.5 2.5\n",
      "8.441404 7.5 10.0\n",
      "9.217741 10 10.0\n",
      "6.127519 5 5.0\n",
      "8.317212 7.5 7.5\n",
      "8.196624 7.5 7.5\n",
      "7.9834213 7.5 10.0\n",
      "5.641536 5 5.0\n",
      "6.13573 5 7.5\n",
      "9.109113 10 10.0\n",
      "5.9636765 5 5.0\n",
      "6.5842867 7.5 7.5\n",
      "7.7114897 7.5 10.0\n",
      "6.721934 7.5 5.0\n",
      "7.4219737 7.5 7.5\n",
      "8.45464 7.5 10.0\n",
      "7.1086082 7.5 7.5\n",
      "6.7797236 7.5 7.5\n",
      "9.308021 10 10.0\n",
      "7.287206 7.5 10.0\n",
      "8.959152 10 10.0\n",
      "8.951061 10 10.0\n",
      "7.508816 7.5 7.5\n",
      "5.068099 5 10.0\n",
      "7.4520006 7.5 7.5\n",
      "7.061678 7.5 10.0\n",
      "7.398614 7.5 10.0\n",
      "7.470941 7.5 7.5\n",
      "6.022891 5 2.5\n",
      "6.1525383 5 5.0\n",
      "6.6300006 7.5 7.5\n",
      "7.019757 7.5 7.5\n",
      "7.284956 7.5 7.5\n",
      "8.901727 10 10.0\n",
      "8.746807 7.5 7.5\n",
      "8.050109 7.5 7.5\n",
      "6.6938796 7.5 7.5\n",
      "8.166225 7.5 10.0\n",
      "7.4254622 7.5 7.5\n",
      "7.721778 7.5 10.0\n",
      "7.1940374 7.5 7.5\n",
      "9.039702 10 10.0\n",
      "8.23031 7.5 10.0\n",
      "9.2777815 10 10.0\n",
      "9.097258 10 10.0\n",
      "7.314315 7.5 10.0\n",
      "7.57996 7.5 7.5\n",
      "6.975276 7.5 7.5\n",
      "7.7763925 7.5 2.5\n",
      "7.2128057 7.5 7.5\n",
      "7.4142804 7.5 10.0\n",
      "8.633662 7.5 7.5\n",
      "8.816249 10 7.5\n",
      "7.356138 7.5 7.5\n",
      "8.937003 10 7.5\n",
      "5.4896417 5 7.5\n",
      "8.899139 10 10.0\n",
      "7.5480833 7.5 7.5\n",
      "9.131315 10 7.5\n",
      "6.890008 7.5 7.5\n",
      "7.1961164 7.5 5.0\n",
      "7.293993 7.5 7.5\n",
      "8.294857 7.5 7.5\n",
      "8.777818 10 10.0\n",
      "9.284302 10 7.5\n",
      "8.583701 7.5 10.0\n",
      "8.726537 7.5 5.0\n",
      "6.5027018 7.5 10.0\n",
      "8.27832 7.5 10.0\n",
      "7.3361435 7.5 10.0\n",
      "4.8088937 5 7.5\n",
      "3.8102713 5 10.0\n",
      "6.2598176 7.5 10.0\n",
      "8.959952 10 5.0\n",
      "4.4287815 5 2.5\n",
      "9.2451515 10 10.0\n",
      "7.2926154 7.5 10.0\n",
      "7.317317 7.5 7.5\n",
      "7.9175944 7.5 10.0\n",
      "7.275666 7.5 2.5\n",
      "7.592629 7.5 7.5\n",
      "6.2287884 5 7.5\n",
      "7.5004053 7.5 7.5\n",
      "7.9783263 7.5 10.0\n",
      "8.9561 10 10.0\n",
      "5.882693 5 7.5\n",
      "4.985522 5 7.5\n",
      "6.6387334 7.5 10.0\n",
      "7.6975536 7.5 10.0\n",
      "8.455681 7.5 10.0\n",
      "7.876215 7.5 10.0\n",
      "8.567278 7.5 10.0\n",
      "8.6879225 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7574396 7.5 7.5\n",
      "7.146657 7.5 10.0\n",
      "8.529603 7.5 5.0\n",
      "7.1334844 7.5 7.5\n",
      "5.8378696 5 2.5\n",
      "7.2832446 7.5 7.5\n",
      "7.612223 7.5 7.5\n",
      "6.818888 7.5 7.5\n",
      "7.420518 7.5 7.5\n",
      "7.2980275 7.5 5.0\n",
      "5.7383604 5 2.5\n",
      "6.2615175 7.5 7.5\n",
      "6.6522627 7.5 7.5\n",
      "6.1226707 5 7.5\n",
      "4.436254 5 7.5\n",
      "7.765819 7.5 7.5\n",
      "7.6464105 7.5 5.0\n",
      "7.4550295 7.5 10.0\n",
      "8.247253 7.5 7.5\n",
      "7.783889 7.5 10.0\n",
      "6.8527164 7.5 7.5\n",
      "7.6722775 7.5 7.5\n",
      "7.215664 7.5 2.5\n",
      "6.639135 7.5 10.0\n",
      "7.11952 7.5 7.5\n",
      "8.538041 7.5 10.0\n",
      "9.917143 10 10.0\n",
      "7.593615 7.5 10.0\n",
      "8.31717 7.5 7.5\n",
      "7.4880567 7.5 2.5\n",
      "6.509329 7.5 7.5\n",
      "6.3432565 7.5 2.5\n",
      "8.837619 10 10.0\n",
      "7.251931 7.5 7.5\n",
      "5.1459727 5 2.5\n",
      "4.7939253 5 0.0\n",
      "7.554099 7.5 10.0\n",
      "5.7530193 5 2.5\n",
      "7.1315784 7.5 10.0\n",
      "6.6707196 7.5 7.5\n",
      "9.495126 10 10.0\n",
      "7.509618 7.5 10.0\n",
      "7.072568 7.5 10.0\n",
      "8.936038 10 10.0\n",
      "7.7594514 7.5 7.5\n",
      "7.373159 7.5 10.0\n",
      "7.533154 7.5 10.0\n",
      "9.063518 10 7.5\n",
      "6.768366 7.5 2.5\n",
      "6.259156 7.5 7.5\n",
      "7.2441187 7.5 7.5\n",
      "7.7757993 7.5 7.5\n",
      "6.8099904 7.5 5.0\n",
      "6.2015033 5 2.5\n",
      "6.786014 7.5 5.0\n",
      "8.877727 10 10.0\n",
      "8.141465 7.5 5.0\n",
      "8.738115 7.5 10.0\n",
      "7.3168907 7.5 5.0\n",
      "7.533999 7.5 7.5\n",
      "7.1918025 7.5 10.0\n",
      "9.0334425 10 7.5\n",
      "6.937531 7.5 10.0\n",
      "7.204334 7.5 10.0\n",
      "7.071659 7.5 2.5\n",
      "7.742923 7.5 7.5\n",
      "6.729344 7.5 10.0\n",
      "8.120781 7.5 10.0\n",
      "6.0358644 5 7.5\n",
      "7.355685 7.5 10.0\n",
      "6.647059 7.5 5.0\n",
      "7.568609 7.5 10.0\n",
      "7.5426946 7.5 7.5\n",
      "8.941104 10 7.5\n",
      "6.500508 7.5 5.0\n",
      "7.668667 7.5 10.0\n",
      "7.583597 7.5 5.0\n",
      "8.444164 7.5 10.0\n",
      "7.6539226 7.5 5.0\n",
      "8.852838 10 7.5\n",
      "6.603188 7.5 7.5\n",
      "6.876526 7.5 7.5\n",
      "8.750996 10 10.0\n",
      "7.1613374 7.5 7.5\n",
      "7.11142 7.5 7.5\n",
      "6.9658685 7.5 10.0\n",
      "7.299549 7.5 10.0\n",
      "8.605099 7.5 7.5\n",
      "7.939755 7.5 7.5\n",
      "8.517868 7.5 7.5\n",
      "7.1593566 7.5 10.0\n",
      "6.0412936 5 7.5\n",
      "6.973075 7.5 7.5\n",
      "6.5312505 7.5 10.0\n",
      "9.309207 10 7.5\n",
      "9.299072 10 10.0\n",
      "5.751255 5 5.0\n",
      "5.9615045 5 5.0\n",
      "8.295078 7.5 10.0\n",
      "8.866927 10 7.5\n",
      "7.134985 7.5 7.5\n",
      "8.729123 7.5 7.5\n",
      "6.3805733 7.5 5.0\n",
      "7.4307704 7.5 2.5\n",
      "7.6332393 7.5 10.0\n",
      "8.731802 7.5 10.0\n",
      "6.043547 5 7.5\n",
      "8.777002 10 10.0\n",
      "7.8185496 7.5 10.0\n",
      "8.107146 7.5 7.5\n",
      "6.249166 5 7.5\n",
      "7.0336714 7.5 7.5\n",
      "8.262865 7.5 10.0\n",
      "7.272145 7.5 7.5\n",
      "7.7072086 7.5 7.5\n",
      "3.7535827 5 0.0\n",
      "8.681874 7.5 10.0\n",
      "6.8649592 7.5 2.5\n",
      "6.7205205 7.5 5.0\n",
      "5.160978 5 2.5\n",
      "9.01724 10 10.0\n",
      "7.6697683 7.5 10.0\n",
      "7.3892393 7.5 2.5\n",
      "8.7398 7.5 10.0\n",
      "8.93222 10 10.0\n",
      "7.3687215 7.5 7.5\n",
      "6.8376613 7.5 2.5\n",
      "7.203699 7.5 10.0\n",
      "6.5606947 7.5 5.0\n",
      "6.350559 7.5 2.5\n",
      "7.1001077 7.5 7.5\n",
      "8.672239 7.5 7.5\n",
      "8.212751 7.5 5.0\n",
      "7.2803283 7.5 7.5\n",
      "7.4151154 7.5 0.0\n",
      "5.0942025 5 5.0\n",
      "6.186628 5 5.0\n",
      "6.751465 7.5 5.0\n",
      "5.196508 5 2.5\n",
      "7.063168 7.5 7.5\n",
      "7.888785 7.5 10.0\n",
      "7.8750644 7.5 10.0\n",
      "7.4212046 7.5 5.0\n",
      "7.041174 7.5 7.5\n",
      "7.1120834 7.5 5.0\n",
      "7.048967 7.5 7.5\n",
      "7.2169 7.5 5.0\n",
      "8.517978 7.5 7.5\n",
      "7.2771215 7.5 2.5\n",
      "6.7754645 7.5 7.5\n",
      "7.521382 7.5 7.5\n",
      "9.355579 10 10.0\n",
      "7.3347387 7.5 7.5\n",
      "7.4087734 7.5 7.5\n",
      "6.7626157 7.5 10.0\n",
      "3.7648726 5 10.0\n",
      "8.51007 7.5 2.5\n",
      "7.98059 7.5 10.0\n",
      "7.1871157 7.5 10.0\n",
      "7.886685 7.5 5.0\n",
      "8.61995 7.5 7.5\n",
      "6.3969207 7.5 2.5\n",
      "9.26906 10 10.0\n",
      "6.4390635 7.5 2.5\n",
      "5.612626 5 2.5\n",
      "9.184707 10 7.5\n",
      "7.366966 7.5 10.0\n",
      "6.931749 7.5 5.0\n",
      "7.1927876 7.5 5.0\n",
      "8.423054 7.5 10.0\n",
      "7.4575047 7.5 7.5\n",
      "8.372066 7.5 10.0\n",
      "7.172108 7.5 7.5\n",
      "7.591867 7.5 2.5\n",
      "7.0086107 7.5 10.0\n",
      "8.654689 7.5 10.0\n",
      "7.601871 7.5 10.0\n",
      "7.7088895 7.5 7.5\n",
      "7.0183425 7.5 7.5\n",
      "8.605385 7.5 10.0\n",
      "8.634449 7.5 10.0\n",
      "3.3498142 2.5 7.5\n",
      "6.9685354 7.5 5.0\n",
      "7.3649716 7.5 7.5\n",
      "5.3046613 5 0.0\n",
      "7.647665 7.5 10.0\n",
      "6.63456 7.5 7.5\n",
      "9.344967 10 10.0\n",
      "6.812086 7.5 5.0\n",
      "7.3582454 7.5 10.0\n",
      "6.210463 5 2.5\n",
      "6.128749 5 10.0\n",
      "8.783801 10 10.0\n",
      "5.6959405 5 0.0\n",
      "9.169274 10 10.0\n",
      "8.075753 7.5 5.0\n",
      "7.017008 7.5 7.5\n",
      "7.362904 7.5 10.0\n",
      "9.165203 10 10.0\n",
      "6.9268236 7.5 5.0\n",
      "7.5351515 7.5 7.5\n",
      "7.181576 7.5 7.5\n",
      "7.651634 7.5 7.5\n",
      "7.6909857 7.5 5.0\n",
      "8.45688 7.5 7.5\n",
      "7.5970693 7.5 2.5\n",
      "7.509553 7.5 7.5\n",
      "8.765275 10 7.5\n",
      "6.52531 7.5 5.0\n",
      "9.021553 10 7.5\n",
      "7.379155 7.5 7.5\n",
      "8.720298 7.5 10.0\n",
      "8.234053 7.5 10.0\n",
      "8.6726675 7.5 10.0\n",
      "7.9455714 7.5 2.5\n",
      "7.494399 7.5 10.0\n",
      "4.8884907 5 0.0\n",
      "8.674735 7.5 10.0\n",
      "7.2710023 7.5 10.0\n",
      "7.250939 7.5 7.5\n",
      "8.4149475 7.5 7.5\n",
      "7.2949195 7.5 5.0\n",
      "7.0001464 7.5 7.5\n",
      "9.594848 10 10.0\n",
      "9.066174 10 10.0\n",
      "7.7019243 7.5 10.0\n",
      "8.730019 7.5 10.0\n",
      "6.0210137 5 2.5\n",
      "9.244882 10 10.0\n",
      "8.176205 7.5 10.0\n",
      "7.230062 7.5 10.0\n",
      "7.140302 7.5 10.0\n",
      "6.3330617 7.5 7.5\n",
      "8.925147 10 10.0\n",
      "7.849755 7.5 7.5\n",
      "6.778028 7.5 10.0\n",
      "9.038649 10 10.0\n",
      "8.382513 7.5 7.5\n",
      "6.8663383 7.5 7.5\n",
      "9.44787 10 7.5\n",
      "6.3165092 7.5 10.0\n",
      "7.796849 7.5 5.0\n",
      "5.3964906 5 0.0\n",
      "3.043529 2.5 0.0\n",
      "8.822692 10 7.5\n",
      "6.5541563 7.5 5.0\n",
      "5.1540256 5 5.0\n",
      "8.641922 7.5 5.0\n",
      "6.859657 7.5 5.0\n",
      "7.480814 7.5 7.5\n",
      "5.4278364 5 5.0\n",
      "8.3631 7.5 10.0\n",
      "7.4739776 7.5 5.0\n",
      "5.390557 5 2.5\n",
      "4.5011883 5 2.5\n",
      "8.504404 7.5 10.0\n",
      "5.083326 5 0.0\n",
      "7.648808 7.5 2.5\n",
      "7.499165 7.5 10.0\n",
      "7.6955414 7.5 7.5\n",
      "7.681861 7.5 10.0\n",
      "6.754502 7.5 7.5\n",
      "7.2869983 7.5 7.5\n",
      "6.365996 7.5 2.5\n",
      "5.204197 5 2.5\n",
      "5.9054847 5 2.5\n",
      "7.972956 7.5 10.0\n",
      "7.422367 7.5 7.5\n",
      "8.446764 7.5 10.0\n",
      "7.7334347 7.5 5.0\n",
      "7.28498 7.5 10.0\n",
      "7.398317 7.5 5.0\n",
      "6.4745936 7.5 7.5\n",
      "9.028527 10 10.0\n",
      "8.540679 7.5 10.0\n",
      "7.104635 7.5 10.0\n",
      "7.0410643 7.5 7.5\n",
      "6.32346 7.5 5.0\n",
      "6.629197 7.5 7.5\n",
      "8.973448 10 10.0\n",
      "8.889798 10 7.5\n",
      "6.9359818 7.5 5.0\n",
      "7.9293647 7.5 7.5\n",
      "6.583788 7.5 7.5\n",
      "7.3018885 7.5 7.5\n",
      "7.6276655 7.5 5.0\n",
      "7.5687647 7.5 10.0\n",
      "6.1155944 5 7.5\n",
      "6.715773 7.5 2.5\n",
      "5.936355 5 7.5\n",
      "7.531159 7.5 10.0\n",
      "8.485824 7.5 10.0\n",
      "4.843729 5 5.0\n",
      "8.509376 7.5 10.0\n",
      "7.9991617 7.5 10.0\n",
      "9.403778 10 7.5\n",
      "10.0034485 10 7.5\n",
      "8.21 7.5 10.0\n",
      "7.479756 7.5 10.0\n",
      "7.0194397 7.5 7.5\n",
      "8.201563 7.5 7.5\n",
      "8.001001 7.5 7.5\n",
      "6.2427216 5 5.0\n",
      "6.8377757 7.5 2.5\n",
      "8.987858 10 10.0\n",
      "9.340121 10 10.0\n",
      "7.528078 7.5 5.0\n",
      "8.86362 10 10.0\n",
      "8.0806875 7.5 0.0\n",
      "7.5769277 7.5 7.5\n",
      "7.6044216 7.5 7.5\n",
      "7.4456353 7.5 10.0\n",
      "7.4248395 7.5 10.0\n",
      "8.448914 7.5 7.5\n",
      "6.783118 7.5 10.0\n",
      "7.9123955 7.5 7.5\n",
      "7.006884 7.5 7.5\n",
      "7.7470303 7.5 10.0\n",
      "7.163418 7.5 7.5\n",
      "7.277816 7.5 7.5\n",
      "8.656313 7.5 10.0\n",
      "8.476597 7.5 7.5\n",
      "7.624916 7.5 7.5\n",
      "7.606934 7.5 5.0\n",
      "8.754588 10 10.0\n",
      "8.915235 10 10.0\n",
      "7.46821 7.5 7.5\n",
      "8.009338 7.5 10.0\n",
      "7.4551687 7.5 10.0\n",
      "8.752472 10 10.0\n",
      "7.84375 7.5 7.5\n",
      "9.731726 10 7.5\n",
      "5.265014 5 2.5\n",
      "6.9478273 7.5 7.5\n",
      "7.893033 7.5 2.5\n",
      "7.1356273 7.5 10.0\n",
      "7.3350983 7.5 7.5\n",
      "7.393844 7.5 7.5\n",
      "7.138094 7.5 7.5\n",
      "7.0465016 7.5 5.0\n",
      "8.300276 7.5 7.5\n",
      "6.698205 7.5 10.0\n",
      "6.934066 7.5 7.5\n",
      "8.498011 7.5 10.0\n",
      "8.801865 10 10.0\n",
      "8.038824 7.5 10.0\n",
      "9.275744 10 10.0\n",
      "7.6378508 7.5 7.5\n",
      "9.272494 10 10.0\n",
      "6.8717723 7.5 7.5\n",
      "7.825387 7.5 2.5\n",
      "4.575383 5 2.5\n",
      "7.338511 7.5 2.5\n",
      "8.965319 10 10.0\n",
      "6.441193 7.5 7.5\n",
      "8.146828 7.5 10.0\n",
      "6.925268 7.5 2.5\n",
      "4.107786 5 2.5\n",
      "8.620431 7.5 10.0\n",
      "7.274011 7.5 7.5\n",
      "5.253542 5 2.5\n",
      "7.1724224 7.5 5.0\n",
      "8.045315 7.5 7.5\n",
      "7.221854 7.5 7.5\n",
      "6.989506 7.5 5.0\n",
      "5.474185 5 5.0\n",
      "6.8879514 7.5 7.5\n",
      "7.6981916 7.5 7.5\n",
      "6.1464844 5 5.0\n",
      "7.589906 7.5 7.5\n",
      "7.516305 7.5 2.5\n",
      "7.3983226 7.5 7.5\n",
      "8.487232 7.5 5.0\n",
      "7.326425 7.5 7.5\n",
      "5.920574 5 5.0\n",
      "7.580915 7.5 10.0\n",
      "7.974285 7.5 10.0\n",
      "7.279925 7.5 7.5\n",
      "6.843707 7.5 10.0\n",
      "8.773031 10 10.0\n",
      "6.9563394 7.5 10.0\n",
      "8.314357 7.5 10.0\n",
      "7.712937 7.5 5.0\n",
      "7.904101 7.5 10.0\n",
      "5.777071 5 2.5\n",
      "8.881493 10 7.5\n",
      "5.931883 5 2.5\n",
      "7.4885664 7.5 5.0\n",
      "7.2951126 7.5 5.0\n",
      "6.5661273 7.5 10.0\n",
      "6.993216 7.5 2.5\n",
      "7.374301 7.5 7.5\n",
      "7.5812654 7.5 5.0\n",
      "5.222502 5 0.0\n",
      "7.185099 7.5 10.0\n",
      "7.9184823 7.5 7.5\n",
      "6.4165473 7.5 5.0\n",
      "8.590414 7.5 7.5\n",
      "9.219994 10 7.5\n",
      "9.152784 10 7.5\n",
      "7.6017833 7.5 7.5\n",
      "8.836202 10 7.5\n",
      "8.775937 10 2.5\n",
      "7.610288 7.5 10.0\n",
      "7.7863674 7.5 10.0\n",
      "6.8701906 7.5 7.5\n",
      "8.082169 7.5 10.0\n",
      "7.43944 7.5 10.0\n",
      "7.8321486 7.5 0.0\n",
      "7.291096 7.5 7.5\n",
      "8.14492 7.5 10.0\n",
      "6.605267 7.5 7.5\n",
      "6.269217 7.5 7.5\n",
      "7.838585 7.5 7.5\n",
      "8.8443775 10 10.0\n",
      "6.777845 7.5 10.0\n",
      "6.5328045 7.5 7.5\n",
      "6.5589867 7.5 7.5\n",
      "8.7802925 10 7.5\n",
      "7.536606 7.5 10.0\n",
      "7.2934513 7.5 10.0\n",
      "7.374728 7.5 7.5\n",
      "6.3944173 7.5 7.5\n",
      "5.7635794 5 2.5\n",
      "3.656596 2.5 2.5\n",
      "7.4562345 7.5 10.0\n",
      "8.499607 7.5 7.5\n",
      "7.003429 7.5 2.5\n",
      "7.5013814 7.5 5.0\n",
      "6.5105658 7.5 2.5\n",
      "6.034872 5 7.5\n",
      "9.135196 10 7.5\n",
      "6.1855226 5 5.0\n",
      "6.432571 7.5 7.5\n",
      "7.159272 7.5 5.0\n",
      "7.2345076 7.5 7.5\n",
      "8.31964 7.5 10.0\n",
      "7.425407 7.5 5.0\n",
      "8.516319 7.5 10.0\n",
      "7.8409014 7.5 10.0\n",
      "7.0929847 7.5 7.5\n",
      "7.2338347 7.5 2.5\n",
      "7.4362245 7.5 10.0\n",
      "8.501143 7.5 10.0\n",
      "5.954244 5 5.0\n",
      "8.66079 7.5 10.0\n",
      "8.956649 10 10.0\n",
      "6.1084347 5 2.5\n",
      "8.614374 7.5 7.5\n",
      "8.822612 10 7.5\n",
      "7.343077 7.5 10.0\n",
      "8.150848 7.5 10.0\n",
      "6.8793154 7.5 7.5\n",
      "9.04114 10 10.0\n",
      "4.342376 5 5.0\n",
      "9.2200985 10 10.0\n",
      "8.320372 7.5 10.0\n",
      "8.98884 10 2.5\n",
      "7.4062414 7.5 7.5\n",
      "5.727801 5 2.5\n",
      "7.2629056 7.5 7.5\n",
      "7.1584306 7.5 10.0\n",
      "7.9017653 7.5 7.5\n",
      "6.979982 7.5 2.5\n",
      "4.926012 5 10.0\n",
      "9.037029 10 10.0\n",
      "5.8635283 5 10.0\n",
      "6.578788 7.5 5.0\n",
      "7.562007 7.5 7.5\n",
      "7.268746 7.5 7.5\n",
      "7.8298683 7.5 10.0\n",
      "6.9110427 7.5 10.0\n",
      "7.2487926 7.5 7.5\n",
      "7.873275 7.5 7.5\n",
      "9.161444 10 10.0\n",
      "7.1817064 7.5 10.0\n",
      "6.5394335 7.5 10.0\n",
      "7.8899946 7.5 10.0\n",
      "7.1179533 7.5 10.0\n",
      "8.062588 7.5 7.5\n",
      "7.4147215 7.5 7.5\n",
      "6.47768 7.5 7.5\n",
      "8.538068 7.5 5.0\n",
      "9.200843 10 5.0\n",
      "7.2260056 7.5 7.5\n",
      "8.386311 7.5 7.5\n",
      "7.5643725 7.5 7.5\n",
      "7.143354 7.5 7.5\n",
      "7.4040995 7.5 7.5\n",
      "7.7747183 7.5 10.0\n",
      "6.9252405 7.5 7.5\n",
      "7.499321 7.5 7.5\n",
      "7.625387 7.5 7.5\n",
      "8.492781 7.5 7.5\n",
      "7.7727137 7.5 10.0\n",
      "9.410736 10 10.0\n",
      "8.4212265 7.5 7.5\n",
      "5.0432887 5 2.5\n",
      "7.5579004 7.5 10.0\n",
      "7.3813653 7.5 10.0\n",
      "7.366298 7.5 2.5\n",
      "8.751657 10 10.0\n",
      "6.9692817 7.5 7.5\n",
      "7.3837996 7.5 10.0\n",
      "4.7128754 5 7.5\n",
      "8.59533 7.5 10.0\n",
      "8.823772 10 10.0\n",
      "8.283888 7.5 7.5\n",
      "5.4611855 5 7.5\n",
      "9.037518 10 10.0\n",
      "7.6592607 7.5 10.0\n",
      "6.630636 7.5 2.5\n",
      "5.9215016 5 7.5\n",
      "8.906701 10 7.5\n",
      "8.294857 7.5 7.5\n",
      "7.245071 7.5 7.5\n",
      "9.327529 10 10.0\n",
      "5.752332 5 7.5\n",
      "7.198105 7.5 2.5\n",
      "7.2243733 7.5 5.0\n",
      "8.646602 7.5 10.0\n",
      "9.225362 10 7.5\n",
      "5.675704 5 7.5\n",
      "7.522191 7.5 10.0\n",
      "8.761958 10 10.0\n",
      "5.250728 5 0.0\n",
      "7.241708 7.5 7.5\n",
      "7.1478324 7.5 2.5\n",
      "7.6252623 7.5 7.5\n",
      "6.9204516 7.5 7.5\n",
      "7.2942324 7.5 7.5\n",
      "7.613877 7.5 10.0\n",
      "6.9543653 7.5 7.5\n",
      "5.7603903 5 10.0\n",
      "9.71579 10 10.0\n",
      "7.1610374 7.5 7.5\n",
      "7.948576 7.5 10.0\n",
      "6.101103 5 7.5\n",
      "7.369439 7.5 10.0\n",
      "8.806883 10 10.0\n",
      "5.090892 5 2.5\n",
      "7.281867 7.5 10.0\n",
      "7.620492 7.5 7.5\n",
      "9.132525 10 10.0\n",
      "9.047476 10 10.0\n",
      "9.00143 10 10.0\n",
      "8.344004 7.5 7.5\n",
      "7.942431 7.5 10.0\n",
      "7.137034 7.5 7.5\n",
      "6.4771767 7.5 5.0\n",
      "5.3286996 5 7.5\n",
      "8.014618 7.5 7.5\n",
      "6.5817986 7.5 5.0\n",
      "8.97556 10 7.5\n",
      "8.652091 7.5 7.5\n",
      "7.585423 7.5 2.5\n",
      "6.96262 7.5 10.0\n",
      "5.509442 5 7.5\n",
      "7.354374 7.5 2.5\n",
      "7.0831857 7.5 7.5\n",
      "7.798883 7.5 5.0\n",
      "7.3192677 7.5 5.0\n",
      "6.5994096 7.5 7.5\n",
      "7.430019 7.5 7.5\n",
      "8.623701 7.5 7.5\n",
      "7.7108502 7.5 5.0\n",
      "8.494919 7.5 2.5\n",
      "3.7998834 5 0.0\n",
      "6.1068435 5 0.0\n",
      "6.4543977 7.5 5.0\n",
      "7.688884 7.5 10.0\n",
      "9.428779 10 10.0\n",
      "6.88592 7.5 7.5\n",
      "7.1319466 7.5 7.5\n",
      "8.133987 7.5 10.0\n",
      "7.638917 7.5 7.5\n",
      "8.382343 7.5 10.0\n",
      "6.763493 7.5 2.5\n",
      "6.5229025 7.5 5.0\n",
      "8.629407 7.5 7.5\n",
      "6.7921944 7.5 10.0\n",
      "6.1916733 5 10.0\n",
      "8.179028 7.5 10.0\n",
      "7.3136697 7.5 5.0\n",
      "7.456883 7.5 2.5\n",
      "7.1727877 7.5 2.5\n",
      "8.083348 7.5 10.0\n",
      "7.8969812 7.5 10.0\n",
      "6.4721923 7.5 7.5\n",
      "7.4286 7.5 7.5\n",
      "8.005686 7.5 7.5\n",
      "9.131033 10 10.0\n",
      "9.200788 10 7.5\n",
      "9.776914 10 10.0\n",
      "7.308954 7.5 7.5\n",
      "7.3787804 7.5 7.5\n",
      "7.10879 7.5 5.0\n",
      "7.5007076 7.5 7.5\n",
      "4.7373276 5 2.5\n",
      "7.698946 7.5 7.5\n",
      "7.825532 7.5 2.5\n",
      "5.112576 5 10.0\n",
      "8.71077 7.5 7.5\n",
      "8.783698 10 7.5\n",
      "8.000311 7.5 10.0\n",
      "5.8526053 5 5.0\n",
      "7.151727 7.5 10.0\n",
      "8.853235 10 10.0\n",
      "6.983809 7.5 7.5\n",
      "7.014088 7.5 10.0\n",
      "7.175038 7.5 2.5\n",
      "9.147533 10 10.0\n",
      "7.1667047 7.5 10.0\n",
      "6.9234366 7.5 7.5\n",
      "8.093098 7.5 10.0\n",
      "8.676489 7.5 7.5\n",
      "7.061639 7.5 10.0\n",
      "7.740413 7.5 5.0\n",
      "8.39974 7.5 10.0\n",
      "9.170129 10 10.0\n",
      "7.397921 7.5 7.5\n",
      "4.475643 5 5.0\n",
      "6.3607326 7.5 7.5\n",
      "8.690546 7.5 7.5\n",
      "6.9081674 7.5 7.5\n",
      "7.314212 7.5 7.5\n",
      "8.531172 7.5 10.0\n",
      "6.959191 7.5 7.5\n",
      "7.404154 7.5 10.0\n",
      "7.47721 7.5 2.5\n",
      "8.420097 7.5 7.5\n",
      "4.8955836 5 2.5\n",
      "6.703501 7.5 10.0\n",
      "6.7747555 7.5 7.5\n",
      "9.1996355 10 7.5\n",
      "7.032372 7.5 5.0\n",
      "7.9516516 7.5 10.0\n",
      "5.8556833 5 7.5\n",
      "7.3941374 7.5 5.0\n",
      "7.621516 7.5 10.0\n",
      "7.4530396 7.5 7.5\n",
      "5.3358355 5 0.0\n",
      "8.779274 10 7.5\n",
      "7.5688725 7.5 10.0\n",
      "7.018472 7.5 2.5\n",
      "6.9987335 7.5 2.5\n",
      "8.985204 10 10.0\n",
      "8.956691 10 7.5\n",
      "8.448505 7.5 10.0\n",
      "6.7558117 7.5 7.5\n",
      "8.861679 10 7.5\n",
      "8.519202 7.5 7.5\n",
      "6.765058 7.5 7.5\n",
      "7.3710456 7.5 5.0\n",
      "7.425432 7.5 7.5\n",
      "6.4374146 7.5 7.5\n",
      "5.760561 5 5.0\n",
      "6.873416 7.5 7.5\n",
      "8.750112 10 7.5\n",
      "8.54989 7.5 5.0\n",
      "7.544607 7.5 7.5\n",
      "6.992478 7.5 7.5\n",
      "7.0540113 7.5 7.5\n",
      "5.8190494 5 7.5\n",
      "7.925432 7.5 7.5\n",
      "6.305715 7.5 7.5\n",
      "8.526509 7.5 7.5\n",
      "8.55321 7.5 10.0\n",
      "6.286523 7.5 5.0\n",
      "7.367794 7.5 10.0\n",
      "6.9315166 7.5 7.5\n",
      "7.518938 7.5 7.5\n",
      "7.978758 7.5 10.0\n",
      "8.811152 10 10.0\n",
      "6.778396 7.5 7.5\n",
      "7.2507076 7.5 10.0\n",
      "8.848014 10 7.5\n",
      "7.60558 7.5 10.0\n",
      "7.777097 7.5 10.0\n",
      "9.21131 10 10.0\n",
      "7.2263703 7.5 10.0\n",
      "8.717333 7.5 7.5\n",
      "7.3780704 7.5 10.0\n",
      "8.837742 10 10.0\n",
      "6.80549 7.5 7.5\n",
      "7.434809 7.5 10.0\n",
      "5.8019896 5 10.0\n",
      "6.4198833 7.5 10.0\n",
      "6.955144 7.5 7.5\n",
      "8.399872 7.5 10.0\n",
      "7.218571 7.5 7.5\n",
      "8.315033 7.5 10.0\n",
      "7.4616976 7.5 10.0\n",
      "4.5755734 5 10.0\n",
      "8.884412 10 10.0\n",
      "7.234712 7.5 7.5\n",
      "7.2955546 7.5 7.5\n",
      "8.162269 7.5 5.0\n",
      "9.323351 10 7.5\n",
      "7.0851483 7.5 10.0\n",
      "6.8806133 7.5 7.5\n",
      "8.919209 10 10.0\n",
      "5.625055 5 0.0\n",
      "7.1418505 7.5 5.0\n",
      "6.501433 7.5 5.0\n",
      "7.3581285 7.5 7.5\n",
      "3.4804149 2.5 7.5\n",
      "6.616448 7.5 7.5\n",
      "6.812366 7.5 2.5\n",
      "5.7436852 5 7.5\n",
      "6.0842075 5 10.0\n",
      "6.2508607 7.5 2.5\n",
      "6.577914 7.5 10.0\n",
      "6.0183907 5 7.5\n",
      "8.457194 7.5 10.0\n",
      "6.610118 7.5 7.5\n",
      "8.618353 7.5 7.5\n",
      "7.341528 7.5 7.5\n",
      "6.82995 7.5 2.5\n",
      "9.439663 10 7.5\n",
      "7.582166 7.5 7.5\n",
      "6.4994745 7.5 10.0\n",
      "8.816916 10 10.0\n",
      "6.426784 7.5 7.5\n",
      "8.822032 10 7.5\n",
      "9.04423 10 7.5\n",
      "7.193652 7.5 7.5\n",
      "7.0033092 7.5 7.5\n",
      "9.108665 10 7.5\n",
      "8.007248 7.5 7.5\n",
      "8.341686 7.5 5.0\n",
      "7.6064563 7.5 7.5\n",
      "8.777297 10 7.5\n",
      "5.358725 5 10.0\n",
      "7.081816 7.5 2.5\n",
      "8.840815 10 10.0\n",
      "6.553141 7.5 7.5\n",
      "9.199583 10 10.0\n",
      "6.9609137 7.5 5.0\n",
      "7.5133815 7.5 7.5\n",
      "7.9938064 7.5 7.5\n",
      "7.693212 7.5 7.5\n",
      "7.58549 7.5 10.0\n",
      "9.619962 10 10.0\n",
      "8.799793 10 7.5\n",
      "7.9237533 7.5 10.0\n",
      "7.232435 7.5 7.5\n",
      "7.4100175 7.5 7.5\n",
      "8.078245 7.5 10.0\n",
      "5.281729 5 2.5\n",
      "8.677006 7.5 10.0\n",
      "7.1018357 7.5 5.0\n",
      "7.7431417 7.5 10.0\n",
      "7.064949 7.5 7.5\n",
      "6.4300313 7.5 7.5\n",
      "6.71622 7.5 7.5\n",
      "8.365703 7.5 10.0\n",
      "6.878198 7.5 7.5\n",
      "8.667368 7.5 10.0\n",
      "6.7442026 7.5 10.0\n",
      "6.9970465 7.5 7.5\n",
      "8.372765 7.5 10.0\n",
      "4.530624 5 2.5\n",
      "8.345398 7.5 7.5\n",
      "7.529927 7.5 10.0\n",
      "8.711141 7.5 0.0\n",
      "7.4070063 7.5 7.5\n",
      "6.7539377 7.5 7.5\n",
      "5.2200203 5 10.0\n",
      "6.1169014 5 7.5\n",
      "5.8806005 5 7.5\n",
      "9.10668 10 10.0\n",
      "9.83744 10 10.0\n",
      "5.6551857 5 2.5\n",
      "7.6088357 7.5 7.5\n",
      "8.358023 7.5 10.0\n",
      "9.011386 10 7.5\n",
      "8.831547 10 10.0\n",
      "7.501549 7.5 2.5\n",
      "6.558412 7.5 7.5\n",
      "9.609767 10 10.0\n",
      "7.427763 7.5 5.0\n",
      "7.8593307 7.5 10.0\n",
      "7.0350695 7.5 7.5\n",
      "6.939128 7.5 5.0\n",
      "7.238811 7.5 5.0\n",
      "7.340443 7.5 7.5\n",
      "7.207247 7.5 5.0\n",
      "9.123986 10 10.0\n",
      "7.595094 7.5 10.0\n",
      "8.903678 10 10.0\n",
      "7.015466 7.5 10.0\n",
      "8.799338 10 7.5\n",
      "9.80547 10 10.0\n",
      "7.1931653 7.5 10.0\n",
      "7.725206 7.5 10.0\n",
      "5.7076716 5 2.5\n",
      "7.8089876 7.5 10.0\n",
      "6.572604 7.5 7.5\n",
      "9.096749 10 10.0\n",
      "8.461212 7.5 10.0\n",
      "6.7182612 7.5 5.0\n",
      "8.312922 7.5 10.0\n",
      "8.733397 7.5 10.0\n",
      "8.481956 7.5 7.5\n",
      "7.9126725 7.5 10.0\n",
      "7.2704425 7.5 7.5\n",
      "8.283058 7.5 10.0\n",
      "8.724705 7.5 10.0\n",
      "5.45062 5 10.0\n",
      "7.4588437 7.5 7.5\n",
      "7.45834 7.5 10.0\n",
      "7.625082 7.5 5.0\n",
      "6.970528 7.5 7.5\n",
      "9.328814 10 10.0\n",
      "6.7867274 7.5 10.0\n",
      "7.290138 7.5 7.5\n",
      "8.969852 10 10.0\n",
      "7.8374104 7.5 7.5\n",
      "9.061124 10 10.0\n",
      "9.368023 10 10.0\n",
      "6.8151965 7.5 10.0\n",
      "7.1556435 7.5 7.5\n",
      "8.437529 7.5 7.5\n",
      "9.119984 10 10.0\n",
      "7.483712 7.5 10.0\n",
      "8.429295 7.5 10.0\n",
      "7.816572 7.5 7.5\n",
      "7.2241826 7.5 10.0\n",
      "7.221929 7.5 7.5\n",
      "7.3898544 7.5 5.0\n",
      "6.9354825 7.5 10.0\n",
      "7.704663 7.5 7.5\n",
      "8.569557 7.5 7.5\n",
      "7.8051343 7.5 10.0\n",
      "7.0423717 7.5 10.0\n",
      "8.97731 10 10.0\n",
      "9.129261 10 10.0\n",
      "8.682636 7.5 10.0\n",
      "9.5561695 10 10.0\n",
      "4.263068 5 0.0\n",
      "8.865366 10 5.0\n",
      "8.779697 10 7.5\n",
      "8.364222 7.5 7.5\n",
      "9.300999 10 10.0\n",
      "7.1051903 7.5 7.5\n",
      "6.7797184 7.5 2.5\n",
      "7.2157984 7.5 7.5\n",
      "8.886085 10 10.0\n",
      "7.835509 7.5 10.0\n",
      "9.084024 10 7.5\n",
      "8.840619 10 10.0\n",
      "8.607864 7.5 10.0\n",
      "8.027666 7.5 10.0\n",
      "7.9053755 7.5 10.0\n",
      "7.7568417 7.5 7.5\n",
      "8.794814 10 2.5\n",
      "5.0802674 5 2.5\n",
      "8.773797 10 7.5\n",
      "7.408327 7.5 10.0\n",
      "7.4752946 7.5 10.0\n",
      "4.1165023 5 0.0\n",
      "7.5339355 7.5 5.0\n",
      "6.3888245 7.5 7.5\n",
      "7.261553 7.5 10.0\n",
      "5.570896 5 2.5\n",
      "9.537508 10 10.0\n",
      "6.592579 7.5 10.0\n",
      "9.057636 10 7.5\n",
      "7.2703137 7.5 2.5\n",
      "5.2237864 5 7.5\n",
      "9.103315 10 10.0\n",
      "9.073639 10 7.5\n",
      "6.7119155 7.5 7.5\n",
      "7.375075 7.5 7.5\n",
      "6.2597117 7.5 2.5\n",
      "8.877202 10 10.0\n",
      "8.159154 7.5 5.0\n",
      "8.534937 7.5 10.0\n",
      "8.479141 7.5 10.0\n",
      "7.466757 7.5 10.0\n",
      "5.8907995 5 10.0\n",
      "6.0842605 5 2.5\n",
      "5.4495397 5 10.0\n",
      "5.672735 5 2.5\n",
      "7.7406306 7.5 10.0\n",
      "8.523182 7.5 10.0\n",
      "7.125222 7.5 10.0\n",
      "9.088972 10 10.0\n",
      "7.580391 7.5 10.0\n",
      "7.2912707 7.5 10.0\n",
      "7.327047 7.5 7.5\n",
      "9.027111 10 10.0\n",
      "6.8746433 7.5 2.5\n",
      "9.664983 10 10.0\n",
      "6.456794 7.5 2.5\n",
      "8.589406 7.5 10.0\n",
      "9.311261 10 10.0\n",
      "8.261053 7.5 10.0\n",
      "7.203201 7.5 7.5\n",
      "7.8879795 7.5 7.5\n",
      "9.073093 10 10.0\n",
      "7.485351 7.5 7.5\n",
      "7.0763807 7.5 2.5\n",
      "6.746741 7.5 10.0\n",
      "5.4014726 5 5.0\n",
      "9.16915 10 10.0\n",
      "7.5489464 7.5 10.0\n",
      "7.518304 7.5 7.5\n",
      "8.876097 10 5.0\n",
      "7.2474256 7.5 7.5\n",
      "8.831597 10 10.0\n",
      "7.466924 7.5 7.5\n",
      "8.799064 10 10.0\n",
      "6.8644986 7.5 10.0\n",
      "6.4735856 7.5 7.5\n",
      "5.430522 5 2.5\n",
      "5.619048 5 7.5\n",
      "6.902569 7.5 7.5\n",
      "7.1490607 7.5 7.5\n",
      "7.8805895 7.5 10.0\n",
      "9.305983 10 10.0\n",
      "8.447409 7.5 7.5\n",
      "8.568017 7.5 7.5\n",
      "6.962968 7.5 7.5\n",
      "9.044534 10 10.0\n",
      "8.634638 7.5 5.0\n",
      "6.2213807 5 7.5\n",
      "8.515125 7.5 7.5\n",
      "7.9398694 7.5 7.5\n",
      "8.781555 10 10.0\n",
      "7.0721946 7.5 5.0\n",
      "6.844661 7.5 7.5\n",
      "6.876979 7.5 7.5\n",
      "6.9269657 7.5 10.0\n",
      "7.2601304 7.5 5.0\n",
      "7.885566 7.5 7.5\n",
      "7.9265537 7.5 5.0\n",
      "7.437221 7.5 7.5\n",
      "8.811155 10 7.5\n",
      "8.558069 7.5 7.5\n",
      "7.911621 7.5 5.0\n",
      "6.879501 7.5 7.5\n",
      "9.173004 10 10.0\n",
      "7.1493964 7.5 7.5\n",
      "6.5831676 7.5 5.0\n",
      "6.375969 7.5 10.0\n",
      "4.497078 5 10.0\n",
      "7.8846903 7.5 5.0\n",
      "7.263644 7.5 7.5\n",
      "8.81542 10 10.0\n",
      "7.306118 7.5 10.0\n",
      "6.6863756 7.5 10.0\n",
      "5.8281255 5 0.0\n",
      "6.87001 7.5 7.5\n",
      "8.560222 7.5 5.0\n",
      "7.347532 7.5 2.5\n",
      "5.394078 5 2.5\n",
      "7.275878 7.5 7.5\n",
      "8.898712 10 10.0\n",
      "7.2550836 7.5 10.0\n",
      "8.904577 10 7.5\n",
      "4.0245585 5 0.0\n",
      "7.2528696 7.5 10.0\n",
      "7.7091513 7.5 2.5\n",
      "7.3640265 7.5 5.0\n",
      "7.106886 7.5 7.5\n",
      "7.56186 7.5 7.5\n",
      "7.6090803 7.5 5.0\n",
      "7.1107397 7.5 7.5\n",
      "6.525983 7.5 10.0\n",
      "6.9776464 7.5 7.5\n",
      "8.471979 7.5 10.0\n",
      "8.762306 10 10.0\n",
      "7.5732536 7.5 10.0\n",
      "6.853691 7.5 10.0\n",
      "8.944574 10 10.0\n",
      "3.8103564 5 0.0\n",
      "7.7247667 7.5 10.0\n",
      "8.806738 10 7.5\n",
      "7.6130667 7.5 10.0\n",
      "7.1254444 7.5 5.0\n",
      "7.663777 7.5 10.0\n",
      "7.0437512 7.5 7.5\n",
      "8.158699 7.5 10.0\n",
      "7.593561 7.5 7.5\n",
      "6.5909743 7.5 7.5\n",
      "6.465161 7.5 10.0\n",
      "5.2460513 5 2.5\n",
      "7.254616 7.5 7.5\n",
      "8.829225 10 10.0\n",
      "7.3770657 7.5 5.0\n",
      "8.297775 7.5 10.0\n",
      "8.31026 7.5 10.0\n",
      "7.1343074 7.5 10.0\n",
      "8.350252 7.5 7.5\n",
      "7.8289466 7.5 10.0\n",
      "8.011559 7.5 10.0\n",
      "8.526553 7.5 10.0\n",
      "5.3406863 5 7.5\n",
      "6.9610796 7.5 10.0\n",
      "8.2193365 7.5 5.0\n",
      "7.4333043 7.5 7.5\n",
      "6.4549375 7.5 7.5\n",
      "6.9679084 7.5 10.0\n",
      "7.695641 7.5 7.5\n",
      "8.809087 10 10.0\n",
      "7.0992556 7.5 7.5\n",
      "7.294381 7.5 7.5\n",
      "4.769452 5 2.5\n",
      "6.862419 7.5 10.0\n",
      "7.262173 7.5 7.5\n",
      "6.6244183 7.5 7.5\n",
      "7.735661 7.5 10.0\n",
      "7.605994 7.5 7.5\n",
      "7.215745 7.5 10.0\n",
      "4.4958534 5 7.5\n",
      "8.518737 7.5 10.0\n",
      "8.913185 10 7.5\n",
      "7.4162307 7.5 5.0\n",
      "6.533009 7.5 10.0\n",
      "9.361176 10 10.0\n",
      "7.679318 7.5 7.5\n",
      "4.874597 5 2.5\n",
      "6.890183 7.5 7.5\n",
      "7.466236 7.5 10.0\n",
      "8.607478 7.5 7.5\n",
      "7.288839 7.5 5.0\n",
      "8.019413 7.5 10.0\n",
      "6.972181 7.5 10.0\n",
      "7.856065 7.5 7.5\n",
      "4.925813 5 2.5\n",
      "8.89687 10 5.0\n",
      "7.697325 7.5 2.5\n",
      "6.339926 7.5 2.5\n",
      "7.458403 7.5 10.0\n",
      "8.886133 10 7.5\n",
      "8.156813 7.5 5.0\n",
      "4.2491355 5 10.0\n",
      "7.208546 7.5 7.5\n",
      "7.7774754 7.5 10.0\n",
      "8.901677 10 10.0\n",
      "7.411892 7.5 7.5\n",
      "7.6627693 7.5 10.0\n",
      "8.291287 7.5 7.5\n",
      "6.8754053 7.5 5.0\n",
      "7.116129 7.5 7.5\n",
      "8.923519 10 10.0\n",
      "8.903907 10 7.5\n",
      "8.551395 7.5 7.5\n",
      "6.917765 7.5 5.0\n",
      "7.658475 7.5 7.5\n",
      "6.823564 7.5 2.5\n",
      "7.212105 7.5 7.5\n",
      "8.078587 7.5 7.5\n",
      "7.2818537 7.5 2.5\n",
      "7.639511 7.5 10.0\n",
      "8.001198 7.5 10.0\n",
      "7.5388484 7.5 7.5\n",
      "8.592069 7.5 10.0\n",
      "7.282885 7.5 7.5\n",
      "6.8850355 7.5 0.0\n",
      "7.5585303 7.5 10.0\n",
      "7.4688296 7.5 7.5\n",
      "7.4883375 7.5 5.0\n",
      "6.7446547 7.5 7.5\n",
      "9.0044985 10 10.0\n",
      "8.517876 7.5 5.0\n",
      "6.8810687 7.5 2.5\n",
      "5.8312182 5 7.5\n",
      "7.5735903 7.5 10.0\n",
      "7.2877374 7.5 10.0\n",
      "8.843364 10 7.5\n",
      "6.737352 7.5 2.5\n",
      "8.75648 10 7.5\n",
      "9.401746 10 10.0\n",
      "6.4341464 7.5 2.5\n",
      "7.333438 7.5 10.0\n",
      "6.200543 5 7.5\n",
      "7.45658 7.5 7.5\n",
      "7.1498437 7.5 7.5\n",
      "8.480831 7.5 10.0\n",
      "3.9833703 5 2.5\n",
      "9.242586 10 10.0\n",
      "7.17867 7.5 10.0\n",
      "6.9658265 7.5 2.5\n",
      "8.323627 7.5 7.5\n",
      "5.8919883 5 7.5\n",
      "7.4632034 7.5 7.5\n",
      "9.369827 10 10.0\n",
      "6.642099 7.5 7.5\n",
      "7.463152 7.5 7.5\n",
      "8.962686 10 10.0\n",
      "7.239458 7.5 7.5\n",
      "8.264124 7.5 0.0\n",
      "8.264651 7.5 10.0\n",
      "9.138285 10 7.5\n",
      "7.316722 7.5 7.5\n",
      "8.802455 10 7.5\n",
      "8.807313 10 10.0\n",
      "8.62666 7.5 10.0\n",
      "7.138647 7.5 5.0\n",
      "6.3900623 7.5 5.0\n",
      "6.9531364 7.5 7.5\n",
      "7.8080053 7.5 2.5\n",
      "8.557921 7.5 7.5\n",
      "9.209425 10 10.0\n",
      "6.783761 7.5 7.5\n",
      "9.444244 10 10.0\n",
      "9.079541 10 7.5\n",
      "7.1074314 7.5 7.5\n",
      "6.1951776 5 7.5\n",
      "8.623536 7.5 7.5\n",
      "7.2252765 7.5 7.5\n",
      "7.331638 7.5 5.0\n",
      "8.6508465 7.5 10.0\n",
      "7.3306384 7.5 7.5\n",
      "7.466047 7.5 7.5\n",
      "7.7273064 7.5 10.0\n",
      "7.6848145 7.5 7.5\n",
      "7.0623646 7.5 7.5\n",
      "6.8659177 7.5 2.5\n",
      "7.2153535 7.5 2.5\n",
      "7.247919 7.5 10.0\n",
      "7.2381372 7.5 2.5\n",
      "7.190825 7.5 7.5\n",
      "10.200215 10 10.0\n",
      "6.5469565 7.5 10.0\n",
      "7.7336664 7.5 7.5\n",
      "7.7640033 7.5 0.0\n",
      "8.036396 7.5 7.5\n",
      "8.526958 7.5 10.0\n",
      "8.39823 7.5 10.0\n",
      "7.905642 7.5 10.0\n",
      "7.771483 7.5 10.0\n",
      "7.483006 7.5 7.5\n",
      "7.0927114 7.5 5.0\n",
      "7.905081 7.5 7.5\n",
      "6.9597306 7.5 10.0\n",
      "4.8576875 5 2.5\n",
      "8.352243 7.5 7.5\n",
      "6.9372787 7.5 5.0\n",
      "8.763585 10 10.0\n",
      "6.5971627 7.5 7.5\n",
      "7.6886377 7.5 7.5\n",
      "7.7117505 7.5 10.0\n",
      "3.6574373 2.5 2.5\n",
      "7.7333417 7.5 10.0\n",
      "6.842124 7.5 7.5\n",
      "9.386593 10 7.5\n",
      "9.340504 10 10.0\n",
      "6.433352 7.5 10.0\n",
      "8.676256 7.5 10.0\n",
      "5.1865845 5 2.5\n",
      "6.8302584 7.5 7.5\n",
      "9.088181 10 10.0\n",
      "7.1308208 7.5 7.5\n",
      "8.301636 7.5 2.5\n",
      "6.832227 7.5 7.5\n",
      "7.071866 7.5 10.0\n",
      "7.1162558 7.5 7.5\n",
      "7.3441596 7.5 7.5\n",
      "7.6289315 7.5 10.0\n",
      "8.030636 7.5 7.5\n",
      "8.812709 10 10.0\n",
      "7.601276 7.5 7.5\n",
      "7.531294 7.5 7.5\n",
      "8.5161 7.5 10.0\n",
      "7.8374043 7.5 5.0\n",
      "8.760788 10 7.5\n",
      "8.213942 7.5 10.0\n",
      "8.396549 7.5 10.0\n",
      "7.1626964 7.5 10.0\n",
      "9.1387615 10 10.0\n",
      "6.1683393 5 7.5\n",
      "8.980715 10 7.5\n",
      "7.755455 7.5 7.5\n",
      "8.587836 7.5 7.5\n",
      "7.688729 7.5 7.5\n",
      "8.571337 7.5 10.0\n",
      "7.275127 7.5 5.0\n",
      "6.9928136 7.5 7.5\n",
      "7.8500066 7.5 10.0\n",
      "8.157331 7.5 7.5\n",
      "8.90799 10 10.0\n",
      "7.009151 7.5 5.0\n",
      "6.3796782 7.5 2.5\n",
      "7.971824 7.5 7.5\n",
      "7.4151106 7.5 10.0\n",
      "6.0447593 5 7.5\n",
      "7.499411 7.5 7.5\n",
      "9.268566 10 7.5\n",
      "9.811992 10 10.0\n",
      "6.811767 7.5 7.5\n",
      "8.686019 7.5 7.5\n",
      "7.7176733 7.5 7.5\n",
      "8.8081455 10 10.0\n",
      "7.136611 7.5 5.0\n",
      "3.5212393 2.5 2.5\n",
      "7.2362223 7.5 7.5\n",
      "7.2695537 7.5 7.5\n",
      "7.3856254 7.5 7.5\n",
      "7.735018 7.5 10.0\n",
      "5.92856 5 0.0\n",
      "6.5153613 7.5 10.0\n",
      "7.7499266 7.5 10.0\n",
      "9.031276 10 10.0\n",
      "5.66629 5 10.0\n",
      "9.140575 10 5.0\n",
      "9.284374 10 10.0\n",
      "9.2049885 10 10.0\n",
      "8.137038 7.5 7.5\n",
      "5.0320044 5 2.5\n",
      "8.861934 10 2.5\n",
      "8.73337 7.5 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.795179 5 2.5\n",
      "8.171051 7.5 5.0\n",
      "5.4485793 5 2.5\n",
      "6.559353 7.5 10.0\n",
      "8.21508 7.5 5.0\n",
      "8.887403 10 10.0\n",
      "6.473309 7.5 5.0\n",
      "9.495146 10 10.0\n",
      "6.067431 5 7.5\n",
      "6.878742 7.5 7.5\n",
      "7.1737523 7.5 5.0\n",
      "7.470629 7.5 7.5\n",
      "7.115641 7.5 0.0\n",
      "5.6777554 5 5.0\n",
      "5.8339877 5 2.5\n",
      "7.111055 7.5 7.5\n",
      "6.7236257 7.5 10.0\n",
      "7.230857 7.5 2.5\n",
      "6.8952537 7.5 5.0\n",
      "7.876106 7.5 10.0\n",
      "9.333084 10 7.5\n",
      "6.7052875 7.5 10.0\n",
      "8.9069605 10 7.5\n",
      "9.08294 10 10.0\n",
      "8.777982 10 10.0\n",
      "8.99087 10 10.0\n",
      "7.303084 7.5 10.0\n",
      "7.020656 7.5 7.5\n",
      "5.3853273 5 5.0\n",
      "8.794083 10 10.0\n",
      "8.935527 10 10.0\n",
      "7.2178936 7.5 7.5\n",
      "8.520957 7.5 5.0\n",
      "7.0320234 7.5 2.5\n",
      "8.815841 10 7.5\n",
      "9.146775 10 10.0\n",
      "9.14814 10 10.0\n",
      "6.1299076 5 0.0\n",
      "8.279397 7.5 7.5\n",
      "8.929781 10 10.0\n",
      "7.00511 7.5 10.0\n",
      "7.3344545 7.5 10.0\n",
      "7.4628363 7.5 10.0\n",
      "6.5345902 7.5 5.0\n",
      "7.4571605 7.5 7.5\n",
      "5.4562893 5 7.5\n",
      "8.557975 7.5 7.5\n",
      "7.588536 7.5 7.5\n",
      "8.936083 10 10.0\n",
      "7.102791 7.5 5.0\n",
      "8.20962 7.5 10.0\n",
      "7.629561 7.5 10.0\n",
      "6.944566 7.5 5.0\n",
      "7.9404235 7.5 7.5\n",
      "6.6885858 7.5 7.5\n",
      "7.023529 7.5 7.5\n",
      "5.356553 5 2.5\n",
      "9.079288 10 10.0\n",
      "7.165941 7.5 7.5\n",
      "9.04088 10 10.0\n",
      "9.113746 10 10.0\n",
      "9.0373535 10 10.0\n",
      "9.040439 10 10.0\n",
      "7.365515 7.5 10.0\n",
      "7.936763 7.5 7.5\n",
      "5.763829 5 10.0\n",
      "5.2984686 5 2.5\n",
      "6.552891 7.5 2.5\n",
      "7.4260426 7.5 10.0\n",
      "9.222185 10 10.0\n",
      "9.180019 10 10.0\n",
      "6.540282 7.5 5.0\n",
      "7.7624674 7.5 7.5\n",
      "8.782645 10 10.0\n",
      "6.4901967 7.5 5.0\n",
      "6.573381 7.5 7.5\n",
      "6.1251035 5 7.5\n",
      "6.5539117 7.5 5.0\n",
      "7.323544 7.5 7.5\n",
      "7.247866 7.5 10.0\n",
      "9.540761 10 10.0\n",
      "7.534303 7.5 10.0\n",
      "8.647705 7.5 7.5\n",
      "8.689438 7.5 7.5\n",
      "8.94824 10 10.0\n",
      "8.095862 7.5 7.5\n",
      "8.199267 7.5 10.0\n",
      "7.4479475 7.5 7.5\n",
      "7.380012 7.5 7.5\n",
      "8.578756 7.5 7.5\n",
      "5.8299794 5 7.5\n",
      "7.6269054 7.5 7.5\n",
      "4.930387 5 7.5\n",
      "7.394697 7.5 7.5\n",
      "8.052896 7.5 10.0\n",
      "8.554947 7.5 7.5\n",
      "6.8885937 7.5 2.5\n",
      "6.013335 5 0.0\n",
      "8.628763 7.5 10.0\n",
      "7.947933 7.5 2.5\n",
      "7.540949 7.5 10.0\n",
      "8.549387 7.5 10.0\n",
      "7.0716825 7.5 7.5\n",
      "6.194329 5 7.5\n",
      "8.15847 7.5 10.0\n",
      "8.958982 10 10.0\n",
      "6.314321 7.5 10.0\n",
      "8.024106 7.5 7.5\n",
      "5.053256 5 7.5\n",
      "7.574957 7.5 10.0\n",
      "6.4917235 7.5 7.5\n",
      "5.65777 5 2.5\n",
      "8.955595 10 10.0\n",
      "8.564895 7.5 7.5\n",
      "7.3967366 7.5 10.0\n",
      "8.607742 7.5 10.0\n",
      "7.449849 7.5 10.0\n",
      "5.07259 5 7.5\n",
      "8.876394 10 10.0\n",
      "7.397967 7.5 5.0\n",
      "8.744714 7.5 10.0\n",
      "7.060741 7.5 7.5\n",
      "7.575723 7.5 7.5\n",
      "7.545907 7.5 7.5\n",
      "7.2055926 7.5 7.5\n",
      "6.738225 7.5 2.5\n",
      "8.813459 10 7.5\n",
      "8.636903 7.5 10.0\n",
      "8.286764 7.5 10.0\n",
      "8.45381 7.5 7.5\n",
      "6.513028 7.5 7.5\n",
      "6.888366 7.5 5.0\n",
      "6.7437277 7.5 2.5\n",
      "6.4264693 7.5 10.0\n",
      "7.00082 7.5 7.5\n",
      "9.14108 10 10.0\n",
      "6.7400637 7.5 7.5\n",
      "7.07835 7.5 10.0\n",
      "7.025781 7.5 5.0\n",
      "6.122841 5 10.0\n",
      "9.032209 10 10.0\n",
      "8.63817 7.5 10.0\n",
      "7.751196 7.5 7.5\n",
      "8.132216 7.5 10.0\n",
      "8.345111 7.5 10.0\n",
      "7.2409096 7.5 10.0\n",
      "7.7641215 7.5 5.0\n",
      "8.930135 10 10.0\n",
      "6.8128047 7.5 7.5\n",
      "7.1406965 7.5 5.0\n",
      "9.445401 10 10.0\n",
      "6.9769707 7.5 10.0\n",
      "9.237422 10 10.0\n",
      "9.022806 10 10.0\n",
      "7.376457 7.5 10.0\n",
      "8.7632065 10 7.5\n",
      "7.676879 7.5 10.0\n",
      "7.5422735 7.5 10.0\n",
      "6.6136656 7.5 7.5\n",
      "6.820296 7.5 7.5\n",
      "8.773305 10 10.0\n",
      "7.4537106 7.5 2.5\n",
      "9.2694235 10 10.0\n",
      "7.744934 7.5 7.5\n",
      "7.586595 7.5 7.5\n",
      "6.404155 7.5 7.5\n",
      "7.824445 7.5 5.0\n",
      "7.232497 7.5 7.5\n",
      "7.2573013 7.5 0.0\n",
      "7.260645 7.5 2.5\n",
      "7.3987403 7.5 7.5\n",
      "7.8917127 7.5 2.5\n",
      "8.92565 10 10.0\n",
      "9.225636 10 5.0\n",
      "8.712306 7.5 10.0\n",
      "8.084717 7.5 7.5\n",
      "5.4848557 5 2.5\n",
      "6.5518064 7.5 2.5\n",
      "8.447678 7.5 7.5\n",
      "6.9655123 7.5 10.0\n",
      "7.4844613 7.5 5.0\n",
      "8.421961 7.5 10.0\n",
      "8.54448 7.5 7.5\n",
      "7.166653 7.5 7.5\n",
      "6.6840625 7.5 10.0\n",
      "7.5627832 7.5 10.0\n",
      "4.9222913 5 2.5\n",
      "8.803404 10 10.0\n",
      "3.5585673 2.5 5.0\n",
      "8.090763 7.5 10.0\n",
      "7.197181 7.5 7.5\n",
      "7.9986105 7.5 10.0\n",
      "7.605664 7.5 10.0\n",
      "5.9690204 5 10.0\n",
      "8.735226 7.5 7.5\n",
      "6.712805 7.5 7.5\n",
      "7.831993 7.5 10.0\n",
      "9.282228 10 10.0\n",
      "8.583235 7.5 7.5\n",
      "7.603235 7.5 7.5\n",
      "8.822308 10 7.5\n",
      "7.950333 7.5 5.0\n",
      "7.733588 7.5 7.5\n",
      "7.612208 7.5 7.5\n",
      "8.970288 10 7.5\n",
      "7.5020623 7.5 10.0\n",
      "7.3014565 7.5 2.5\n",
      "7.3953776 7.5 10.0\n",
      "6.0299373 5 2.5\n",
      "8.762857 10 7.5\n",
      "6.8085504 7.5 10.0\n",
      "8.402221 7.5 7.5\n",
      "6.962987 7.5 7.5\n",
      "7.5777607 7.5 7.5\n",
      "7.6539173 7.5 7.5\n",
      "6.9473543 7.5 7.5\n",
      "8.871499 10 10.0\n",
      "8.632639 7.5 10.0\n",
      "6.6380157 7.5 7.5\n",
      "5.424932 5 0.0\n",
      "7.31108 7.5 7.5\n",
      "6.5554976 7.5 7.5\n",
      "8.790182 10 7.5\n",
      "9.272254 10 10.0\n",
      "7.0529423 7.5 7.5\n",
      "7.143752 7.5 2.5\n",
      "7.236778 7.5 7.5\n",
      "8.189236 7.5 10.0\n",
      "5.593506 5 5.0\n",
      "7.0223684 7.5 7.5\n",
      "5.939659 5 2.5\n",
      "7.982329 7.5 2.5\n",
      "7.470095 7.5 7.5\n",
      "6.68159 7.5 10.0\n",
      "7.380261 7.5 7.5\n",
      "8.832326 10 10.0\n",
      "6.773444 7.5 5.0\n",
      "6.8262787 7.5 2.5\n",
      "6.738958 7.5 7.5\n",
      "6.9315753 7.5 2.5\n",
      "7.938725 7.5 7.5\n",
      "7.5798883 7.5 10.0\n",
      "7.113123 7.5 2.5\n",
      "7.575845 7.5 10.0\n",
      "8.766823 10 7.5\n",
      "9.478572 10 10.0\n",
      "6.410552 7.5 5.0\n",
      "7.6727724 7.5 7.5\n",
      "6.707111 7.5 7.5\n",
      "7.7603555 7.5 10.0\n",
      "7.3331995 7.5 7.5\n",
      "7.392276 7.5 10.0\n",
      "7.734407 7.5 10.0\n",
      "8.350414 7.5 7.5\n",
      "8.780409 10 7.5\n",
      "9.288985 10 10.0\n",
      "7.6241884 7.5 10.0\n",
      "8.848245 10 10.0\n",
      "7.121177 7.5 7.5\n",
      "9.181227 10 10.0\n",
      "7.564501 7.5 10.0\n",
      "8.4676285 7.5 10.0\n",
      "6.508122 7.5 7.5\n",
      "7.3495307 7.5 7.5\n",
      "7.8854747 7.5 10.0\n",
      "9.050826 10 10.0\n",
      "7.4045124 7.5 7.5\n",
      "6.5935645 7.5 2.5\n",
      "8.3751745 7.5 7.5\n",
      "9.151305 10 7.5\n",
      "8.780131 10 10.0\n",
      "7.6999984 7.5 5.0\n",
      "5.535413 5 10.0\n",
      "8.099703 7.5 10.0\n",
      "7.2799983 7.5 10.0\n",
      "7.5637827 7.5 5.0\n",
      "6.69554 7.5 10.0\n",
      "8.014756 7.5 7.5\n",
      "5.6018634 5 5.0\n",
      "5.8502812 5 10.0\n",
      "7.660278 7.5 10.0\n",
      "6.363688 7.5 7.5\n",
      "7.16239 7.5 2.5\n",
      "8.888669 10 10.0\n",
      "8.793113 10 7.5\n",
      "5.2504034 5 2.5\n",
      "7.7403865 7.5 10.0\n",
      "7.2918777 7.5 5.0\n",
      "8.890551 10 7.5\n",
      "6.0898294 5 7.5\n",
      "7.0753913 7.5 7.5\n",
      "6.7912726 7.5 10.0\n",
      "6.2981052 7.5 5.0\n",
      "7.498666 7.5 10.0\n",
      "7.287884 7.5 7.5\n",
      "7.5241075 7.5 0.0\n",
      "6.6154714 7.5 2.5\n",
      "7.8933024 7.5 10.0\n",
      "7.555913 7.5 10.0\n",
      "6.595496 7.5 2.5\n",
      "8.42863 7.5 7.5\n",
      "7.307203 7.5 5.0\n",
      "7.184511 7.5 0.0\n",
      "7.0012555 7.5 10.0\n",
      "7.479455 7.5 10.0\n",
      "6.9161158 7.5 7.5\n",
      "8.029268 7.5 5.0\n",
      "8.731306 7.5 10.0\n",
      "6.884422 7.5 10.0\n",
      "6.532835 7.5 7.5\n",
      "6.432507 7.5 7.5\n",
      "9.07966 10 10.0\n",
      "7.604865 7.5 10.0\n",
      "8.08231 7.5 10.0\n",
      "6.9609394 7.5 10.0\n",
      "9.161975 10 10.0\n",
      "7.1567783 7.5 10.0\n",
      "7.4081416 7.5 7.5\n",
      "9.139743 10 10.0\n",
      "8.521601 7.5 7.5\n",
      "7.290606 7.5 7.5\n",
      "5.186452 5 2.5\n",
      "8.407731 7.5 7.5\n",
      "6.79906 7.5 7.5\n",
      "6.202064 5 10.0\n",
      "8.942495 10 10.0\n",
      "7.8363967 7.5 7.5\n",
      "9.117894 10 7.5\n",
      "7.0929956 7.5 2.5\n",
      "7.58046 7.5 5.0\n",
      "6.639838 7.5 2.5\n",
      "7.6985745 7.5 7.5\n",
      "8.985766 10 10.0\n",
      "8.577229 7.5 5.0\n",
      "7.324442 7.5 7.5\n",
      "8.544062 7.5 5.0\n",
      "8.827666 10 10.0\n",
      "6.444445 7.5 10.0\n",
      "9.051476 10 10.0\n",
      "7.9380655 7.5 10.0\n",
      "7.4969687 7.5 5.0\n",
      "6.833603 7.5 7.5\n",
      "7.971432 7.5 7.5\n",
      "7.536485 7.5 7.5\n",
      "8.43069 7.5 5.0\n",
      "7.3821015 7.5 2.5\n",
      "5.799295 5 7.5\n",
      "8.073907 7.5 7.5\n",
      "5.60116 5 7.5\n",
      "6.549524 7.5 7.5\n",
      "7.0820284 7.5 10.0\n",
      "8.597996 7.5 7.5\n",
      "6.8750105 7.5 7.5\n",
      "8.843159 10 7.5\n",
      "7.9714055 7.5 7.5\n",
      "6.813808 7.5 2.5\n",
      "7.354239 7.5 10.0\n",
      "8.172924 7.5 2.5\n",
      "5.9640074 5 7.5\n",
      "9.345592 10 10.0\n",
      "9.310735 10 10.0\n",
      "7.7087145 7.5 10.0\n",
      "7.2377157 7.5 7.5\n",
      "5.315522 5 7.5\n",
      "5.406442 5 2.5\n",
      "8.275028 7.5 10.0\n",
      "6.9613595 7.5 10.0\n",
      "8.819082 10 10.0\n",
      "7.230734 7.5 10.0\n",
      "5.4223123 5 7.5\n",
      "6.5875525 7.5 10.0\n",
      "9.070607 10 7.5\n",
      "6.310473 7.5 5.0\n",
      "7.780624 7.5 2.5\n",
      "7.170576 7.5 10.0\n",
      "6.585246 7.5 5.0\n",
      "7.83606 7.5 7.5\n",
      "6.5752416 7.5 5.0\n",
      "6.531415 7.5 7.5\n",
      "6.7328267 7.5 7.5\n",
      "8.808004 10 10.0\n",
      "6.9216685 7.5 2.5\n",
      "4.927455 5 10.0\n",
      "7.271681 7.5 2.5\n",
      "8.627091 7.5 10.0\n",
      "6.8262577 7.5 7.5\n",
      "7.181028 7.5 10.0\n",
      "6.819683 7.5 7.5\n",
      "7.0804667 7.5 7.5\n",
      "7.1746454 7.5 7.5\n",
      "6.605191 7.5 7.5\n",
      "8.671727 7.5 10.0\n",
      "8.540407 7.5 7.5\n",
      "6.381366 7.5 7.5\n",
      "9.040679 10 10.0\n",
      "7.6297555 7.5 10.0\n",
      "7.765636 7.5 7.5\n",
      "9.418956 10 10.0\n",
      "7.2643185 7.5 10.0\n",
      "7.543571 7.5 7.5\n",
      "4.5083385 5 2.5\n",
      "8.987176 10 10.0\n",
      "6.282797 7.5 10.0\n",
      "8.752212 10 7.5\n",
      "8.134048 7.5 5.0\n",
      "6.272325 7.5 7.5\n",
      "6.4707394 7.5 2.5\n",
      "8.47811 7.5 7.5\n",
      "9.198601 10 10.0\n",
      "8.891259 10 7.5\n",
      "7.4879937 7.5 2.5\n",
      "8.307059 7.5 7.5\n",
      "8.559082 7.5 7.5\n",
      "5.9692698 5 0.0\n",
      "7.7506266 7.5 5.0\n",
      "7.448652 7.5 7.5\n",
      "7.338175 7.5 7.5\n",
      "7.816957 7.5 10.0\n",
      "6.2678604 7.5 10.0\n",
      "7.2281046 7.5 7.5\n",
      "6.98469 7.5 7.5\n",
      "8.576602 7.5 7.5\n",
      "7.2163014 7.5 7.5\n",
      "7.3090806 7.5 7.5\n",
      "8.222189 7.5 10.0\n",
      "7.5153875 7.5 7.5\n",
      "8.2531595 7.5 10.0\n",
      "6.450212 7.5 7.5\n",
      "6.9856334 7.5 5.0\n",
      "8.6321125 7.5 10.0\n",
      "7.7887406 7.5 7.5\n",
      "9.742432 10 10.0\n",
      "6.501456 7.5 7.5\n",
      "7.182554 7.5 7.5\n",
      "9.5116205 10 10.0\n",
      "7.3807206 7.5 7.5\n",
      "8.575488 7.5 10.0\n",
      "9.038429 10 7.5\n",
      "9.080168 10 10.0\n",
      "7.048025 7.5 7.5\n",
      "6.602903 7.5 5.0\n",
      "7.9332724 7.5 10.0\n",
      "7.8160176 7.5 7.5\n",
      "7.9278636 7.5 10.0\n",
      "7.3710523 7.5 5.0\n",
      "8.86883 10 7.5\n",
      "8.946785 10 10.0\n",
      "5.2464566 5 2.5\n",
      "9.305518 10 7.5\n",
      "7.804692 7.5 10.0\n",
      "6.3784103 7.5 7.5\n",
      "9.54782 10 7.5\n",
      "7.4317656 7.5 7.5\n",
      "6.901681 7.5 7.5\n",
      "7.3965397 7.5 7.5\n",
      "4.2099056 5 2.5\n",
      "5.702581 5 10.0\n",
      "6.514368 7.5 7.5\n",
      "7.0762715 7.5 2.5\n",
      "8.334358 7.5 7.5\n",
      "7.3036222 7.5 10.0\n",
      "6.4931464 7.5 7.5\n",
      "6.416714 7.5 5.0\n",
      "8.737952 7.5 7.5\n",
      "5.6974754 5 2.5\n",
      "7.534326 7.5 7.5\n",
      "7.9984493 7.5 2.5\n",
      "7.301328 7.5 7.5\n",
      "7.6245074 7.5 10.0\n",
      "6.631763 7.5 2.5\n",
      "5.8321214 5 10.0\n",
      "9.06773 10 10.0\n",
      "8.647634 7.5 7.5\n",
      "6.249001 5 2.5\n",
      "7.668551 7.5 2.5\n",
      "5.7010255 5 2.5\n",
      "8.953619 10 10.0\n",
      "6.2180176 5 10.0\n",
      "7.3723426 7.5 10.0\n",
      "6.8781543 7.5 7.5\n",
      "7.8162885 7.5 10.0\n",
      "6.6770473 7.5 7.5\n",
      "6.7807345 7.5 7.5\n",
      "8.368383 7.5 10.0\n",
      "8.977012 10 7.5\n",
      "7.5830326 7.5 7.5\n",
      "7.2363696 7.5 2.5\n",
      "7.1309705 7.5 5.0\n",
      "9.395374 10 10.0\n",
      "8.418922 7.5 7.5\n",
      "7.5338683 7.5 10.0\n",
      "6.6314735 7.5 7.5\n",
      "7.156119 7.5 10.0\n",
      "4.632284 5 7.5\n",
      "7.8378553 7.5 7.5\n",
      "7.7962084 7.5 7.5\n",
      "6.6233783 7.5 2.5\n",
      "6.3846226 7.5 10.0\n",
      "9.125645 10 10.0\n",
      "9.478191 10 10.0\n",
      "7.3396754 7.5 10.0\n",
      "8.340441 7.5 7.5\n",
      "7.2170515 7.5 10.0\n",
      "8.068691 7.5 7.5\n",
      "7.6339335 7.5 10.0\n",
      "7.729588 7.5 5.0\n",
      "7.6988664 7.5 5.0\n",
      "6.897742 7.5 7.5\n",
      "7.693759 7.5 10.0\n",
      "7.8304935 7.5 7.5\n",
      "8.542388 7.5 10.0\n",
      "8.798858 10 10.0\n",
      "8.561046 7.5 7.5\n",
      "6.3286815 7.5 5.0\n",
      "8.455389 7.5 10.0\n",
      "7.117511 7.5 7.5\n",
      "8.982763 10 10.0\n",
      "7.577491 7.5 10.0\n",
      "9.262005 10 7.5\n",
      "6.569786 7.5 7.5\n",
      "7.406586 7.5 10.0\n",
      "8.255782 7.5 5.0\n",
      "7.5876536 7.5 10.0\n",
      "9.059542 10 10.0\n",
      "9.005013 10 7.5\n",
      "7.9841666 7.5 5.0\n",
      "6.2209425 5 10.0\n",
      "8.255762 7.5 10.0\n",
      "6.9165416 7.5 7.5\n",
      "6.933199 7.5 10.0\n",
      "6.7013674 7.5 10.0\n",
      "7.101739 7.5 5.0\n",
      "8.727008 7.5 10.0\n",
      "6.9873323 7.5 7.5\n",
      "7.4176683 7.5 5.0\n",
      "8.71631 7.5 7.5\n",
      "9.447727 10 10.0\n",
      "9.106267 10 10.0\n",
      "7.467645 7.5 7.5\n",
      "8.583505 7.5 7.5\n",
      "7.940151 7.5 10.0\n",
      "8.2465105 7.5 7.5\n",
      "9.016502 10 7.5\n",
      "7.649454 7.5 10.0\n",
      "7.549582 7.5 10.0\n",
      "9.270515 10 7.5\n",
      "4.552969 5 0.0\n",
      "7.605285 7.5 5.0\n",
      "6.70693 7.5 2.5\n",
      "8.519252 7.5 10.0\n",
      "7.751408 7.5 10.0\n",
      "6.514062 7.5 5.0\n",
      "8.626833 7.5 7.5\n",
      "8.701287 7.5 10.0\n",
      "6.390295 7.5 5.0\n",
      "6.985173 7.5 7.5\n",
      "6.9405117 7.5 7.5\n",
      "7.7030587 7.5 2.5\n",
      "7.601935 7.5 7.5\n",
      "7.380377 7.5 10.0\n",
      "7.207549 7.5 5.0\n",
      "5.2560205 5 2.5\n",
      "8.865373 10 7.5\n",
      "7.959296 7.5 7.5\n",
      "8.459663 7.5 10.0\n",
      "7.6938925 7.5 5.0\n",
      "7.7472315 7.5 10.0\n",
      "8.166938 7.5 5.0\n",
      "6.3575034 7.5 7.5\n",
      "7.2995877 7.5 7.5\n",
      "8.310004 7.5 5.0\n",
      "9.675833 10 10.0\n",
      "8.481352 7.5 7.5\n",
      "7.701749 7.5 7.5\n",
      "7.2444715 7.5 7.5\n",
      "7.163082 7.5 2.5\n",
      "8.7460985 7.5 7.5\n",
      "6.332188 7.5 10.0\n",
      "7.695487 7.5 7.5\n",
      "8.956744 10 7.5\n",
      "6.0311384 5 7.5\n",
      "6.792069 7.5 5.0\n",
      "5.2646055 5 2.5\n",
      "4.8947 5 2.5\n",
      "8.391121 7.5 7.5\n",
      "7.781183 7.5 10.0\n",
      "8.387264 7.5 5.0\n",
      "7.512713 7.5 5.0\n",
      "6.6981516 7.5 5.0\n",
      "7.2297783 7.5 7.5\n",
      "7.3083534 7.5 7.5\n",
      "3.7569492 5 2.5\n",
      "6.580185 7.5 7.5\n",
      "7.0869474 7.5 7.5\n",
      "8.044603 7.5 10.0\n",
      "6.600531 7.5 7.5\n",
      "8.699702 7.5 10.0\n",
      "7.774529 7.5 5.0\n",
      "6.686033 7.5 2.5\n",
      "7.706295 7.5 10.0\n",
      "7.245576 7.5 10.0\n",
      "7.6629405 7.5 7.5\n",
      "5.437481 5 5.0\n",
      "8.486286 7.5 7.5\n",
      "7.341423 7.5 7.5\n",
      "7.244211 7.5 10.0\n",
      "8.795363 10 10.0\n",
      "7.7861633 7.5 10.0\n",
      "8.75372 10 10.0\n",
      "4.447223 5 2.5\n",
      "8.098503 7.5 10.0\n",
      "8.214169 7.5 7.5\n",
      "7.165618 7.5 2.5\n",
      "6.6332064 7.5 5.0\n",
      "6.7120156 7.5 7.5\n",
      "7.2642407 7.5 5.0\n",
      "6.988785 7.5 5.0\n",
      "5.4750347 5 7.5\n",
      "7.777383 7.5 7.5\n",
      "8.971156 10 7.5\n",
      "8.806214 10 7.5\n",
      "8.319092 7.5 10.0\n",
      "7.9334025 7.5 7.5\n",
      "8.744163 7.5 7.5\n",
      "6.205485 5 7.5\n",
      "7.7057076 7.5 7.5\n",
      "9.111185 10 0.0\n",
      "8.613579 7.5 7.5\n",
      "6.9350934 7.5 5.0\n",
      "6.9429216 7.5 5.0\n",
      "6.798795 7.5 7.5\n",
      "8.676356 7.5 10.0\n",
      "8.751474 10 10.0\n",
      "4.9838586 5 0.0\n",
      "7.687613 7.5 10.0\n",
      "8.854778 10 7.5\n",
      "7.957039 7.5 5.0\n",
      "6.9394145 7.5 7.5\n",
      "8.237345 7.5 10.0\n",
      "7.3617816 7.5 10.0\n",
      "8.576541 7.5 10.0\n",
      "7.156694 7.5 7.5\n",
      "9.571813 10 10.0\n",
      "7.175396 7.5 5.0\n",
      "7.095522 7.5 10.0\n",
      "7.673754 7.5 7.5\n",
      "6.612209 7.5 7.5\n",
      "7.0314493 7.5 7.5\n",
      "6.6542187 7.5 2.5\n",
      "6.0832415 5 5.0\n",
      "8.326136 7.5 7.5\n",
      "9.324812 10 10.0\n",
      "7.313712 7.5 7.5\n",
      "6.1933355 5 2.5\n",
      "7.461219 7.5 5.0\n",
      "8.992753 10 10.0\n",
      "6.2270217 5 2.5\n",
      "6.379108 7.5 7.5\n",
      "8.720922 7.5 10.0\n",
      "6.4751725 7.5 5.0\n",
      "6.4918175 7.5 7.5\n",
      "6.598204 7.5 7.5\n",
      "8.401873 7.5 7.5\n",
      "6.512863 7.5 5.0\n",
      "7.435588 7.5 10.0\n",
      "6.938879 7.5 10.0\n",
      "6.4807773 7.5 5.0\n",
      "7.206088 7.5 7.5\n",
      "5.669739 5 7.5\n",
      "6.9036975 7.5 7.5\n",
      "9.766813 10 10.0\n",
      "5.915247 5 2.5\n",
      "6.511838 7.5 0.0\n",
      "6.8798976 7.5 7.5\n",
      "4.0228643 5 7.5\n",
      "8.412083 7.5 10.0\n",
      "6.883768 7.5 10.0\n",
      "7.151635 7.5 7.5\n",
      "8.786153 10 7.5\n",
      "8.576738 7.5 7.5\n",
      "8.997942 10 10.0\n",
      "7.5907836 7.5 7.5\n",
      "4.9446144 5 5.0\n",
      "8.61695 7.5 7.5\n",
      "8.100332 7.5 10.0\n",
      "7.7605987 7.5 10.0\n",
      "7.419445 7.5 7.5\n",
      "8.319029 7.5 7.5\n",
      "9.376163 10 10.0\n",
      "8.933031 10 7.5\n",
      "7.2321033 7.5 7.5\n",
      "6.378215 7.5 7.5\n",
      "6.398544 7.5 10.0\n",
      "7.2348213 7.5 7.5\n",
      "6.0665336 5 7.5\n",
      "7.6436553 7.5 5.0\n",
      "6.4242477 7.5 7.5\n",
      "6.5864177 7.5 7.5\n",
      "6.9929976 7.5 2.5\n",
      "7.4308586 7.5 7.5\n",
      "7.5122366 7.5 0.0\n",
      "8.338272 7.5 10.0\n",
      "7.1991534 7.5 7.5\n",
      "9.292533 10 7.5\n",
      "9.265516 10 7.5\n",
      "9.265324 10 10.0\n",
      "9.279284 10 10.0\n",
      "8.923593 10 10.0\n",
      "6.752211 7.5 5.0\n",
      "9.663937 10 10.0\n",
      "8.513506 7.5 7.5\n",
      "7.260325 7.5 7.5\n",
      "8.810713 10 7.5\n",
      "4.8796697 5 2.5\n",
      "7.3917603 7.5 10.0\n",
      "8.993802 10 10.0\n",
      "8.011976 7.5 10.0\n",
      "7.286121 7.5 5.0\n",
      "7.5255103 7.5 10.0\n",
      "9.275547 10 5.0\n",
      "7.3426614 7.5 7.5\n",
      "8.989453 10 7.5\n",
      "7.8295655 7.5 7.5\n",
      "7.0525703 7.5 2.5\n",
      "6.0915527 5 7.5\n",
      "4.912957 5 2.5\n",
      "9.574413 10 10.0\n",
      "6.402634 7.5 7.5\n",
      "9.079139 10 7.5\n",
      "7.740183 7.5 5.0\n",
      "7.620727 7.5 10.0\n",
      "8.095327 7.5 7.5\n",
      "9.134417 10 10.0\n",
      "7.545144 7.5 10.0\n",
      "7.1886134 7.5 10.0\n",
      "8.670951 7.5 10.0\n",
      "7.4531302 7.5 5.0\n",
      "7.1803293 7.5 7.5\n",
      "6.865906 7.5 5.0\n",
      "5.2394466 5 7.5\n",
      "6.990627 7.5 7.5\n",
      "6.317846 7.5 5.0\n",
      "7.521504 7.5 5.0\n",
      "8.356823 7.5 10.0\n",
      "7.337122 7.5 5.0\n",
      "6.9681034 7.5 7.5\n",
      "8.132064 7.5 10.0\n",
      "7.20198 7.5 10.0\n",
      "7.2596145 7.5 5.0\n",
      "6.8938975 7.5 7.5\n",
      "8.849633 10 7.5\n",
      "5.2152276 5 2.5\n",
      "7.1922903 7.5 7.5\n",
      "5.925305 5 5.0\n",
      "8.83126 10 10.0\n",
      "8.037479 7.5 7.5\n",
      "7.42992 7.5 7.5\n",
      "8.1327305 7.5 10.0\n",
      "7.892463 7.5 10.0\n",
      "6.946012 7.5 10.0\n",
      "7.1389556 7.5 10.0\n",
      "9.1234455 10 10.0\n",
      "7.071132 7.5 2.5\n",
      "7.69124 7.5 7.5\n",
      "7.291709 7.5 7.5\n",
      "7.9747124 7.5 10.0\n",
      "6.6424527 7.5 7.5\n",
      "8.618468 7.5 5.0\n",
      "7.699234 7.5 7.5\n",
      "6.5376515 7.5 7.5\n",
      "7.7759223 7.5 7.5\n",
      "7.5235915 7.5 7.5\n",
      "7.37816 7.5 7.5\n",
      "8.659096 7.5 7.5\n",
      "7.8772883 7.5 10.0\n",
      "7.325911 7.5 7.5\n",
      "2.848714 2.5 0.0\n",
      "6.7180777 7.5 5.0\n",
      "8.414538 7.5 7.5\n",
      "6.953184 7.5 5.0\n",
      "5.395814 5 2.5\n",
      "7.5803337 7.5 10.0\n",
      "9.489346 10 7.5\n",
      "8.6335335 7.5 10.0\n",
      "7.9350557 7.5 7.5\n",
      "9.432738 10 10.0\n",
      "6.423227 7.5 2.5\n",
      "8.856326 10 10.0\n",
      "7.8391647 7.5 10.0\n",
      "8.914419 10 10.0\n",
      "7.756202 7.5 10.0\n",
      "8.731067 7.5 5.0\n",
      "8.860134 10 7.5\n",
      "7.8849535 7.5 7.5\n",
      "9.06101 10 10.0\n",
      "8.809544 10 10.0\n",
      "7.3787103 7.5 10.0\n",
      "6.9704385 7.5 7.5\n",
      "7.158867 7.5 10.0\n",
      "5.0284066 5 2.5\n",
      "8.663938 7.5 10.0\n",
      "8.108798 7.5 7.5\n",
      "8.541402 7.5 2.5\n",
      "8.541363 7.5 10.0\n",
      "7.1693697 7.5 7.5\n",
      "7.4652405 7.5 10.0\n",
      "7.9994063 7.5 10.0\n",
      "7.520384 7.5 7.5\n",
      "6.370214 7.5 2.5\n",
      "7.507338 7.5 0.0\n",
      "8.412423 7.5 10.0\n",
      "3.2681868 2.5 2.5\n",
      "7.138706 7.5 7.5\n",
      "8.925926 10 10.0\n",
      "8.697322 7.5 10.0\n",
      "7.9604325 7.5 10.0\n",
      "8.204713 7.5 2.5\n",
      "8.400347 7.5 7.5\n",
      "6.3788147 7.5 7.5\n",
      "7.306433 7.5 7.5\n",
      "7.764073 7.5 5.0\n",
      "5.8734336 5 7.5\n",
      "6.4721055 7.5 2.5\n",
      "7.0267596 7.5 7.5\n",
      "7.4443154 7.5 10.0\n",
      "7.105748 7.5 5.0\n",
      "6.749915 7.5 7.5\n",
      "6.4740024 7.5 7.5\n",
      "8.486832 7.5 10.0\n",
      "6.4215064 7.5 10.0\n",
      "7.074429 7.5 5.0\n",
      "9.22484 10 10.0\n",
      "4.1694484 5 2.5\n",
      "7.288771 7.5 7.5\n",
      "7.4001155 7.5 5.0\n",
      "7.3550854 7.5 7.5\n",
      "8.675209 7.5 10.0\n",
      "7.4599094 7.5 5.0\n",
      "7.4428554 7.5 7.5\n",
      "7.153505 7.5 7.5\n",
      "7.4663324 7.5 10.0\n",
      "7.890716 7.5 2.5\n",
      "9.152111 10 10.0\n",
      "9.179613 10 10.0\n",
      "8.499989 7.5 10.0\n",
      "6.978427 7.5 2.5\n",
      "8.882984 10 7.5\n",
      "9.803037 10 5.0\n",
      "7.5173397 7.5 10.0\n",
      "7.946553 7.5 10.0\n",
      "5.157532 5 2.5\n",
      "8.385147 7.5 7.5\n",
      "6.8091373 7.5 7.5\n",
      "9.738599 10 10.0\n",
      "8.577357 7.5 10.0\n",
      "7.6354556 7.5 7.5\n",
      "7.944271 7.5 7.5\n",
      "7.8088984 7.5 7.5\n",
      "6.711192 7.5 5.0\n",
      "9.181415 10 10.0\n",
      "8.345118 7.5 10.0\n",
      "7.464939 7.5 2.5\n",
      "9.017062 10 10.0\n",
      "3.4188087 2.5 0.0\n",
      "8.990631 10 10.0\n",
      "6.8886046 7.5 10.0\n",
      "5.5455594 5 7.5\n",
      "5.849814 5 7.5\n",
      "6.8834105 7.5 0.0\n",
      "9.077557 10 10.0\n",
      "7.7458606 7.5 7.5\n",
      "8.170761 7.5 7.5\n",
      "4.5359063 5 2.5\n",
      "7.4548306 7.5 7.5\n",
      "7.4947147 7.5 10.0\n",
      "8.942481 10 7.5\n",
      "7.2921114 7.5 7.5\n",
      "9.10942 10 10.0\n",
      "6.4626794 7.5 7.5\n",
      "7.2657614 7.5 7.5\n",
      "7.692549 7.5 7.5\n",
      "7.803355 7.5 10.0\n",
      "6.7984285 7.5 5.0\n",
      "3.8623085 5 7.5\n",
      "8.608974 7.5 10.0\n",
      "8.99698 10 10.0\n",
      "6.342052 7.5 10.0\n",
      "7.0033474 7.5 7.5\n",
      "7.2271075 7.5 5.0\n",
      "8.703488 7.5 7.5\n",
      "7.881562 7.5 7.5\n",
      "8.665552 7.5 10.0\n",
      "7.053925 7.5 10.0\n",
      "7.779216 7.5 7.5\n",
      "5.0165305 5 10.0\n",
      "7.631777 7.5 10.0\n",
      "7.155921 7.5 10.0\n",
      "7.2695866 7.5 7.5\n",
      "7.0282784 7.5 7.5\n",
      "8.904624 10 7.5\n",
      "8.660762 7.5 5.0\n",
      "7.398917 7.5 7.5\n",
      "8.270994 7.5 7.5\n",
      "7.796476 7.5 7.5\n",
      "8.634703 7.5 10.0\n",
      "8.86881 10 10.0\n",
      "7.062053 7.5 10.0\n",
      "8.940746 10 10.0\n",
      "8.315051 7.5 10.0\n",
      "7.662619 7.5 10.0\n",
      "8.663633 7.5 10.0\n",
      "7.4767423 7.5 7.5\n",
      "7.2762866 7.5 7.5\n",
      "5.3332033 5 2.5\n",
      "6.442603 7.5 7.5\n",
      "8.949857 10 7.5\n",
      "7.00041 7.5 10.0\n",
      "4.3921757 5 0.0\n",
      "9.298478 10 10.0\n",
      "7.939052 7.5 5.0\n",
      "7.8926616 7.5 10.0\n",
      "7.360098 7.5 5.0\n",
      "8.901692 10 7.5\n",
      "6.5881624 7.5 10.0\n",
      "7.6436553 7.5 5.0\n",
      "9.26612 10 10.0\n",
      "7.279023 7.5 2.5\n",
      "7.454567 7.5 5.0\n",
      "8.84128 10 10.0\n",
      "7.154193 7.5 7.5\n",
      "7.348761 7.5 10.0\n",
      "7.0509744 7.5 10.0\n",
      "7.4109974 7.5 10.0\n",
      "7.50665 7.5 10.0\n",
      "7.6811013 7.5 10.0\n",
      "7.7428393 7.5 7.5\n",
      "9.00808 10 10.0\n",
      "7.262486 7.5 10.0\n",
      "8.888634 10 7.5\n",
      "7.2414865 7.5 7.5\n",
      "9.01813 10 10.0\n",
      "5.4588103 5 5.0\n",
      "9.536162 10 10.0\n",
      "8.924709 10 10.0\n",
      "9.236886 10 7.5\n",
      "8.050895 7.5 7.5\n",
      "5.5868134 5 2.5\n",
      "8.454868 7.5 7.5\n",
      "6.8156075 7.5 7.5\n",
      "7.3488946 7.5 5.0\n",
      "9.12472 10 10.0\n",
      "7.9694934 7.5 10.0\n",
      "8.356356 7.5 10.0\n",
      "6.3539596 7.5 5.0\n",
      "4.8942156 5 7.5\n",
      "5.792913 5 2.5\n",
      "8.34318 7.5 7.5\n",
      "6.2689314 7.5 7.5\n",
      "6.4542704 7.5 7.5\n",
      "6.0504494 5 5.0\n",
      "5.3503 5 5.0\n",
      "8.388317 7.5 7.5\n",
      "6.404294 7.5 7.5\n",
      "8.114807 7.5 7.5\n",
      "7.017598 7.5 0.0\n",
      "7.436452 7.5 7.5\n",
      "8.936677 10 10.0\n",
      "7.492207 7.5 7.5\n",
      "7.747825 7.5 5.0\n",
      "5.4058166 5 2.5\n",
      "8.482055 7.5 5.0\n",
      "7.5904565 7.5 7.5\n",
      "8.903685 10 10.0\n",
      "7.2752185 7.5 7.5\n",
      "6.237676 5 5.0\n",
      "7.296435 7.5 10.0\n",
      "6.833897 7.5 10.0\n",
      "7.549978 7.5 10.0\n",
      "7.071357 7.5 10.0\n",
      "5.4863944 5 2.5\n",
      "6.307876 7.5 7.5\n",
      "8.20893 7.5 10.0\n",
      "5.990776 5 7.5\n",
      "8.362532 7.5 10.0\n",
      "7.1043367 7.5 7.5\n",
      "7.3421392 7.5 10.0\n",
      "7.644373 7.5 10.0\n",
      "7.4476748 7.5 2.5\n",
      "8.021668 7.5 10.0\n",
      "7.874553 7.5 7.5\n",
      "9.096622 10 10.0\n",
      "7.7939878 7.5 7.5\n",
      "7.065462 7.5 7.5\n",
      "7.933445 7.5 10.0\n",
      "6.372114 7.5 0.0\n",
      "7.3497086 7.5 7.5\n",
      "9.058817 10 10.0\n",
      "7.126306 7.5 7.5\n",
      "9.141496 10 7.5\n",
      "7.120605 7.5 7.5\n",
      "7.9963956 7.5 7.5\n",
      "7.2307744 7.5 7.5\n",
      "7.8520155 7.5 7.5\n",
      "6.823829 7.5 5.0\n",
      "7.277965 7.5 10.0\n",
      "6.9042625 7.5 5.0\n",
      "7.4205875 7.5 10.0\n",
      "9.475593 10 7.5\n",
      "7.6673994 7.5 7.5\n",
      "7.582217 7.5 10.0\n",
      "7.6652284 7.5 5.0\n",
      "7.099575 7.5 10.0\n",
      "7.53591 7.5 7.5\n",
      "6.852302 7.5 7.5\n",
      "7.071714 7.5 5.0\n",
      "8.843876 10 5.0\n",
      "6.181886 5 2.5\n",
      "9.502911 10 10.0\n",
      "8.127546 7.5 7.5\n",
      "9.289203 10 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.760685 7.5 10.0\n",
      "8.821927 10 7.5\n",
      "7.4442616 7.5 7.5\n",
      "7.7990084 7.5 7.5\n",
      "6.3827243 7.5 2.5\n",
      "7.2358866 7.5 10.0\n",
      "8.875368 10 10.0\n",
      "6.5619397 7.5 5.0\n",
      "9.182947 10 10.0\n",
      "4.367136 5 7.5\n",
      "7.6697392 7.5 7.5\n",
      "7.6056943 7.5 7.5\n",
      "7.1915956 7.5 10.0\n",
      "8.1389675 7.5 10.0\n",
      "8.704581 7.5 7.5\n",
      "7.4515715 7.5 7.5\n",
      "7.3995833 7.5 2.5\n",
      "5.835661 5 2.5\n",
      "8.826144 10 10.0\n",
      "9.235827 10 7.5\n",
      "5.5191054 5 5.0\n",
      "6.203065 5 7.5\n",
      "6.5741863 7.5 7.5\n",
      "6.2972455 7.5 10.0\n",
      "7.064277 7.5 5.0\n",
      "5.743789 5 5.0\n",
      "8.2548685 7.5 10.0\n",
      "8.869461 10 10.0\n",
      "7.3615146 7.5 7.5\n",
      "6.889896 7.5 7.5\n",
      "6.8485804 7.5 7.5\n",
      "6.5264893 7.5 7.5\n",
      "6.994022 7.5 7.5\n",
      "7.7897563 7.5 10.0\n",
      "8.830721 10 7.5\n",
      "6.8106136 7.5 10.0\n",
      "7.553045 7.5 10.0\n",
      "6.657207 7.5 5.0\n",
      "7.0640388 7.5 7.5\n",
      "6.8612704 7.5 5.0\n",
      "8.883724 10 7.5\n",
      "7.7433324 7.5 7.5\n",
      "7.1755404 7.5 10.0\n",
      "7.748843 7.5 7.5\n",
      "6.334149 7.5 5.0\n",
      "9.155457 10 10.0\n",
      "8.379332 7.5 10.0\n",
      "8.09853 7.5 10.0\n",
      "8.055823 7.5 7.5\n",
      "6.5188313 7.5 10.0\n",
      "8.244404 7.5 7.5\n",
      "7.3874316 7.5 5.0\n",
      "7.6197114 7.5 7.5\n",
      "5.0924687 5 2.5\n",
      "7.3565054 7.5 7.5\n",
      "6.8516836 7.5 5.0\n",
      "7.22283 7.5 7.5\n",
      "8.544028 7.5 10.0\n",
      "8.874953 10 10.0\n",
      "7.785538 7.5 2.5\n",
      "7.615743 7.5 5.0\n",
      "6.2110815 5 7.5\n",
      "8.905908 10 7.5\n",
      "9.155115 10 7.5\n",
      "8.831339 10 10.0\n",
      "8.791692 10 10.0\n",
      "7.1740227 7.5 7.5\n",
      "7.984481 7.5 10.0\n",
      "6.8095455 7.5 7.5\n",
      "6.7658477 7.5 7.5\n",
      "4.0211477 5 0.0\n",
      "9.298213 10 10.0\n",
      "7.7640285 7.5 10.0\n",
      "7.1943264 7.5 7.5\n",
      "6.6188107 7.5 5.0\n",
      "7.418891 7.5 7.5\n",
      "9.093144 10 10.0\n",
      "6.556414 7.5 2.5\n",
      "8.967906 10 7.5\n",
      "6.96446 7.5 7.5\n",
      "9.513585 10 10.0\n",
      "6.2502117 7.5 2.5\n",
      "6.600219 7.5 7.5\n",
      "6.180531 5 7.5\n",
      "8.556815 7.5 10.0\n",
      "6.4508605 7.5 2.5\n",
      "7.747286 7.5 7.5\n",
      "8.94993 10 10.0\n",
      "7.9718065 7.5 0.0\n",
      "7.671445 7.5 7.5\n",
      "8.54826 7.5 10.0\n",
      "6.4970074 7.5 10.0\n",
      "6.2253866 5 5.0\n",
      "9.364621 10 10.0\n",
      "7.103515 7.5 7.5\n",
      "4.0923433 5 5.0\n",
      "7.1871715 7.5 10.0\n",
      "8.133171 7.5 10.0\n",
      "7.228049 7.5 7.5\n",
      "5.460142 5 0.0\n",
      "9.281177 10 10.0\n",
      "6.7303257 7.5 7.5\n",
      "9.328558 10 7.5\n",
      "7.0105066 7.5 5.0\n",
      "7.8402147 7.5 10.0\n",
      "9.561613 10 10.0\n",
      "5.0860367 5 5.0\n",
      "6.75933 7.5 5.0\n",
      "7.101638 7.5 5.0\n",
      "8.863973 10 10.0\n",
      "9.284204 10 10.0\n",
      "8.5385065 7.5 7.5\n",
      "7.055512 7.5 10.0\n",
      "8.534483 7.5 7.5\n",
      "7.2394156 7.5 7.5\n",
      "6.813231 7.5 10.0\n",
      "5.1219826 5 5.0\n",
      "8.446651 7.5 2.5\n",
      "8.489075 7.5 7.5\n",
      "6.176046 5 10.0\n",
      "7.112429 7.5 7.5\n",
      "8.769637 10 10.0\n",
      "6.7999105 7.5 7.5\n",
      "7.1541214 7.5 2.5\n",
      "7.662334 7.5 7.5\n",
      "7.457184 7.5 7.5\n",
      "8.565492 7.5 10.0\n",
      "7.406676 7.5 10.0\n",
      "8.319792 7.5 10.0\n",
      "4.7781196 5 5.0\n",
      "7.4248605 7.5 7.5\n",
      "7.2647586 7.5 7.5\n",
      "8.287544 7.5 10.0\n",
      "9.121345 10 10.0\n",
      "6.904462 7.5 7.5\n",
      "7.063353 7.5 5.0\n",
      "7.685941 7.5 10.0\n",
      "7.0683255 7.5 7.5\n",
      "9.269771 10 10.0\n",
      "6.7854 7.5 5.0\n",
      "8.355713 7.5 7.5\n",
      "8.555223 7.5 7.5\n",
      "6.920619 7.5 5.0\n",
      "7.2219195 7.5 10.0\n",
      "7.631307 7.5 7.5\n",
      "8.436543 7.5 10.0\n",
      "7.7471223 7.5 10.0\n",
      "6.6988764 7.5 7.5\n",
      "7.487588 7.5 7.5\n",
      "8.995469 10 10.0\n",
      "7.4221916 7.5 5.0\n",
      "7.378341 7.5 10.0\n",
      "6.356868 7.5 0.0\n",
      "8.7482395 7.5 7.5\n",
      "8.006449 7.5 7.5\n",
      "8.9731455 10 10.0\n",
      "8.04119 7.5 7.5\n",
      "7.2025995 7.5 7.5\n",
      "7.1456933 7.5 7.5\n",
      "8.393837 7.5 10.0\n",
      "7.091093 7.5 7.5\n",
      "7.6636677 7.5 7.5\n",
      "7.4544606 7.5 10.0\n",
      "6.9319725 7.5 7.5\n",
      "6.9912496 7.5 7.5\n",
      "5.8340125 5 7.5\n",
      "8.336481 7.5 2.5\n",
      "7.256458 7.5 10.0\n",
      "7.868079 7.5 5.0\n",
      "6.8389444 7.5 5.0\n",
      "7.5735617 7.5 2.5\n",
      "5.6374464 5 2.5\n",
      "8.234454 7.5 10.0\n",
      "7.6379957 7.5 7.5\n",
      "7.2473564 7.5 10.0\n",
      "6.423319 7.5 5.0\n",
      "6.8627553 7.5 7.5\n",
      "8.638815 7.5 10.0\n",
      "7.8739066 7.5 7.5\n",
      "7.2595453 7.5 7.5\n",
      "6.9961743 7.5 10.0\n",
      "6.727895 7.5 5.0\n",
      "7.7048035 7.5 5.0\n",
      "9.503086 10 10.0\n",
      "8.992665 10 7.5\n",
      "7.1220965 7.5 10.0\n",
      "8.152927 7.5 10.0\n",
      "6.0989876 5 7.5\n",
      "7.2947507 7.5 10.0\n",
      "7.812168 7.5 10.0\n",
      "8.249279 7.5 7.5\n",
      "9.083114 10 7.5\n",
      "6.684174 7.5 7.5\n",
      "8.27601 7.5 7.5\n",
      "7.4649386 7.5 7.5\n",
      "6.228361 5 7.5\n",
      "7.2239947 7.5 10.0\n",
      "8.472889 7.5 10.0\n",
      "7.2850413 7.5 10.0\n",
      "5.152608 5 2.5\n",
      "7.450144 7.5 10.0\n",
      "9.023595 10 10.0\n",
      "6.1205363 5 5.0\n",
      "7.088463 7.5 7.5\n",
      "8.339172 7.5 7.5\n",
      "8.894118 10 10.0\n",
      "8.418751 7.5 10.0\n",
      "7.47054 7.5 7.5\n",
      "7.6479 7.5 7.5\n",
      "8.790858 10 10.0\n",
      "5.976678 5 2.5\n",
      "6.3362617 7.5 5.0\n",
      "7.508385 7.5 7.5\n",
      "9.050475 10 10.0\n",
      "7.22314 7.5 10.0\n",
      "9.095815 10 7.5\n",
      "7.5938005 7.5 7.5\n",
      "7.402622 7.5 10.0\n",
      "8.155241 7.5 7.5\n",
      "6.7528048 7.5 5.0\n",
      "6.831529 7.5 5.0\n",
      "8.079639 7.5 7.5\n",
      "7.168214 7.5 7.5\n",
      "7.065857 7.5 7.5\n",
      "8.898822 10 7.5\n",
      "8.517264 7.5 10.0\n",
      "8.42282 7.5 10.0\n",
      "6.33531 7.5 5.0\n",
      "7.5515003 7.5 7.5\n",
      "8.382813 7.5 10.0\n",
      "9.278016 10 10.0\n",
      "6.69611 7.5 2.5\n",
      "7.9641695 7.5 7.5\n",
      "8.9510145 10 7.5\n",
      "7.120676 7.5 10.0\n",
      "8.603761 7.5 10.0\n",
      "7.2068686 7.5 2.5\n",
      "8.484365 7.5 10.0\n",
      "7.5601597 7.5 7.5\n",
      "7.4336624 7.5 10.0\n",
      "7.676981 7.5 7.5\n",
      "7.314356 7.5 7.5\n",
      "7.321901 7.5 7.5\n",
      "7.0178547 7.5 5.0\n",
      "7.8469286 7.5 7.5\n",
      "6.5889993 7.5 7.5\n",
      "6.132666 5 5.0\n",
      "9.227357 10 10.0\n",
      "7.771103 7.5 10.0\n",
      "8.806351 10 2.5\n",
      "4.484934 5 2.5\n",
      "6.7978477 7.5 7.5\n",
      "6.767732 7.5 0.0\n",
      "8.985864 10 10.0\n",
      "7.0490413 7.5 7.5\n",
      "7.362008 7.5 7.5\n",
      "8.767563 10 10.0\n",
      "8.767576 10 10.0\n",
      "7.6037 7.5 7.5\n",
      "7.472853 7.5 10.0\n",
      "7.4841633 7.5 7.5\n",
      "8.15233 7.5 10.0\n",
      "7.745507 7.5 10.0\n",
      "7.3786197 7.5 10.0\n",
      "8.100622 7.5 5.0\n",
      "7.5063143 7.5 7.5\n",
      "8.019329 7.5 7.5\n",
      "7.081466 7.5 7.5\n",
      "6.8630347 7.5 10.0\n",
      "7.892143 7.5 10.0\n",
      "6.891666 7.5 5.0\n",
      "7.5126605 7.5 10.0\n",
      "7.487547 7.5 7.5\n",
      "7.158037 7.5 5.0\n",
      "7.1660485 7.5 7.5\n",
      "7.125655 7.5 7.5\n",
      "6.889044 7.5 10.0\n",
      "9.171648 10 7.5\n",
      "6.2396994 5 7.5\n",
      "9.701401 10 10.0\n",
      "7.149961 7.5 7.5\n",
      "8.671176 7.5 10.0\n",
      "7.6878686 7.5 7.5\n",
      "7.2988453 7.5 5.0\n",
      "6.78473 7.5 0.0\n",
      "6.952039 7.5 7.5\n",
      "9.267616 10 10.0\n",
      "8.707578 7.5 7.5\n",
      "6.4654503 7.5 7.5\n",
      "7.875001 7.5 7.5\n",
      "6.2194095 5 2.5\n",
      "6.391421 7.5 7.5\n",
      "7.931196 7.5 10.0\n",
      "7.3833327 7.5 7.5\n",
      "6.3278265 7.5 7.5\n",
      "8.853412 10 10.0\n",
      "8.527034 7.5 10.0\n",
      "7.1646705 7.5 0.0\n",
      "4.830397 5 0.0\n",
      "7.9131107 7.5 7.5\n",
      "7.0594935 7.5 7.5\n",
      "6.41397 7.5 7.5\n",
      "8.766951 10 7.5\n",
      "8.48736 7.5 10.0\n",
      "7.68842 7.5 7.5\n",
      "7.4392753 7.5 10.0\n",
      "6.8414216 7.5 7.5\n",
      "8.034958 7.5 7.5\n",
      "6.0081954 5 5.0\n",
      "8.634897 7.5 10.0\n",
      "6.126692 5 10.0\n",
      "8.662507 7.5 7.5\n",
      "6.707382 7.5 7.5\n",
      "7.843692 7.5 2.5\n",
      "8.566007 7.5 10.0\n",
      "9.95166 10 7.5\n",
      "7.8053713 7.5 10.0\n",
      "3.3283925 2.5 2.5\n",
      "8.162451 7.5 10.0\n",
      "7.5280657 7.5 10.0\n",
      "7.6494412 7.5 7.5\n",
      "9.088149 10 10.0\n",
      "8.942622 10 10.0\n",
      "9.069761 10 7.5\n",
      "8.784606 10 7.5\n",
      "7.5085697 7.5 7.5\n",
      "8.459416 7.5 7.5\n",
      "9.266925 10 10.0\n",
      "6.5855036 7.5 0.0\n",
      "8.705413 7.5 7.5\n",
      "7.36313 7.5 10.0\n",
      "8.466101 7.5 10.0\n",
      "7.400836 7.5 10.0\n",
      "7.8765554 7.5 7.5\n",
      "7.7707906 7.5 5.0\n",
      "6.338151 7.5 5.0\n",
      "6.449645 7.5 7.5\n",
      "6.7081747 7.5 5.0\n",
      "6.397057 7.5 7.5\n",
      "6.9551578 7.5 10.0\n",
      "9.258585 10 10.0\n",
      "8.364756 7.5 10.0\n",
      "7.536412 7.5 7.5\n",
      "7.2656803 7.5 7.5\n",
      "7.810284 7.5 10.0\n",
      "7.5170255 7.5 7.5\n",
      "7.2494063 7.5 10.0\n",
      "7.197843 7.5 7.5\n",
      "7.7980466 7.5 10.0\n",
      "6.504983 7.5 2.5\n",
      "9.44681 10 10.0\n",
      "4.16425 5 2.5\n",
      "7.66822 7.5 7.5\n",
      "5.1666336 5 7.5\n",
      "6.283653 7.5 7.5\n",
      "8.754262 10 7.5\n",
      "7.1499963 7.5 7.5\n",
      "5.7567387 5 2.5\n",
      "6.232669 5 5.0\n",
      "8.56062 7.5 10.0\n",
      "7.4789815 7.5 10.0\n",
      "7.169029 7.5 2.5\n",
      "7.0149016 7.5 7.5\n",
      "5.8781085 5 7.5\n",
      "9.148239 10 7.5\n",
      "8.4042015 7.5 7.5\n",
      "7.6319895 7.5 10.0\n",
      "7.684509 7.5 10.0\n",
      "6.562287 7.5 7.5\n",
      "7.7269554 7.5 10.0\n",
      "8.871754 10 10.0\n",
      "7.497858 7.5 5.0\n",
      "8.635564 7.5 7.5\n",
      "7.614476 7.5 5.0\n",
      "8.73728 7.5 7.5\n",
      "7.680233 7.5 7.5\n",
      "7.3038306 7.5 5.0\n",
      "6.51153 7.5 2.5\n",
      "7.249142 7.5 5.0\n",
      "5.9831886 5 7.5\n",
      "9.194047 10 5.0\n",
      "6.564926 7.5 7.5\n",
      "7.376843 7.5 7.5\n",
      "6.883712 7.5 5.0\n",
      "7.2710114 7.5 7.5\n",
      "6.5180864 7.5 7.5\n",
      "6.8026314 7.5 7.5\n",
      "7.9298987 7.5 7.5\n",
      "5.750521 5 7.5\n",
      "3.5695658 2.5 0.0\n",
      "7.1151724 7.5 7.5\n",
      "6.5837936 7.5 7.5\n",
      "8.670176 7.5 7.5\n",
      "8.762258 10 10.0\n",
      "7.7187757 7.5 2.5\n",
      "7.1892815 7.5 7.5\n",
      "9.041867 10 10.0\n",
      "7.552977 7.5 7.5\n",
      "7.5985346 7.5 10.0\n",
      "9.450669 10 10.0\n",
      "5.1497116 5 7.5\n",
      "7.0983987 7.5 10.0\n",
      "7.4697337 7.5 7.5\n",
      "8.99073 10 10.0\n",
      "7.088537 7.5 7.5\n",
      "7.4016585 7.5 7.5\n",
      "5.7633333 5 7.5\n",
      "9.429383 10 10.0\n",
      "6.74521 7.5 7.5\n",
      "8.124723 7.5 7.5\n",
      "5.767807 5 0.0\n",
      "8.250881 7.5 7.5\n",
      "9.027729 10 7.5\n",
      "7.931411 7.5 10.0\n",
      "4.4305305 5 0.0\n",
      "7.7821355 7.5 10.0\n",
      "8.188417 7.5 10.0\n",
      "6.294384 7.5 7.5\n",
      "7.5833473 7.5 7.5\n",
      "8.190156 7.5 7.5\n",
      "7.5552173 7.5 2.5\n",
      "5.401988 5 10.0\n",
      "8.687737 7.5 7.5\n",
      "7.3829203 7.5 7.5\n",
      "4.9184823 5 7.5\n",
      "4.795736 5 10.0\n",
      "8.450025 7.5 7.5\n",
      "6.302373 7.5 10.0\n",
      "7.9600043 7.5 10.0\n",
      "7.285608 7.5 2.5\n",
      "7.430115 7.5 7.5\n",
      "8.461951 7.5 10.0\n",
      "8.900803 10 10.0\n",
      "9.764553 10 10.0\n",
      "7.173943 7.5 10.0\n",
      "7.2012124 7.5 5.0\n",
      "9.271759 10 10.0\n",
      "8.847291 10 10.0\n",
      "7.331409 7.5 7.5\n",
      "7.6099057 7.5 7.5\n",
      "6.362331 7.5 7.5\n",
      "6.9939804 7.5 2.5\n",
      "7.1794066 7.5 10.0\n",
      "8.91889 10 10.0\n",
      "7.495342 7.5 10.0\n",
      "5.962276 5 7.5\n",
      "6.79363 7.5 7.5\n",
      "7.3363185 7.5 10.0\n",
      "6.842632 7.5 5.0\n",
      "9.456772 10 2.5\n",
      "7.6076565 7.5 7.5\n",
      "8.131601 7.5 7.5\n",
      "5.491631 5 2.5\n",
      "8.915633 10 7.5\n",
      "7.686285 7.5 7.5\n",
      "9.151863 10 7.5\n",
      "6.7845774 7.5 7.5\n",
      "6.9657335 7.5 7.5\n",
      "6.9048076 7.5 7.5\n",
      "7.1704164 7.5 7.5\n",
      "6.575851 7.5 7.5\n",
      "8.08417 7.5 10.0\n",
      "8.502848 7.5 10.0\n",
      "6.927402 7.5 10.0\n",
      "7.3492827 7.5 5.0\n",
      "8.512946 7.5 7.5\n",
      "8.936766 10 10.0\n",
      "8.954133 10 10.0\n",
      "8.521378 7.5 7.5\n",
      "7.0609393 7.5 7.5\n",
      "7.061174 7.5 7.5\n",
      "8.530084 7.5 7.5\n",
      "7.4564056 7.5 5.0\n",
      "7.1120663 7.5 7.5\n",
      "9.085295 10 10.0\n",
      "9.576993 10 10.0\n",
      "9.058344 10 2.5\n",
      "6.1162314 5 7.5\n",
      "7.615408 7.5 2.5\n",
      "6.636728 7.5 10.0\n",
      "7.300126 7.5 7.5\n",
      "7.492826 7.5 7.5\n",
      "7.9226766 7.5 10.0\n",
      "9.098399 10 10.0\n",
      "7.315274 7.5 7.5\n",
      "7.2308707 7.5 10.0\n",
      "8.218155 7.5 7.5\n",
      "8.825605 10 10.0\n",
      "9.131255 10 10.0\n",
      "6.3436623 7.5 0.0\n",
      "7.1296115 7.5 10.0\n",
      "6.2182455 5 10.0\n",
      "7.571516 7.5 7.5\n",
      "7.8731775 7.5 10.0\n",
      "6.3650527 7.5 10.0\n",
      "7.4471903 7.5 5.0\n",
      "7.588214 7.5 10.0\n",
      "6.9339223 7.5 5.0\n",
      "7.271678 7.5 7.5\n",
      "8.605566 7.5 10.0\n",
      "6.868173 7.5 7.5\n",
      "8.517467 7.5 7.5\n",
      "6.343595 7.5 10.0\n",
      "7.0638437 7.5 7.5\n",
      "9.584772 10 10.0\n",
      "5.2647486 5 5.0\n",
      "7.063435 7.5 2.5\n",
      "7.6944933 7.5 7.5\n",
      "6.9750166 7.5 2.5\n",
      "7.5036335 7.5 10.0\n",
      "8.626322 7.5 7.5\n",
      "7.160359 7.5 7.5\n",
      "6.7259126 7.5 2.5\n",
      "8.633618 7.5 10.0\n",
      "7.1803737 7.5 10.0\n",
      "8.456575 7.5 7.5\n",
      "8.528995 7.5 10.0\n",
      "6.9848337 7.5 10.0\n",
      "8.582359 7.5 10.0\n",
      "7.6636477 7.5 5.0\n",
      "7.5601425 7.5 7.5\n"
     ]
    }
   ],
   "source": [
    "for pred, clipped, actual in zip(xgb_preds, clipS(xgb_copy), y_test ):\n",
    "    print (pred, clipped, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35883188889119\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,clipS(xgb_preds))**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shrikar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import theano\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "np.random.seed(123)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11202/11202 [==============================] - 5s 467us/step - loss: 41.1009\n",
      "Epoch 2/200\n",
      "11202/11202 [==============================] - 6s 500us/step - loss: 34.7649\n",
      "Epoch 3/200\n",
      "11202/11202 [==============================] - 5s 453us/step - loss: 29.2374\n",
      "Epoch 4/200\n",
      "11202/11202 [==============================] - 5s 425us/step - loss: 24.4289\n",
      "Epoch 5/200\n",
      "11202/11202 [==============================] - 5s 435us/step - loss: 20.2696\n",
      "Epoch 6/200\n",
      "11202/11202 [==============================] - 6s 507us/step - loss: 16.7329\n",
      "Epoch 7/200\n",
      "11202/11202 [==============================] - 7s 610us/step - loss: 13.8000\n",
      "Epoch 8/200\n",
      "11202/11202 [==============================] - 6s 525us/step - loss: 11.4331\n",
      "Epoch 9/200\n",
      "11202/11202 [==============================] - 5s 451us/step - loss: 9.6048\n",
      "Epoch 10/200\n",
      "11202/11202 [==============================] - 5s 431us/step - loss: 8.2789\n",
      "Epoch 11/200\n",
      "11202/11202 [==============================] - 5s 459us/step - loss: 7.4013\n",
      "Epoch 12/200\n",
      "11202/11202 [==============================] - 6s 521us/step - loss: 6.8826\n",
      "Epoch 13/200\n",
      "11202/11202 [==============================] - 5s 484us/step - loss: 6.6276\n",
      "Epoch 14/200\n",
      "11202/11202 [==============================] - 5s 450us/step - loss: 6.5269\n",
      "Epoch 15/200\n",
      "11202/11202 [==============================] - 7s 583us/step - loss: 6.4957\n",
      "Epoch 16/200\n",
      "11202/11202 [==============================] - 5s 456us/step - loss: 6.4871\n",
      "Epoch 17/200\n",
      "11202/11202 [==============================] - 7s 593us/step - loss: 6.4848\n",
      "Epoch 18/200\n",
      "11202/11202 [==============================] - 7s 660us/step - loss: 6.4844\n",
      "Epoch 19/200\n",
      "11202/11202 [==============================] - 7s 626us/step - loss: 6.4841\n",
      "Epoch 20/200\n",
      "11202/11202 [==============================] - 7s 597us/step - loss: 6.4841\n",
      "Epoch 21/200\n",
      "11202/11202 [==============================] - 6s 501us/step - loss: 6.4841\n",
      "Epoch 22/200\n",
      "11202/11202 [==============================] - 5s 472us/step - loss: 6.4841\n",
      "Epoch 23/200\n",
      "11202/11202 [==============================] - 6s 494us/step - loss: 6.4841\n",
      "Epoch 24/200\n",
      "11202/11202 [==============================] - 6s 520us/step - loss: 6.4841\n",
      "Epoch 25/200\n",
      "11202/11202 [==============================] - 6s 515us/step - loss: 6.4841\n",
      "Epoch 26/200\n",
      "11202/11202 [==============================] - 5s 475us/step - loss: 6.4841\n",
      "Epoch 27/200\n",
      "11202/11202 [==============================] - 6s 493us/step - loss: 6.4842\n",
      "Epoch 28/200\n",
      "11202/11202 [==============================] - 6s 500us/step - loss: 6.4842\n",
      "Epoch 29/200\n",
      "11202/11202 [==============================] - 6s 523us/step - loss: 6.4842\n",
      "Epoch 30/200\n",
      "11202/11202 [==============================] - 5s 479us/step - loss: 6.4841\n",
      "Epoch 31/200\n",
      "11202/11202 [==============================] - 6s 535us/step - loss: 6.4841\n",
      "Epoch 32/200\n",
      "11202/11202 [==============================] - 7s 585us/step - loss: 6.4842\n",
      "Epoch 33/200\n",
      "11202/11202 [==============================] - 7s 600us/step - loss: 6.4842\n",
      "Epoch 34/200\n",
      "11202/11202 [==============================] - 5s 468us/step - loss: 6.4842\n",
      "Epoch 35/200\n",
      "11202/11202 [==============================] - 5s 476us/step - loss: 6.4841\n",
      "Epoch 36/200\n",
      "11202/11202 [==============================] - 5s 464us/step - loss: 6.4843\n",
      "Epoch 37/200\n",
      "11202/11202 [==============================] - 6s 558us/step - loss: 6.4842\n",
      "Epoch 38/200\n",
      "11202/11202 [==============================] - 6s 512us/step - loss: 6.4842\n",
      "Epoch 39/200\n",
      "11202/11202 [==============================] - 5s 479us/step - loss: 6.4841\n",
      "Epoch 40/200\n",
      "11202/11202 [==============================] - 6s 553us/step - loss: 6.4841\n",
      "Epoch 41/200\n",
      "11202/11202 [==============================] - 5s 449us/step - loss: 6.4842\n",
      "Epoch 42/200\n",
      "11202/11202 [==============================] - 6s 561us/step - loss: 6.4841\n",
      "Epoch 43/200\n",
      "11202/11202 [==============================] - 6s 514us/step - loss: 6.4842\n",
      "Epoch 44/200\n",
      "11202/11202 [==============================] - 7s 611us/step - loss: 6.4841\n",
      "Epoch 45/200\n",
      "11202/11202 [==============================] - 7s 587us/step - loss: 6.4841\n",
      "Epoch 46/200\n",
      "11202/11202 [==============================] - 6s 533us/step - loss: 6.4841\n",
      "Epoch 47/200\n",
      "11202/11202 [==============================] - 5s 417us/step - loss: 6.4841\n",
      "Epoch 48/200\n",
      "11202/11202 [==============================] - 5s 419us/step - loss: 6.4841\n",
      "Epoch 49/200\n",
      "11202/11202 [==============================] - 5s 410us/step - loss: 6.4842\n",
      "Epoch 50/200\n",
      "11202/11202 [==============================] - 5s 426us/step - loss: 6.4841\n",
      "Epoch 51/200\n",
      "11202/11202 [==============================] - 5s 409us/step - loss: 6.4841\n",
      "Epoch 52/200\n",
      "11202/11202 [==============================] - 5s 418us/step - loss: 6.4841\n",
      "Epoch 53/200\n",
      "11202/11202 [==============================] - 5s 421us/step - loss: 6.4841\n",
      "Epoch 54/200\n",
      "11202/11202 [==============================] - 5s 422us/step - loss: 6.4842\n",
      "Epoch 55/200\n",
      "11202/11202 [==============================] - 5s 417us/step - loss: 6.4842\n",
      "Epoch 56/200\n",
      "11202/11202 [==============================] - 5s 422us/step - loss: 6.4841\n",
      "Epoch 57/200\n",
      "11202/11202 [==============================] - 5s 419us/step - loss: 6.4841\n",
      "Epoch 58/200\n",
      "11202/11202 [==============================] - 5s 419us/step - loss: 6.4842\n",
      "Epoch 59/200\n",
      "11202/11202 [==============================] - 5s 416us/step - loss: 6.4841\n",
      "Epoch 60/200\n",
      "11202/11202 [==============================] - 5s 425us/step - loss: 6.4841\n",
      "Epoch 61/200\n",
      "11202/11202 [==============================] - 5s 416us/step - loss: 6.4841\n",
      "Epoch 62/200\n",
      "11202/11202 [==============================] - 5s 421us/step - loss: 6.4842\n",
      "Epoch 63/200\n",
      "11202/11202 [==============================] - 5s 466us/step - loss: 6.4841\n",
      "Epoch 64/200\n",
      "11202/11202 [==============================] - 7s 613us/step - loss: 6.4841\n",
      "Epoch 65/200\n",
      "11202/11202 [==============================] - 6s 569us/step - loss: 6.4842\n",
      "Epoch 66/200\n",
      "11202/11202 [==============================] - 8s 693us/step - loss: 6.4842\n",
      "Epoch 67/200\n",
      "11202/11202 [==============================] - 6s 577us/step - loss: 6.4841\n",
      "Epoch 68/200\n",
      "11202/11202 [==============================] - 6s 554us/step - loss: 6.4842\n",
      "Epoch 69/200\n",
      "11202/11202 [==============================] - 6s 492us/step - loss: 6.4842\n",
      "Epoch 70/200\n",
      "11202/11202 [==============================] - 5s 488us/step - loss: 6.4842\n",
      "Epoch 71/200\n",
      "11202/11202 [==============================] - 5s 487us/step - loss: 6.4842\n",
      "Epoch 72/200\n",
      "11202/11202 [==============================] - 5s 484us/step - loss: 6.4842\n",
      "Epoch 73/200\n",
      "11202/11202 [==============================] - 5s 479us/step - loss: 6.4842\n",
      "Epoch 74/200\n",
      "11202/11202 [==============================] - 5s 474us/step - loss: 6.4841\n",
      "Epoch 75/200\n",
      "11202/11202 [==============================] - 6s 497us/step - loss: 6.4841\n",
      "Epoch 76/200\n",
      "11202/11202 [==============================] - 5s 479us/step - loss: 6.4842\n",
      "Epoch 77/200\n",
      "11202/11202 [==============================] - 5s 483us/step - loss: 6.4840\n",
      "Epoch 78/200\n",
      "11202/11202 [==============================] - 7s 660us/step - loss: 6.4842\n",
      "Epoch 79/200\n",
      "11202/11202 [==============================] - 6s 532us/step - loss: 6.4841\n",
      "Epoch 80/200\n",
      "11202/11202 [==============================] - 6s 567us/step - loss: 6.4841\n",
      "Epoch 81/200\n",
      "11202/11202 [==============================] - 5s 465us/step - loss: 6.4842\n",
      "Epoch 82/200\n",
      "11202/11202 [==============================] - 5s 463us/step - loss: 6.4842\n",
      "Epoch 83/200\n",
      "11202/11202 [==============================] - 5s 467us/step - loss: 6.4841\n",
      "Epoch 84/200\n",
      "11202/11202 [==============================] - 5s 486us/step - loss: 6.4841\n",
      "Epoch 85/200\n",
      "11202/11202 [==============================] - 5s 453us/step - loss: 6.4841\n",
      "Epoch 86/200\n",
      "11202/11202 [==============================] - 5s 465us/step - loss: 6.4842\n",
      "Epoch 87/200\n",
      "11202/11202 [==============================] - 5s 461us/step - loss: 6.4840\n",
      "Epoch 88/200\n",
      "11202/11202 [==============================] - 5s 472us/step - loss: 6.4841\n",
      "Epoch 89/200\n",
      "11202/11202 [==============================] - 5s 459us/step - loss: 6.4842\n",
      "Epoch 90/200\n",
      "11202/11202 [==============================] - 5s 456us/step - loss: 6.4843\n",
      "Epoch 91/200\n",
      "11202/11202 [==============================] - 5s 467us/step - loss: 6.4842\n",
      "Epoch 92/200\n",
      "11202/11202 [==============================] - 5s 469us/step - loss: 6.4842\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202/11202 [==============================] - 5s 441us/step - loss: 6.4842\n",
      "Epoch 94/200\n",
      "11202/11202 [==============================] - 6s 538us/step - loss: 6.4842\n",
      "Epoch 95/200\n",
      "11202/11202 [==============================] - 5s 413us/step - loss: 6.4841\n",
      "Epoch 96/200\n",
      "11202/11202 [==============================] - 4s 385us/step - loss: 6.4842\n",
      "Epoch 97/200\n",
      "11202/11202 [==============================] - 4s 398us/step - loss: 6.4842\n",
      "Epoch 98/200\n",
      "11202/11202 [==============================] - 4s 371us/step - loss: 6.4841\n",
      "Epoch 99/200\n",
      "11202/11202 [==============================] - 4s 370us/step - loss: 6.4842\n",
      "Epoch 100/200\n",
      "11202/11202 [==============================] - 4s 367us/step - loss: 6.4840\n",
      "Epoch 101/200\n",
      "11202/11202 [==============================] - 4s 398us/step - loss: 6.4841\n",
      "Epoch 102/200\n",
      "11202/11202 [==============================] - 5s 425us/step - loss: 6.4842\n",
      "Epoch 103/200\n",
      "11202/11202 [==============================] - 4s 400us/step - loss: 6.4842\n",
      "Epoch 104/200\n",
      "11202/11202 [==============================] - 4s 395us/step - loss: 6.4843\n",
      "Epoch 105/200\n",
      "11202/11202 [==============================] - 4s 401us/step - loss: 6.4843\n",
      "Epoch 106/200\n",
      "11202/11202 [==============================] - 5s 409us/step - loss: 6.4841\n",
      "Epoch 107/200\n",
      "11202/11202 [==============================] - 5s 404us/step - loss: 6.4841\n",
      "Epoch 108/200\n",
      "11202/11202 [==============================] - 4s 392us/step - loss: 6.4842\n",
      "Epoch 109/200\n",
      "11202/11202 [==============================] - 5s 464us/step - loss: 6.4842\n",
      "Epoch 110/200\n",
      "11202/11202 [==============================] - 5s 429us/step - loss: 6.4844\n",
      "Epoch 111/200\n",
      "11202/11202 [==============================] - 5s 433us/step - loss: 6.4841\n",
      "Epoch 112/200\n",
      "11202/11202 [==============================] - 5s 462us/step - loss: 6.4841\n",
      "Epoch 113/200\n",
      "11202/11202 [==============================] - 4s 347us/step - loss: 6.4842\n",
      "Epoch 114/200\n",
      "11202/11202 [==============================] - 4s 331us/step - loss: 6.4842\n",
      "Epoch 115/200\n",
      "11202/11202 [==============================] - 5s 449us/step - loss: 6.4841\n",
      "Epoch 116/200\n",
      "11202/11202 [==============================] - 5s 416us/step - loss: 6.4842\n",
      "Epoch 117/200\n",
      "11202/11202 [==============================] - 5s 420us/step - loss: 6.4841\n",
      "Epoch 118/200\n",
      "11202/11202 [==============================] - 5s 463us/step - loss: 6.4843\n",
      "Epoch 119/200\n",
      "11202/11202 [==============================] - 4s 365us/step - loss: 6.4841\n",
      "Epoch 120/200\n",
      "11202/11202 [==============================] - 4s 339us/step - loss: 6.4842\n",
      "Epoch 121/200\n",
      "11202/11202 [==============================] - 4s 338us/step - loss: 6.4842\n",
      "Epoch 122/200\n",
      "11202/11202 [==============================] - 6s 546us/step - loss: 6.4842\n",
      "Epoch 123/200\n",
      "11202/11202 [==============================] - 6s 534us/step - loss: 6.4841\n",
      "Epoch 124/200\n",
      "11202/11202 [==============================] - 7s 605us/step - loss: 6.4842\n",
      "Epoch 125/200\n",
      "11202/11202 [==============================] - 4s 362us/step - loss: 6.4841\n",
      "Epoch 126/200\n",
      "11202/11202 [==============================] - 5s 459us/step - loss: 6.4842\n",
      "Epoch 127/200\n",
      "11202/11202 [==============================] - 4s 327us/step - loss: 6.4843\n",
      "Epoch 128/200\n",
      "11202/11202 [==============================] - 4s 337us/step - loss: 6.4841\n",
      "Epoch 129/200\n",
      "11202/11202 [==============================] - 4s 335us/step - loss: 6.4842\n",
      "Epoch 130/200\n",
      "11202/11202 [==============================] - 4s 396us/step - loss: 6.4842\n",
      "Epoch 131/200\n",
      "11202/11202 [==============================] - 4s 399us/step - loss: 6.4842\n",
      "Epoch 132/200\n",
      "11202/11202 [==============================] - 4s 321us/step - loss: 6.4840\n",
      "Epoch 133/200\n",
      "11202/11202 [==============================] - 4s 333us/step - loss: 6.4842\n",
      "Epoch 134/200\n",
      "11202/11202 [==============================] - 3s 305us/step - loss: 6.4841\n",
      "Epoch 135/200\n",
      "11202/11202 [==============================] - 3s 305us/step - loss: 6.4842\n",
      "Epoch 136/200\n",
      "11202/11202 [==============================] - 3s 296us/step - loss: 6.4842\n",
      "Epoch 137/200\n",
      "11202/11202 [==============================] - 3s 303us/step - loss: 6.4842\n",
      "Epoch 138/200\n",
      "11202/11202 [==============================] - 4s 347us/step - loss: 6.4842\n",
      "Epoch 139/200\n",
      "11202/11202 [==============================] - 5s 448us/step - loss: 6.4842\n",
      "Epoch 140/200\n",
      "11202/11202 [==============================] - 3s 295us/step - loss: 6.4841\n",
      "Epoch 141/200\n",
      "11202/11202 [==============================] - 3s 290us/step - loss: 6.4842\n",
      "Epoch 142/200\n",
      "11202/11202 [==============================] - 3s 301us/step - loss: 6.4842\n",
      "Epoch 143/200\n",
      "11202/11202 [==============================] - 3s 302us/step - loss: 6.4841\n",
      "Epoch 144/200\n",
      "11202/11202 [==============================] - 3s 290us/step - loss: 6.4841\n",
      "Epoch 145/200\n",
      "11202/11202 [==============================] - 3s 292us/step - loss: 6.4841\n",
      "Epoch 146/200\n",
      "11202/11202 [==============================] - 4s 339us/step - loss: 6.4842\n",
      "Epoch 147/200\n",
      "11202/11202 [==============================] - 6s 495us/step - loss: 6.4841\n",
      "Epoch 148/200\n",
      "11202/11202 [==============================] - 5s 437us/step - loss: 6.4841\n",
      "Epoch 149/200\n",
      "11202/11202 [==============================] - 6s 509us/step - loss: 6.4841\n",
      "Epoch 150/200\n",
      "11202/11202 [==============================] - 5s 461us/step - loss: 6.4841\n",
      "Epoch 151/200\n",
      "11202/11202 [==============================] - 6s 498us/step - loss: 6.4842\n",
      "Epoch 152/200\n",
      "11202/11202 [==============================] - 7s 652us/step - loss: 6.4841\n",
      "Epoch 153/200\n",
      "11202/11202 [==============================] - 8s 721us/step - loss: 6.4842\n",
      "Epoch 154/200\n",
      "11202/11202 [==============================] - 7s 642us/step - loss: 6.4843\n",
      "Epoch 155/200\n",
      "11202/11202 [==============================] - 7s 591us/step - loss: 6.4841\n",
      "Epoch 156/200\n",
      "11202/11202 [==============================] - 6s 569us/step - loss: 6.4841\n",
      "Epoch 157/200\n",
      "11202/11202 [==============================] - 4s 380us/step - loss: 6.4840\n",
      "Epoch 158/200\n",
      "11202/11202 [==============================] - 4s 321us/step - loss: 6.4842\n",
      "Epoch 159/200\n",
      "11202/11202 [==============================] - 4s 320us/step - loss: 6.4842\n",
      "Epoch 160/200\n",
      "11202/11202 [==============================] - 4s 317us/step - loss: 6.4842\n",
      "Epoch 161/200\n",
      "11202/11202 [==============================] - 4s 337us/step - loss: 6.4841\n",
      "Epoch 162/200\n",
      "11202/11202 [==============================] - 6s 528us/step - loss: 6.4841\n",
      "Epoch 163/200\n",
      "11202/11202 [==============================] - 6s 513us/step - loss: 6.4842\n",
      "Epoch 164/200\n",
      "11202/11202 [==============================] - 6s 529us/step - loss: 6.4842\n",
      "Epoch 165/200\n",
      "11202/11202 [==============================] - 6s 497us/step - loss: 6.4842\n",
      "Epoch 166/200\n",
      "11202/11202 [==============================] - 6s 510us/step - loss: 6.4842\n",
      "Epoch 167/200\n",
      "11202/11202 [==============================] - 7s 640us/step - loss: 6.4842\n",
      "Epoch 168/200\n",
      "11202/11202 [==============================] - 6s 577us/step - loss: 6.4843\n",
      "Epoch 169/200\n",
      "11202/11202 [==============================] - 7s 598us/step - loss: 6.4842\n",
      "Epoch 170/200\n",
      "11202/11202 [==============================] - 6s 541us/step - loss: 6.4842\n",
      "Epoch 171/200\n",
      "11202/11202 [==============================] - 6s 553us/step - loss: 6.4843\n",
      "Epoch 172/200\n",
      "11202/11202 [==============================] - 6s 529us/step - loss: 6.4841\n",
      "Epoch 173/200\n",
      "11202/11202 [==============================] - 6s 521us/step - loss: 6.4841\n",
      "Epoch 174/200\n",
      "11202/11202 [==============================] - 6s 525us/step - loss: 6.4842\n",
      "Epoch 175/200\n",
      "11202/11202 [==============================] - 6s 537us/step - loss: 6.4842\n",
      "Epoch 176/200\n",
      "11202/11202 [==============================] - 6s 531us/step - loss: 6.4842\n",
      "Epoch 177/200\n",
      "11202/11202 [==============================] - 6s 558us/step - loss: 6.4841\n",
      "Epoch 178/200\n",
      "11202/11202 [==============================] - 5s 454us/step - loss: 6.4842\n",
      "Epoch 179/200\n",
      "11202/11202 [==============================] - 6s 546us/step - loss: 6.4841\n",
      "Epoch 180/200\n",
      "11202/11202 [==============================] - 4s 380us/step - loss: 6.4840\n",
      "Epoch 181/200\n",
      "11202/11202 [==============================] - 5s 481us/step - loss: 6.4841\n",
      "Epoch 182/200\n",
      "11202/11202 [==============================] - 4s 379us/step - loss: 6.4841\n",
      "Epoch 183/200\n",
      "11202/11202 [==============================] - 5s 426us/step - loss: 6.4842\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11202/11202 [==============================] - 4s 399us/step - loss: 6.4841\n",
      "Epoch 185/200\n",
      "11202/11202 [==============================] - 4s 366us/step - loss: 6.4842\n",
      "Epoch 186/200\n",
      "11202/11202 [==============================] - 4s 353us/step - loss: 6.4841\n",
      "Epoch 187/200\n",
      "11202/11202 [==============================] - 4s 365us/step - loss: 6.4841\n",
      "Epoch 188/200\n",
      "11202/11202 [==============================] - 5s 408us/step - loss: 6.4842\n",
      "Epoch 189/200\n",
      "11202/11202 [==============================] - 5s 402us/step - loss: 6.4841\n",
      "Epoch 190/200\n",
      "11202/11202 [==============================] - 5s 427us/step - loss: 6.4841\n",
      "Epoch 191/200\n",
      "11202/11202 [==============================] - 4s 345us/step - loss: 6.4842\n",
      "Epoch 192/200\n",
      "11202/11202 [==============================] - 4s 379us/step - loss: 6.4842\n",
      "Epoch 193/200\n",
      "11202/11202 [==============================] - 5s 447us/step - loss: 6.4842\n",
      "Epoch 194/200\n",
      "11202/11202 [==============================] - 4s 380us/step - loss: 6.4841\n",
      "Epoch 195/200\n",
      "11202/11202 [==============================] - 5s 438us/step - loss: 6.4841\n",
      "Epoch 196/200\n",
      "11202/11202 [==============================] - 4s 368us/step - loss: 6.4841\n",
      "Epoch 197/200\n",
      "11202/11202 [==============================] - 4s 356us/step - loss: 6.4841\n",
      "Epoch 198/200\n",
      "11202/11202 [==============================] - 4s 362us/step - loss: 6.4842\n",
      "Epoch 199/200\n",
      "11202/11202 [==============================] - 4s 356us/step - loss: 6.4842\n",
      "Epoch 200/200\n",
      "11202/11202 [==============================] - 5s 428us/step - loss: 6.4841\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(346, input_dim=346, activation='relu'))\n",
    "#model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='hard_sigmoid'))\n",
    "#model.add(Dense(50, activation='hard_sigmoid'))\n",
    "#model.add(Dense(40, activation='sigmoid'))\n",
    "#model.add(Dense(10, activation='sigmoid'))\n",
    "#model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=.00001))\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10)\n",
    "\n",
    "nn_preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5454019774075713\n"
     ]
    }
   ],
   "source": [
    "print (mean_squared_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.918158279204034\n"
     ]
    }
   ],
   "source": [
    "print (mean_absolute_error(y_test,nn_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Hello World!\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f68cdd6908ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#gridSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f3a695028b0, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/shrika...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['C20D1B75A4164F2493A4698E035E1B98']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['C20D1B75A4164F2493A4698E035E1B98'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2018, 5, 2, 5, 53, 55, 34178, tzinfo=tzutc()), u'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', u'msg_type': u'execute_request', u'session': u'C20D1B75A4164F2493A4698E035E1B98', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'4687FE3B0F7D494A87FEC30B2115F9FE', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'# Refer https://github.com/keras-team/keras/bl...int(\"%f (%f) with: %r\" % (mean, stdev, param))\\n', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Import object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, ...], cell_name='<ipython-input-10-f68cdd6908ba>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2817 \n   2818         try:\n   2819             for i, node in enumerate(to_run_exec):\n   2820                 mod = ast.Module([node])\n   2821                 code = compiler(mod, cell_name, \"exec\")\n-> 2822                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        result = <ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>, result=<ExecutionResult object at 7f3a212d4d50, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f3a0ec10930, file \"<ipython-input-10-f68cdd6908ba>\", line 56>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'AdaBoostRegressor': <class 'sklearn.ensemble.weight_boosting.AdaBoostRegressor'>, 'Convolution2D': <class 'keras.layers.convolutional.Conv2D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'ExtraTreesRegressor': <class 'sklearn.ensemble.forest.ExtraTreesRegressor'>, 'Flatten': <class 'keras.layers.core.Flatten'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/home/shrikar/Documents/pythonStuff/dsfinalproject/<ipython-input-10-f68cdd6908ba> in <module>()\n     51 batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n     52 param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n     53 \n     54 #gridSearch\n     55 grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n---> 56 grid_result = grid.fit(X_test, y_test) \n     57 \n     58 \n     59 # summarize results\n     60 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=1), X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method KFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns]\n        y = 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed May  2 00:53:55 2018\nPID: 6680                 Python 2.7.14: /home/shrikar/anaconda2/bin/python\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasRegressor object>,              Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], 17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, {'score': <function _passthrough_scorer>}, array([1601, 1602, 1603, ..., 4799, 4800, 4801]), array([   0,    1,    2, ..., 1598, 1599, 1600]), 1, {'activation': 'relu', 'batch_size': 20, 'epochs': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasRegressor object>, X=             Age  Years IT / Programming Experie...            1.0       \n\n[4802 rows x 346 columns], y=17789    10.0\n11732     2.5\n21218    10.0\n4269  ...0      7.5\nName: Job Satisfaction, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([1601, 1602, 1603, ..., 4799, 4800, 4801]), test=array([   0,    1,    2, ..., 1598, 1599, 1600]), verbose=1, parameters={'activation': 'relu', 'batch_size': 20, 'epochs': 1}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method KerasRegressor.set_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        parameters = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in set_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, **params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n    108             **params: Dictionary of parameter names mapped to their values.\n    109 \n    110         # Returns\n    111             self\n    112         \"\"\"\n--> 113         self.check_params(params)\n        self.check_params = <bound method KerasRegressor.check_params of <keras.wrappers.scikit_learn.KerasRegressor object>>\n        params = {'activation': 'relu', 'batch_size': 20, 'epochs': 1}\n    114         self.sk_params.update(params)\n    115         return self\n    116 \n    117     def fit(self, x, y, **kwargs):\n\n...........................................................................\n/home/shrikar/anaconda2/lib/python2.7/site-packages/keras/wrappers/scikit_learn.py in check_params(self=<keras.wrappers.scikit_learn.KerasRegressor object>, params={'activation': 'relu', 'batch_size': 20, 'epochs': 1})\n     84                 if has_arg(fn, params_name):\n     85                     break\n     86             else:\n     87                 if params_name != 'nb_epoch':\n     88                     raise ValueError(\n---> 89                         '{} is not a legal parameter'.format(params_name))\n        params_name = 'activation'\n     90 \n     91     def get_params(self, **params):\n     92         \"\"\"Gets parameters for this estimator.\n     93 \n\nValueError: activation is not a legal parameter\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Refer https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "# Refer https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# Aim of this is to show case use of keras and grid search libraries\n",
    "print(\"Hello World!\")\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "##############################################################\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(346, input_dim=346, activation='relu'))\n",
    "    model.add(Dense(200, activation=activation))\n",
    "    model.add(Dense(100, activation=activation))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "print(\"Hello World!\")\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=1)\n",
    "\n",
    "# Use scikit-learn to grid search \n",
    "#activation =  ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign \n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "learn_rate = [.00001,.0001,0.001, 0.01, 0.1, 0.3]\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weight_constraint=[1, 2, 3, 4, 5]\n",
    "neurons = [1, 5, 10, 15, 20, 25, 30]\n",
    "init = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "optimizer = [ 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "\n",
    "# grid search epochs, batch size\n",
    "#learn_rate = [.00001,.0001, 0.001]\n",
    "activations =  ['relu', 'hard_sigmoid', 'softsign'] # softmax, softplus, softsign \n",
    "#dropout_rate = [0.0, 0.3, 0.7,]\n",
    "epochs = [1, 10,50,150] # add 50, 100, 150 etc\n",
    "batch_size = [20,50,100] # add 5, 10, 20, 40, 60, 80, 100 etc\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size, activation=activations )\n",
    "\n",
    "#gridSearch\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, verbose = 1)\n",
    "grid_result = grid.fit(X_test, y_test) \n",
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4157204f298c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mngrid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mngrid_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "ngrid_preds = grid.predict(X_test)\n",
    "print (mean_squared_error(y_test,ngrid_preds)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
